{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris/blob/main/Copy_of_solaris_reborn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Libraries"
      ],
      "metadata": {
        "id": "XUR0zNCpOy7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "f727e16e-3134-4a3f-c9bb-26a96454d8fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "3hev1JrVPjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\"AAPL\", \"SPY\", \"TSLA\", \"NVDA\", \"QQQ\"]  # note: ^VIX for Yahoo\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "0bb8feb3-a26a-4a71-db27-cfb90c08388e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "SPY: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "TSLA: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "NVDA: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "QQQ: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL         SPY        TSLA        NVDA  \\\n",
            "Datetime                                                              \n",
            "2025-08-08 15:30:00  228.199997  636.875000  330.319214  182.908096   \n",
            "2025-08-08 16:30:00  228.675003  636.395020  328.660004  181.884995   \n",
            "2025-08-08 17:30:00  229.289993  637.219971  329.510498  182.615005   \n",
            "2025-08-08 18:30:00  228.830002  637.260010  328.630005  182.695007   \n",
            "2025-08-08 19:30:00  229.369995  637.119995  329.679993  182.750000   \n",
            "\n",
            "                            QQQ  \n",
            "Datetime                         \n",
            "2025-08-08 15:30:00  574.000000  \n",
            "2025-08-08 16:30:00  573.280029  \n",
            "2025-08-08 17:30:00  574.375000  \n",
            "2025-08-08 18:30:00  574.375000  \n",
            "2025-08-08 19:30:00  574.549988  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Creation"
      ],
      "metadata": {
        "id": "jLnkdkzRRvVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Features"
      ],
      "metadata": {
        "id": "omLPzq5TDwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    macd = ta.trend.MACD(price_series)\n",
        "    feat_tmp[\"macd\"] = macd.macd()\n",
        "    feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"SPY\", \"QQQ\", \"NVDA\"]:\n",
        "        if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    if \"^VIX\" in aligned_ffill.columns:\n",
        "        feat_tmp[\"vix_ret_1h\"] = aligned_ffill[\"^VIX\"].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    feat_tmp = feat_tmp.dropna(subset=[col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]])\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = ticker\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())\n"
      ],
      "metadata": {
        "id": "MFIHXqY5R2fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac81e9b5-56ee-410b-9c90-acfaccabb52d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created features for 5 tickers\n",
            "Shape: (25210, 26)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.007971  0.012013  0.024587  0.031305 -0.007604  0.003690  0.003882   \n",
            "1  0.002602  0.008187  0.021955  0.036208 -0.003386  0.003683  0.003588   \n",
            "2  0.001715  0.012327  0.018588  0.040581  0.003208  0.003681  0.003188   \n",
            "3  0.011595  0.015967  0.028172  0.049035  0.016817  0.004992  0.003984   \n",
            "4  0.004310  0.017698  0.026030  0.047453  0.012652  0.004917  0.003945   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...      ema_20  vol_change_1h  \\\n",
            "0  0.006928  57.174728 -0.489358  ...  152.371399       0.354865   \n",
            "1  0.006946  58.880818 -0.266801  ...  152.577932      -0.018507   \n",
            "2  0.006880  60.014242 -0.068253  ...  152.790033       1.223954   \n",
            "3  0.007246  66.708324  0.231274  ...  153.152888      -0.300933   \n",
            "4  0.007102  68.822038  0.517156  ...  153.545469       0.135969   \n",
            "\n",
            "     vol_ma_24h  SPY_ret_1h  QQQ_ret_1h  NVDA_ret_1h  hour  day_of_week  \\\n",
            "0  1.176824e+07    0.007243    0.007556     0.008757    18            0   \n",
            "1  1.186138e+07    0.001443    0.001342     0.001497    19            0   \n",
            "2  1.239661e+07   -0.011685   -0.007730    -0.004633    13            1   \n",
            "3  1.266864e+07    0.001588    0.003572     0.007054    14            1   \n",
            "4  1.299610e+07   -0.000104   -0.000854    -0.005476    15            1   \n",
            "\n",
            "             datetime  ticker  \n",
            "0 2022-09-19 18:30:00    AAPL  \n",
            "1 2022-09-19 19:30:00    AAPL  \n",
            "2 2022-09-20 13:30:00    AAPL  \n",
            "3 2022-09-20 14:30:00    AAPL  \n",
            "4 2022-09-20 15:30:00    AAPL  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation"
      ],
      "metadata": {
        "id": "TKZHysWZZsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "vol_lookback = 24         # hours to compute rolling volatility\n",
        "vol_multiplier = 0.5      # threshold scaling vs volatility\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Volatility-based threshold\n",
        "    rolling_vol = price_series.pct_change().rolling(vol_lookback).std()\n",
        "    threshold = rolling_vol * vol_multiplier\n",
        "\n",
        "    # Label creation\n",
        "    label = future_ret.copy()\n",
        "    label[future_ret > threshold] = 1    # Up\n",
        "    label[future_ret < -threshold] = -1  # Down\n",
        "    label[(future_ret <= threshold) & (future_ret >= -threshold)] = 0  # Neutral\n",
        "\n",
        "    # Drop NaNs\n",
        "    label = label.dropna()\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": label.index,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[label.index],\n",
        "        \"label\": label.values,\n",
        "        \"future_ret\": future_ret.loc[label.index],\n",
        "        \"volatility\": rolling_vol.loc[label.index]\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "print(labels_df[\"label\"].value_counts(normalize=True))\n",
        "labels_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "251e001f-2d50-48ea-bd04-504b20c6d053"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (25370, 6)\n",
            "label\n",
            " 0.000000    0.532322\n",
            " 1.000000    0.245171\n",
            "-1.000000    0.217777\n",
            "-0.009297    0.000039\n",
            "-0.006482    0.000039\n",
            "               ...   \n",
            " 0.004660    0.000039\n",
            "-0.013126    0.000039\n",
            "-0.002298    0.000039\n",
            "-0.002268    0.000039\n",
            " 0.002448    0.000039\n",
            "Name: proportion, Length: 123, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime ticker       price     label  future_ret  volatility\n",
              "0 2022-09-13 13:30:00   AAPL  157.820007 -0.008618   -0.008618         NaN\n",
              "1 2022-09-13 14:30:00   AAPL  156.459900 -0.001324   -0.001324         NaN\n",
              "2 2022-09-13 15:30:00   AAPL  156.252701  0.001647    0.001647         NaN\n",
              "3 2022-09-13 16:30:00   AAPL  156.509995 -0.009297   -0.009297         NaN\n",
              "4 2022-09-13 17:30:00   AAPL  155.054993 -0.006482   -0.006482         NaN\n",
              "5 2022-09-13 18:30:00   AAPL  154.050003 -0.001298   -0.001298         NaN\n",
              "6 2022-09-13 19:30:00   AAPL  153.850006  0.007410    0.007410         NaN\n",
              "7 2022-09-14 13:30:00   AAPL  154.990005  0.006065    0.006065         NaN\n",
              "8 2022-09-14 14:30:00   AAPL  155.929993 -0.003912   -0.003912         NaN\n",
              "9 2022-09-14 15:30:00   AAPL  155.320007 -0.001642   -0.001642         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a11c2772-3f6d-412c-8200-291801be1709\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>label</th>\n",
              "      <th>future_ret</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-13 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.820007</td>\n",
              "      <td>-0.008618</td>\n",
              "      <td>-0.008618</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-13 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.459900</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-13 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.252701</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-13 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.509995</td>\n",
              "      <td>-0.009297</td>\n",
              "      <td>-0.009297</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-13 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>155.054993</td>\n",
              "      <td>-0.006482</td>\n",
              "      <td>-0.006482</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-13 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.050003</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-13 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.850006</td>\n",
              "      <td>0.007410</td>\n",
              "      <td>0.007410</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-14 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.990005</td>\n",
              "      <td>0.006065</td>\n",
              "      <td>0.006065</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-09-14 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>155.929993</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-09-14 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>155.320007</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a11c2772-3f6d-412c-8200-291801be1709')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a11c2772-3f6d-412c-8200-291801be1709 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a11c2772-3f6d-412c-8200-291801be1709');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-15130697-fe5e-4139-90c6-2f0997d771cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15130697-fe5e-4139-90c6-2f0997d771cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-15130697-fe5e-4139-90c6-2f0997d771cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 25370,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-13 13:30:00\",\n        \"max\": \"2025-08-08 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-09-08 14:30:00\",\n          \"2024-03-19 19:30:00\",\n          \"2022-09-19 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SPY\",\n          \"QQQ\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 164.9018196603458,\n        \"min\": 11.14999008178711,\n        \"max\": 638.8200073242188,\n        \"num_unique_values\": 23043,\n        \"samples\": [\n          235.34500122070312,\n          194.55499267578125,\n          428.8399963378906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6798652804231663,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          -0.010206823419083452,\n          -0.008030450047519849,\n          -0.01496935961038128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009398811145410326,\n        \"min\": -0.13022686951739132,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          0.002815443242036273,\n          0.029964044609556647,\n          0.0016589617246019581\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005535026745197608,\n        \"min\": 0.0008907621389855575,\n        \"max\": 0.05414076773543391,\n        \"num_unique_values\": 25250,\n        \"samples\": [\n          0.014011333107111322,\n          0.005262215907619315,\n          0.002179474647293163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "rieWxNf5Mp44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1H-ATXHjSK6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Features"
      ],
      "metadata": {
        "id": "_PxZH38IebtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & labels\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y distribution:\\n\", y.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "OERLO3TNed16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554332af-73c8-4413-c685-6cec412d14f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25205, 26)\n",
            "y distribution:\n",
            " label\n",
            " 0.0    0.534854\n",
            " 1.0    0.245983\n",
            "-1.0    0.219163\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale"
      ],
      "metadata": {
        "id": "rpnDnFsiWa87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Label distribution in Train:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "4oxCtsXaSTrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a287f34-ec89-43e5-a280-f4ff9f463cca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train: (17631, 26), Val: (3778, 26), Test: (3779, 26)\n",
            "Label distribution in Train: label\n",
            " 0.0    0.525325\n",
            " 1.0    0.252056\n",
            "-1.0    0.222619\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence making - For LSTM AND CNN"
      ],
      "metadata": {
        "id": "euQxLDkaWdBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 24  # last 24 hours to predict next hour\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "id": "mn5XIK9DWlAN",
        "outputId": "d48951d8-2c8e-415e-a22f-bb26d92b3bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (17607, 24, 26), Val seq: (3754, 24, 26), Test seq: (3755, 24, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 — label encoding + class weights\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# mapping: -1 -> 0 (down), 0 -> 1 (neutral), 1 -> 2 (up)\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "\n",
        "# If your y_* are numpy arrays (seq labels), convert\n",
        "y_train_seq_mapped = np.vectorize(label_map.get)(y_train_seq)\n",
        "y_val_seq_mapped   = np.vectorize(label_map.get)(y_val_seq)\n",
        "y_test_seq_mapped  = np.vectorize(label_map.get)(y_test_seq)\n",
        "\n",
        "# one-hot for Keras\n",
        "y_train_cat = to_categorical(y_train_seq_mapped, num_classes=3)\n",
        "y_val_cat   = to_categorical(y_val_seq_mapped, num_classes=3)\n",
        "y_test_cat  = to_categorical(y_test_seq_mapped, num_classes=3)\n",
        "\n",
        "# compute class weights from training sequence labels\n",
        "classes = np.unique(y_train_seq_mapped)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_seq_mapped)\n",
        "class_weights_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "print(\"Train class distribution:\", np.bincount(y_train_seq_mapped) / len(y_train_seq_mapped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "eb4a44e6-83cb-41ac-f6dd-ca8236b31416"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.4983405667602758), 1: np.float64(0.6344179007674846), 2: np.float64(1.322144627168281)}\n",
            "Train class distribution: [0.22246834 0.52541603 0.25211564]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1jUYMhA9cSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, BatchNormalization, Activation, Dropout,\n",
        "    GlobalAveragePooling1D, Dense, Add\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def residual_block(x, filters, kernel_size, dropout_rate=0.2):\n",
        "    # Shortcut projection if needed\n",
        "    shortcut = x\n",
        "    if x.shape[-1] != filters:\n",
        "        shortcut = Conv1D(filters, kernel_size=1, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_cnn_enhanced(input_shape, n_classes=3, dropout_rate=0.3):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution\n",
        "    x = Conv1D(64, kernel_size=3, padding='same')(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks with increasing filters\n",
        "    x = residual_block(x, 64, 3, dropout_rate=dropout_rate)\n",
        "    x = residual_block(x, 128, 5, dropout_rate=dropout_rate)\n",
        "    x = residual_block(x, 256, 3, dropout_rate=dropout_rate)\n",
        "\n",
        "    # Global pooling + Dense layers\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "cnn_model = build_cnn_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.3)\n",
        "cnn_model.summary()\n"
      ],
      "metadata": {
        "id": "2mDqNrx0SddA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ffed3a7-87f5-4de1-88ea-5719a35d0b3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m5,056\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m82,048\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m594,115\u001b[0m (2.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">594,115</span> (2.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m591,427\u001b[0m (2.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,427</span> (2.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,688\u001b[0m (10.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> (10.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "-p_nIYgVcWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, Bidirectional, LSTM, GRU, Dense, Dropout,\n",
        "    LayerNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
        "    Concatenate, Attention\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_lstm_enhanced(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = LayerNormalization()(inp)\n",
        "\n",
        "    # First BiLSTM layer\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Second BiGRU layer (faster and adds diversity in sequence modeling)\n",
        "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Self-Attention layer\n",
        "    attn_data = Attention()([x, x])\n",
        "    x = Concatenate()([x, attn_data])  # fuse original and attention output\n",
        "\n",
        "    # Pooling\n",
        "    x_avg = GlobalAveragePooling1D()(x)\n",
        "    x_max = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([x_avg, x_max])\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate model\n",
        "lstm_model = build_lstm_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "id": "IYtsddwpfp1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "6acd70b3-2953-4b22-8451-f7f972cade54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │         \u001b[38;5;34m52\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m158,720\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m123,648\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,720</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "7FalnDi8fxYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import numpy as np\n",
        "\n",
        "# Map labels to 0,1,2\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "y_train_tab = np.vectorize(label_map.get)(y_train)\n",
        "y_val_tab   = np.vectorize(label_map.get)(y_val)\n",
        "y_test_tab  = np.vectorize(label_map.get)(y_test)\n",
        "\n",
        "# Class-balanced sample weights\n",
        "sample_weight = compute_sample_weight('balanced', y_train_tab)\n",
        "\n",
        "# Class imbalance handling (per-class scaling)\n",
        "class_counts = np.bincount(y_train_tab)\n",
        "total = len(y_train_tab)\n",
        "scale_weights = [total / (len(class_counts) * c) for c in class_counts]\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=3,\n",
        "    n_estimators=600,               # more trees for better learning\n",
        "    learning_rate=0.03,             # lower LR for more stable learning\n",
        "    max_depth=6,                    # slightly deeper trees\n",
        "    max_leaves=32,                   # controls tree complexity\n",
        "    min_child_weight=3,              # avoids too-specific splits\n",
        "    gamma=1,                         # min loss reduction to split\n",
        "    subsample=0.85,                  # random row sampling\n",
        "    colsample_bytree=0.85,           # random feature sampling\n",
        "    reg_alpha=0.1,                   # L1 regularization\n",
        "    reg_lambda=1.0,                  # L2 regularization\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',              # fast CPU method; use 'gpu_hist' if GPU is available\n",
        "    scale_pos_weight=scale_weights[1], # handles imbalance for the positive class (for binary) — here we might ignore for multi\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EjSEPd16f61x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "TKR7NlqVaq34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cOvOaClz5nPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if supported\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile with lower LR initially for stability\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_cnn_full_model.keras',  # save full model, not just weights\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/cnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "beae2168-2afe-414b-a50d-1abea246f9fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.07967, saving model to best_cnn_full_model.keras\n",
            "138/138 - 53s - 386ms/step - accuracy: 0.3705 - loss: 1.1104 - val_accuracy: 0.4326 - val_loss: 1.0797 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.07967 to 1.07437, saving model to best_cnn_full_model.keras\n",
            "138/138 - 83s - 604ms/step - accuracy: 0.4221 - loss: 1.0875 - val_accuracy: 0.4547 - val_loss: 1.0744 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.07437 to 1.03092, saving model to best_cnn_full_model.keras\n",
            "138/138 - 79s - 575ms/step - accuracy: 0.4347 - loss: 1.0797 - val_accuracy: 0.5112 - val_loss: 1.0309 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.03092\n",
            "138/138 - 82s - 591ms/step - accuracy: 0.4519 - loss: 1.0712 - val_accuracy: 0.4435 - val_loss: 1.0725 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.03092\n",
            "138/138 - 45s - 324ms/step - accuracy: 0.4629 - loss: 1.0666 - val_accuracy: 0.4182 - val_loss: 1.0889 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.03092\n",
            "138/138 - 81s - 588ms/step - accuracy: 0.4595 - loss: 1.0599 - val_accuracy: 0.4350 - val_loss: 1.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.03092\n",
            "138/138 - 81s - 585ms/step - accuracy: 0.4738 - loss: 1.0506 - val_accuracy: 0.4491 - val_loss: 1.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.03092\n",
            "138/138 - 84s - 608ms/step - accuracy: 0.4891 - loss: 1.0344 - val_accuracy: 0.3831 - val_loss: 1.1560 - learning_rate: 2.5000e-04\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.03092\n",
            "138/138 - 79s - 572ms/step - accuracy: 0.5020 - loss: 1.0216 - val_accuracy: 0.3109 - val_loss: 1.2588 - learning_rate: 2.5000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.03092\n",
            "138/138 - 82s - 595ms/step - accuracy: 0.5084 - loss: 1.0150 - val_accuracy: 0.3359 - val_loss: 1.2094 - learning_rate: 2.5000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.03092\n",
            "138/138 - 84s - 605ms/step - accuracy: 0.5154 - loss: 1.0074 - val_accuracy: 0.3524 - val_loss: 1.1722 - learning_rate: 2.5000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.03092\n",
            "138/138 - 45s - 323ms/step - accuracy: 0.5274 - loss: 0.9893 - val_accuracy: 0.3218 - val_loss: 1.2202 - learning_rate: 1.2500e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.03092\n",
            "138/138 - 82s - 593ms/step - accuracy: 0.5296 - loss: 0.9832 - val_accuracy: 0.3213 - val_loss: 1.2562 - learning_rate: 1.2500e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yxu1niZ7gq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if GPU supports it (LSTMs benefit less than CNNs, but still good for speed)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile LSTM with gradient clipping (helps with exploding gradients in RNNs)\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_lstm_full_model.keras',  # Save entire model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/lstm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=120,  # Give it more room to converge\n",
        "    batch_size=96,  # Smaller batch size often helps LSTM generalization\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "3e60908c-efbc-40ad-d906-621a0e667ca3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.11030, saving model to best_lstm_full_model.keras\n",
            "184/184 - 55s - 300ms/step - accuracy: 0.4015 - loss: 1.0903 - val_accuracy: 0.3487 - val_loss: 1.1103 - learning_rate: 3.0000e-04\n",
            "Epoch 2/120\n",
            "\n",
            "Epoch 2: val_loss improved from 1.11030 to 1.07659, saving model to best_lstm_full_model.keras\n",
            "184/184 - 82s - 446ms/step - accuracy: 0.4341 - loss: 1.0765 - val_accuracy: 0.4204 - val_loss: 1.0766 - learning_rate: 3.0000e-04\n",
            "Epoch 3/120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.07659\n",
            "184/184 - 81s - 443ms/step - accuracy: 0.4465 - loss: 1.0689 - val_accuracy: 0.3924 - val_loss: 1.0987 - learning_rate: 3.0000e-04\n",
            "Epoch 4/120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.07659\n",
            "184/184 - 44s - 240ms/step - accuracy: 0.4574 - loss: 1.0606 - val_accuracy: 0.3974 - val_loss: 1.0953 - learning_rate: 3.0000e-04\n",
            "Epoch 5/120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.07659\n",
            "184/184 - 83s - 453ms/step - accuracy: 0.4688 - loss: 1.0511 - val_accuracy: 0.4068 - val_loss: 1.1001 - learning_rate: 3.0000e-04\n",
            "Epoch 6/120\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.07659\n",
            "184/184 - 77s - 419ms/step - accuracy: 0.4670 - loss: 1.0433 - val_accuracy: 0.4177 - val_loss: 1.0845 - learning_rate: 3.0000e-04\n",
            "Epoch 7/120\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.07659\n",
            "184/184 - 42s - 226ms/step - accuracy: 0.4876 - loss: 1.0237 - val_accuracy: 0.4196 - val_loss: 1.0831 - learning_rate: 1.5000e-04\n",
            "Epoch 8/120\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.07659\n",
            "184/184 - 81s - 438ms/step - accuracy: 0.4958 - loss: 1.0127 - val_accuracy: 0.4286 - val_loss: 1.0779 - learning_rate: 1.5000e-04\n",
            "Epoch 9/120\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.07659\n",
            "184/184 - 43s - 236ms/step - accuracy: 0.5094 - loss: 0.9989 - val_accuracy: 0.4086 - val_loss: 1.1098 - learning_rate: 1.5000e-04\n",
            "Epoch 10/120\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.07659\n",
            "184/184 - 43s - 233ms/step - accuracy: 0.5096 - loss: 0.9882 - val_accuracy: 0.3988 - val_loss: 1.1118 - learning_rate: 1.5000e-04\n",
            "Epoch 11/120\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.07659\n",
            "184/184 - 46s - 250ms/step - accuracy: 0.5216 - loss: 0.9719 - val_accuracy: 0.3868 - val_loss: 1.1339 - learning_rate: 7.5000e-05\n",
            "Epoch 12/120\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.07659\n",
            "184/184 - 79s - 429ms/step - accuracy: 0.5293 - loss: 0.9648 - val_accuracy: 0.3881 - val_loss: 1.1373 - learning_rate: 7.5000e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "2RHWbvELgyIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ============================\n",
        "# Optuna objective function\n",
        "# ============================\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 3,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'hist',  # Change to 'gpu_hist' if GPU available\n",
        "        'seed': 42,\n",
        "\n",
        "        # Hyperparameters to tune\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),\n",
        "    }\n",
        "\n",
        "    # DMatrix objects\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train_tab)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val_tab)\n",
        "\n",
        "    # Train with early stopping\n",
        "    evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "    model = xgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=1000,\n",
        "        evals=evals,\n",
        "        early_stopping_rounds=30,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "\n",
        "    # Validation predictions\n",
        "    preds = model.predict(dval)\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "    return accuracy_score(y_val_tab, pred_labels)\n",
        "\n",
        "# ============================\n",
        "# Run Optuna study\n",
        "# ============================\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # Try 50 parameter sets\n",
        "\n",
        "print(\"\\nBest parameters:\", study.best_params)\n",
        "print(\"Best validation accuracy:\", study.best_value)\n",
        "\n",
        "# ============================\n",
        "# Train final model with best params\n",
        "# ============================\n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 3,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'hist',  # Or 'gpu_hist'\n",
        "    'seed': 42\n",
        "})\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_tab)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_tab)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "final_model = xgb.train(\n",
        "    best_params,\n",
        "    dtrain,\n",
        "    num_boost_round=1500,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=30,\n",
        "    verbose_eval=50\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# Evaluate on test set\n",
        "# ============================\n",
        "y_prob = final_model.predict(dtest)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "test_acc = accuracy_score(y_test_tab, y_pred)\n",
        "print(\"\\nFinal Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOUy9Yd0g-6E",
        "outputId": "0327a9b6-fecf-484c-f0f8-9e318629bf43"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/395.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-11 13:11:27,016] A new study created in memory with name: no-name-4b49761b-af0d-40c2-adaf-454621602ad6\n",
            "[I 2025-08-11 13:11:32,192] Trial 0 finished with value: 0.5688194812069878 and parameters: {'max_depth': 3, 'learning_rate': 0.02231350205413467, 'subsample': 0.6169255393733186, 'colsample_bytree': 0.805613833521202, 'gamma': 2.8654092777286637, 'min_child_weight': 6, 'reg_alpha': 0.5094164809696309, 'reg_lambda': 1.9173460639593571}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:11:50,086] Trial 1 finished with value: 0.5561143462149285 and parameters: {'max_depth': 9, 'learning_rate': 0.026507103249523163, 'subsample': 0.646664551451375, 'colsample_bytree': 0.9503787705439664, 'gamma': 0.8003582316298191, 'min_child_weight': 1, 'reg_alpha': 0.3066024031896877, 'reg_lambda': 2.8326926150143015}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:11:51,549] Trial 2 finished with value: 0.5516146109052409 and parameters: {'max_depth': 8, 'learning_rate': 0.18718323581045868, 'subsample': 0.7693040051123242, 'colsample_bytree': 0.8736021632085498, 'gamma': 2.183636750549778, 'min_child_weight': 2, 'reg_alpha': 0.31070624488027654, 'reg_lambda': 0.5324195370934441}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:11:52,440] Trial 3 finished with value: 0.5622022233986236 and parameters: {'max_depth': 5, 'learning_rate': 0.18191614835985992, 'subsample': 0.8865189837349287, 'colsample_bytree': 0.7816461966682337, 'gamma': 3.289517239228722, 'min_child_weight': 6, 'reg_alpha': 0.4035318601036587, 'reg_lambda': 1.3567621777997334}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:11:55,294] Trial 4 finished with value: 0.5614081524616199 and parameters: {'max_depth': 3, 'learning_rate': 0.13005354766566748, 'subsample': 0.6112584156710407, 'colsample_bytree': 0.9034398735627094, 'gamma': 1.6243154770364532, 'min_child_weight': 10, 'reg_alpha': 0.888064865610686, 'reg_lambda': 2.447161944290025}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:11:56,818] Trial 5 finished with value: 0.5444679724722075 and parameters: {'max_depth': 10, 'learning_rate': 0.1793443676485174, 'subsample': 0.7379661855174156, 'colsample_bytree': 0.7123551695832105, 'gamma': 2.154679591050282, 'min_child_weight': 4, 'reg_alpha': 0.06595568639718141, 'reg_lambda': 1.9601507072674629}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:01,057] Trial 6 finished with value: 0.5614081524616199 and parameters: {'max_depth': 8, 'learning_rate': 0.036746768644131275, 'subsample': 0.7399998039028757, 'colsample_bytree': 0.9758030478675006, 'gamma': 3.5157321779372523, 'min_child_weight': 1, 'reg_alpha': 0.17478235434390144, 'reg_lambda': 0.9293206115733278}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:32,020] Trial 7 finished with value: 0.5492323980942297 and parameters: {'max_depth': 10, 'learning_rate': 0.014941244204175416, 'subsample': 0.9949180865056549, 'colsample_bytree': 0.8414203295933609, 'gamma': 0.33475762461077807, 'min_child_weight': 6, 'reg_alpha': 0.18843326629313772, 'reg_lambda': 2.955067702782662}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:32,791] Trial 8 finished with value: 0.5635256749602965 and parameters: {'max_depth': 9, 'learning_rate': 0.26213335012746064, 'subsample': 0.9857906629225496, 'colsample_bytree': 0.7373792476503809, 'gamma': 4.158484386939693, 'min_child_weight': 8, 'reg_alpha': 0.99732110487866, 'reg_lambda': 2.657031686075068}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:35,072] Trial 9 finished with value: 0.5431445209105347 and parameters: {'max_depth': 10, 'learning_rate': 0.13895407241764926, 'subsample': 0.8799648536882534, 'colsample_bytree': 0.970594675867962, 'gamma': 1.8177484348201163, 'min_child_weight': 8, 'reg_alpha': 0.08570912251591467, 'reg_lambda': 2.808579531185308}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:41,950] Trial 10 finished with value: 0.5685547908946532 and parameters: {'max_depth': 3, 'learning_rate': 0.010957775764595062, 'subsample': 0.6777431012552821, 'colsample_bytree': 0.6408243100471044, 'gamma': 4.9329899052652415, 'min_child_weight': 4, 'reg_alpha': 0.6553079970816837, 'reg_lambda': 1.9700059196405852}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:51,837] Trial 11 finished with value: 0.5682901005823187 and parameters: {'max_depth': 3, 'learning_rate': 0.0102238638859666, 'subsample': 0.6556640251989857, 'colsample_bytree': 0.6129654792363076, 'gamma': 4.9464532949962745, 'min_child_weight': 4, 'reg_alpha': 0.6464474030769349, 'reg_lambda': 1.9584079731149018}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:12:59,290] Trial 12 finished with value: 0.5640550555849656 and parameters: {'max_depth': 5, 'learning_rate': 0.02101690601335898, 'subsample': 0.6844925162496629, 'colsample_bytree': 0.6204930914509688, 'gamma': 4.8321114708943265, 'min_child_weight': 4, 'reg_alpha': 0.6324776842502697, 'reg_lambda': 1.5450848476937138}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:00,909] Trial 13 finished with value: 0.5611434621492853 and parameters: {'max_depth': 5, 'learning_rate': 0.06391991762694328, 'subsample': 0.6049034702872887, 'colsample_bytree': 0.6856271099806779, 'gamma': 3.1325087084920353, 'min_child_weight': 7, 'reg_alpha': 0.5984229609122855, 'reg_lambda': 2.1383643296214325}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:10,095] Trial 14 finished with value: 0.5672313393329804 and parameters: {'max_depth': 4, 'learning_rate': 0.010164297701700948, 'subsample': 0.7037384295776838, 'colsample_bytree': 0.8017310428633954, 'gamma': 4.074759503978441, 'min_child_weight': 3, 'reg_alpha': 0.7776433612612391, 'reg_lambda': 2.2899734170511468}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:12,466] Trial 15 finished with value: 0.5574377977766014 and parameters: {'max_depth': 6, 'learning_rate': 0.057095076913933875, 'subsample': 0.8156197002311953, 'colsample_bytree': 0.6657696129738581, 'gamma': 2.8274382372425992, 'min_child_weight': 5, 'reg_alpha': 0.4968784821618742, 'reg_lambda': 1.6210257714428846}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:17,644] Trial 16 finished with value: 0.5688194812069878 and parameters: {'max_depth': 3, 'learning_rate': 0.01730766232540492, 'subsample': 0.8126915278213961, 'colsample_bytree': 0.7672675241115654, 'gamma': 4.105542525749187, 'min_child_weight': 5, 'reg_alpha': 0.5046938136361033, 'reg_lambda': 1.2809837004268425}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:21,873] Trial 17 finished with value: 0.5677607199576495 and parameters: {'max_depth': 4, 'learning_rate': 0.03452562488132499, 'subsample': 0.8283606214343348, 'colsample_bytree': 0.775769896940036, 'gamma': 3.8463078214047934, 'min_child_weight': 10, 'reg_alpha': 0.4717114157065955, 'reg_lambda': 1.1970667256867653}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:26,908] Trial 18 finished with value: 0.565643197458973 and parameters: {'max_depth': 4, 'learning_rate': 0.017154663382431944, 'subsample': 0.878593722615064, 'colsample_bytree': 0.8261671005640612, 'gamma': 2.713712801142181, 'min_child_weight': 8, 'reg_alpha': 0.7594880227280242, 'reg_lambda': 0.8834949388145861}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:28,417] Trial 19 finished with value: 0.5664372683959767 and parameters: {'max_depth': 6, 'learning_rate': 0.08354735164031252, 'subsample': 0.9412936144113526, 'colsample_bytree': 0.732171447507586, 'gamma': 4.376325287841753, 'min_child_weight': 7, 'reg_alpha': 0.3671625428769945, 'reg_lambda': 1.2651835491848582}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:35,445] Trial 20 finished with value: 0.5592906299629433 and parameters: {'max_depth': 7, 'learning_rate': 0.03797755251029515, 'subsample': 0.8448852070452575, 'colsample_bytree': 0.892757171604115, 'gamma': 1.2901697818919378, 'min_child_weight': 5, 'reg_alpha': 0.5413112000599349, 'reg_lambda': 1.737812652364757}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:40,749] Trial 21 finished with value: 0.5682901005823187 and parameters: {'max_depth': 3, 'learning_rate': 0.014473563798255661, 'subsample': 0.7866190338474499, 'colsample_bytree': 0.6584128949328912, 'gamma': 4.532666808198814, 'min_child_weight': 3, 'reg_alpha': 0.7052625793806817, 'reg_lambda': 1.956508400680953}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:46,335] Trial 22 finished with value: 0.5661725780836422 and parameters: {'max_depth': 3, 'learning_rate': 0.023228945287580127, 'subsample': 0.6466922471770676, 'colsample_bytree': 0.7651454359146982, 'gamma': 3.685035143280254, 'min_child_weight': 5, 'reg_alpha': 0.5384191674967035, 'reg_lambda': 1.4947762844323182}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:13:52,860] Trial 23 finished with value: 0.5669666490206459 and parameters: {'max_depth': 4, 'learning_rate': 0.013126451739441049, 'subsample': 0.7112129024790015, 'colsample_bytree': 0.8432738599694248, 'gamma': 4.616106292089174, 'min_child_weight': 6, 'reg_alpha': 0.43189871574179256, 'reg_lambda': 1.0230264965281832}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:00,060] Trial 24 finished with value: 0.567496029645315 and parameters: {'max_depth': 3, 'learning_rate': 0.017885306479208822, 'subsample': 0.7670441608157895, 'colsample_bytree': 0.7000376737004993, 'gamma': 4.051745037288406, 'min_child_weight': 3, 'reg_alpha': 0.7417132103688728, 'reg_lambda': 1.8414329537755676}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:03,118] Trial 25 finished with value: 0.5659078877713075 and parameters: {'max_depth': 4, 'learning_rate': 0.026916111674801714, 'subsample': 0.6291293063533855, 'colsample_bytree': 0.7494299977548344, 'gamma': 3.208492986961076, 'min_child_weight': 7, 'reg_alpha': 0.8332270312868042, 'reg_lambda': 2.2470707729321586}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:11,721] Trial 26 finished with value: 0.5661725780836422 and parameters: {'max_depth': 5, 'learning_rate': 0.012623062202903797, 'subsample': 0.6776124464774598, 'colsample_bytree': 0.807104297132339, 'gamma': 4.949308512270312, 'min_child_weight': 4, 'reg_alpha': 0.6035479325038716, 'reg_lambda': 2.434530085163661}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:15,565] Trial 27 finished with value: 0.5680254102699841 and parameters: {'max_depth': 3, 'learning_rate': 0.020127199085957198, 'subsample': 0.724985022990609, 'colsample_bytree': 0.6458447781265877, 'gamma': 4.327636015563551, 'min_child_weight': 5, 'reg_alpha': 0.32843905450685773, 'reg_lambda': 1.7651284237116778}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:19,381] Trial 28 finished with value: 0.5653785071466384 and parameters: {'max_depth': 4, 'learning_rate': 0.029420802844312952, 'subsample': 0.6775808853012449, 'colsample_bytree': 0.9338289211581977, 'gamma': 2.828625038115876, 'min_child_weight': 2, 'reg_alpha': 0.6799213540257578, 'reg_lambda': 1.397387898038401}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:24,532] Trial 29 finished with value: 0.5598200105876125 and parameters: {'max_depth': 6, 'learning_rate': 0.04305670768187833, 'subsample': 0.637145533194651, 'colsample_bytree': 0.7206689147823278, 'gamma': 1.1241140397219578, 'min_child_weight': 9, 'reg_alpha': 0.2160078235760814, 'reg_lambda': 2.108434131053554}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:28,957] Trial 30 finished with value: 0.5664372683959767 and parameters: {'max_depth': 3, 'learning_rate': 0.02481621266791, 'subsample': 0.8481931015769585, 'colsample_bytree': 0.868035800738717, 'gamma': 3.550790755238164, 'min_child_weight': 6, 'reg_alpha': 0.5592504586566357, 'reg_lambda': 1.1179140427138774}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:37,667] Trial 31 finished with value: 0.5677607199576495 and parameters: {'max_depth': 3, 'learning_rate': 0.010172639390178928, 'subsample': 0.6569988044334527, 'colsample_bytree': 0.6030572170061873, 'gamma': 4.9091396825963605, 'min_child_weight': 4, 'reg_alpha': 0.6563415400450098, 'reg_lambda': 1.9863071965891592}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:44,853] Trial 32 finished with value: 0.567496029645315 and parameters: {'max_depth': 4, 'learning_rate': 0.011524544104496465, 'subsample': 0.6584357045122957, 'colsample_bytree': 0.6298913715049914, 'gamma': 4.6827052388436154, 'min_child_weight': 4, 'reg_alpha': 0.8450764626939314, 'reg_lambda': 1.6740641040262374}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:14:51,190] Trial 33 finished with value: 0.5659078877713075 and parameters: {'max_depth': 3, 'learning_rate': 0.0159012440460691, 'subsample': 0.7605461846914878, 'colsample_bytree': 0.6866115630275832, 'gamma': 2.362973252626092, 'min_child_weight': 2, 'reg_alpha': 0.4444172514609903, 'reg_lambda': 0.6587185394432009}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:15:00,327] Trial 34 finished with value: 0.5669666490206459 and parameters: {'max_depth': 5, 'learning_rate': 0.011805577045191563, 'subsample': 0.622182233446358, 'colsample_bytree': 0.6256143696424271, 'gamma': 4.972148798485653, 'min_child_weight': 3, 'reg_alpha': 0.3882539668959691, 'reg_lambda': 2.435445955811811}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:15:04,766] Trial 35 finished with value: 0.5685547908946532 and parameters: {'max_depth': 3, 'learning_rate': 0.018750216809255055, 'subsample': 0.7880951325559366, 'colsample_bytree': 0.678642542334219, 'gamma': 4.449549955279234, 'min_child_weight': 5, 'reg_alpha': 0.5744329304149385, 'reg_lambda': 1.8839935785712807}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:15:11,793] Trial 36 finished with value: 0.5685547908946532 and parameters: {'max_depth': 4, 'learning_rate': 0.017879611076327278, 'subsample': 0.7957905599035765, 'colsample_bytree': 0.7636454950329025, 'gamma': 3.8739300413769135, 'min_child_weight': 6, 'reg_alpha': 0.5094306718408583, 'reg_lambda': 1.452094332615097}. Best is trial 0 with value: 0.5688194812069878.\n",
            "[I 2025-08-11 13:15:14,943] Trial 37 finished with value: 0.5696135521439916 and parameters: {'max_depth': 3, 'learning_rate': 0.02845916357450999, 'subsample': 0.7552507762672391, 'colsample_bytree': 0.6666641910069, 'gamma': 4.394916003559231, 'min_child_weight': 5, 'reg_alpha': 0.5856294446650139, 'reg_lambda': 1.838450350300456}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:17,543] Trial 38 finished with value: 0.5598200105876125 and parameters: {'max_depth': 7, 'learning_rate': 0.04543006771016175, 'subsample': 0.7517526343597168, 'colsample_bytree': 0.6438273893786655, 'gamma': 3.3121255248818016, 'min_child_weight': 7, 'reg_alpha': 0.2589499726586643, 'reg_lambda': 2.174194827790865}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:32,258] Trial 39 finished with value: 0.5524086818422446 and parameters: {'max_depth': 9, 'learning_rate': 0.030511030745283933, 'subsample': 0.6011269751295195, 'colsample_bytree': 0.7041545441536478, 'gamma': 0.201968521586267, 'min_child_weight': 1, 'reg_alpha': 0.9346350524237047, 'reg_lambda': 2.5760377279458164}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:35,392] Trial 40 finished with value: 0.5622022233986236 and parameters: {'max_depth': 4, 'learning_rate': 0.0759772680357854, 'subsample': 0.7045510833062777, 'colsample_bytree': 0.8196603486678391, 'gamma': 1.7622438840158279, 'min_child_weight': 6, 'reg_alpha': 0.7049379626026049, 'reg_lambda': 1.2985211174464988}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:38,777] Trial 41 finished with value: 0.5682901005823187 and parameters: {'max_depth': 3, 'learning_rate': 0.020678525032002886, 'subsample': 0.7884345723059621, 'colsample_bytree': 0.6758092583523239, 'gamma': 4.354958744180391, 'min_child_weight': 5, 'reg_alpha': 0.5963038231622849, 'reg_lambda': 1.8376899090318835}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:42,577] Trial 42 finished with value: 0.5690841715193224 and parameters: {'max_depth': 3, 'learning_rate': 0.02310898562254149, 'subsample': 0.8077764126211291, 'colsample_bytree': 0.7866571381119741, 'gamma': 4.597499086608856, 'min_child_weight': 5, 'reg_alpha': 0.5590662728851968, 'reg_lambda': 2.032532336458675}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:47,713] Trial 43 finished with value: 0.5667019587083113 and parameters: {'max_depth': 3, 'learning_rate': 0.02426198234706221, 'subsample': 0.8197539878502996, 'colsample_bytree': 0.861832311081581, 'gamma': 4.186367961711421, 'min_child_weight': 4, 'reg_alpha': 0.5080316341667852, 'reg_lambda': 2.0163166879837773}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:50,102] Trial 44 finished with value: 0.5685547908946532 and parameters: {'max_depth': 3, 'learning_rate': 0.03169130596684328, 'subsample': 0.7353217860564714, 'colsample_bytree': 0.7910062954036763, 'gamma': 4.666285807562271, 'min_child_weight': 5, 'reg_alpha': 0.43753000420598037, 'reg_lambda': 2.282996797209425}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:15:55,468] Trial 45 finished with value: 0.567496029645315 and parameters: {'max_depth': 4, 'learning_rate': 0.014765823493744832, 'subsample': 0.8519237519283884, 'colsample_bytree': 0.7432741679003116, 'gamma': 3.927640932972917, 'min_child_weight': 6, 'reg_alpha': 0.6258622527150153, 'reg_lambda': 1.6370045726142646}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:16:01,990] Trial 46 finished with value: 0.563790365272631 and parameters: {'max_depth': 5, 'learning_rate': 0.02206492431285287, 'subsample': 0.9007614482541715, 'colsample_bytree': 0.8434010591432459, 'gamma': 2.0251062713414667, 'min_child_weight': 4, 'reg_alpha': 0.36981950745649794, 'reg_lambda': 2.093199657306879}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:16:06,381] Trial 47 finished with value: 0.567496029645315 and parameters: {'max_depth': 8, 'learning_rate': 0.026617315144658513, 'subsample': 0.8086640273678516, 'colsample_bytree': 0.7865333657896214, 'gamma': 3.7068134070178784, 'min_child_weight': 6, 'reg_alpha': 0.4745929353056184, 'reg_lambda': 1.588024145703013}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:16:14,497] Trial 48 finished with value: 0.5677607199576495 and parameters: {'max_depth': 3, 'learning_rate': 0.014119165054634328, 'subsample': 0.9038052395642204, 'colsample_bytree': 0.7223182124976799, 'gamma': 4.706445286116323, 'min_child_weight': 5, 'reg_alpha': 0.005685309592198595, 'reg_lambda': 1.7332974035527946}. Best is trial 37 with value: 0.5696135521439916.\n",
            "[I 2025-08-11 13:16:15,177] Trial 49 finished with value: 0.5457914240338804 and parameters: {'max_depth': 4, 'learning_rate': 0.26383880603952636, 'subsample': 0.7732730156775298, 'colsample_bytree': 0.7635082476313971, 'gamma': 0.5489915187465217, 'min_child_weight': 4, 'reg_alpha': 0.8019349868864578, 'reg_lambda': 0.7268132576665534}. Best is trial 37 with value: 0.5696135521439916.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters: {'max_depth': 3, 'learning_rate': 0.02845916357450999, 'subsample': 0.7552507762672391, 'colsample_bytree': 0.6666641910069, 'gamma': 4.394916003559231, 'min_child_weight': 5, 'reg_alpha': 0.5856294446650139, 'reg_lambda': 1.838450350300456}\n",
            "Best validation accuracy: 0.5696135521439916\n",
            "[0]\ttrain-mlogloss:1.09381\teval-mlogloss:1.09371\n",
            "[50]\ttrain-mlogloss:0.99107\teval-mlogloss:0.98831\n",
            "[100]\ttrain-mlogloss:0.97124\teval-mlogloss:0.96997\n",
            "[150]\ttrain-mlogloss:0.96354\teval-mlogloss:0.96515\n",
            "[200]\ttrain-mlogloss:0.95937\teval-mlogloss:0.96353\n",
            "[250]\ttrain-mlogloss:0.95628\teval-mlogloss:0.96241\n",
            "[300]\ttrain-mlogloss:0.95466\teval-mlogloss:0.96200\n",
            "[350]\ttrain-mlogloss:0.95309\teval-mlogloss:0.96196\n",
            "[361]\ttrain-mlogloss:0.95293\teval-mlogloss:0.96197\n",
            "\n",
            "Final Test Accuracy: 0.5800476316485843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Evaluation function for any base model\n",
        "def evaluate_model(model, X_test, y_test, model_name, save_path=None):\n",
        "    \"\"\"\n",
        "    Evaluate a trained model on test data and plot confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model object with .predict() method\n",
        "    - X_test: Feature matrix for testing\n",
        "    - y_test: True labels (list, NumPy array, or Pandas Series)\n",
        "    - model_name: String label for model\n",
        "    - save_path: Optional path to save confusion matrix figure\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure numpy array format\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Handle probability outputs\n",
        "    if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "    elif y_pred.ndim > 1 and y_pred.shape[1] == 1:\n",
        "        y_pred = (y_pred > 0.5).astype(int).ravel()\n",
        "\n",
        "    # Accuracy\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"📊 {model_name} Accuracy: {acc:.4%}\")\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(f\"{model_name} - Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save or show\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "        print(f\"Confusion matrix saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "# ==== Evaluate all three base models ====\n",
        "evaluate_model(cnn_model, X_test_seq, y_test_seq_mapped, \"CNN\")\n",
        "evaluate_model(lstm_model, X_test_seq, y_test_seq_mapped, \"LSTM\")\n",
        "evaluate_model(xgb_clf, X_test, y_test, \"XGBoost\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IvI3T9Z4ZmsH",
        "outputId": "33f43586-8975-4dcf-dac9-a3900f115de2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
            "📊 CNN Accuracy: 37.5233%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2025    0.2801    0.2350       757\n",
            "           1     0.5532    0.4623    0.5037      2124\n",
            "           2     0.2304    0.2460    0.2380       874\n",
            "\n",
            "    accuracy                         0.3752      3755\n",
            "   macro avg     0.3287    0.3295    0.3256      3755\n",
            "weighted avg     0.4074    0.3752    0.3877      3755\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
            "📊 LSTM Accuracy: 41.3316%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2145    0.3448    0.2644       757\n",
            "           1     0.5582    0.5800    0.5689      2124\n",
            "           2     0.1782    0.0675    0.0979       874\n",
            "\n",
            "    accuracy                         0.4133      3755\n",
            "   macro avg     0.3170    0.3308    0.3104      3755\n",
            "weighted avg     0.4005    0.4133    0.3979      3755\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 XGBoost Accuracy: 23.1013%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0     0.0000    0.0000    0.0000       761\n",
            "         0.0     0.3125    0.0023    0.0046      2140\n",
            "         1.0     0.2327    0.9886    0.3767       878\n",
            "         2.0     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    accuracy                         0.2310      3779\n",
            "   macro avg     0.1363    0.2477    0.0953      3779\n",
            "weighted avg     0.2310    0.2310    0.0902      3779\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-O-F Predictions"
      ],
      "metadata": {
        "id": "Di2jwJEwhUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ==== Combine your split data back into one dataset ====\n",
        "X_tab = np.vstack([X_train, X_val, X_test])\n",
        "y_tab = np.concatenate([y_train, y_val, y_test])\n",
        "y_tab = pd.Series(y_tab)  # needed for .map()\n",
        "\n",
        "# ==== Time series split config ====\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# ==== Label remap (-1, 0, 1) -> (0, 1, 2) ====\n",
        "label_map = {-1: 0, 0: 1, 1: 2}\n",
        "\n",
        "# ==== One-hot encoder for DL models ====\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "y_all_mapped = y_tab.map(label_map)\n",
        "y_all_oh = enc.fit_transform(y_all_mapped.values.reshape(-1, 1))\n",
        "\n",
        "# ==== Storage for OOF predictions ====\n",
        "oof_cnn = np.zeros((len(X_tab), 3))\n",
        "oof_lstm = np.zeros((len(X_tab), 3))\n",
        "oof_xgb = np.zeros((len(X_tab), 3))\n",
        "\n",
        "# ==== Ensure tabular and sequence data match in length ====\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_all_mapped))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_all_mapped_aligned = y_all_mapped.iloc[:min_len]\n",
        "y_all_oh_aligned = y_all_oh[:min_len]\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_all_mapped_aligned.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BstRtL0ehVta",
        "outputId": "da02325f-20d9-4690-bea5-076f1a0ccfee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(17607, 26), seq=(17607, 24, 26), y=(17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    cnn_model = build_cnn_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3NN2CkhDvJ",
        "outputId": "c55e4224-c655-4b8a-dcf0-3a0117e8f786"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating CNN OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    lstm_model = build_lstm_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUIXAYdhGJ4",
        "outputId": "33d73308-fdfa-4305-e8f2-87fc9d7f4d68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating LSTM OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Tabular split\n",
        "    X_tr_tab, X_va_tab = X_tab_aligned[train_idx], X_tab_aligned[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_all_mapped_aligned.iloc[train_idx], y_all_mapped_aligned.iloc[val_idx]\n",
        "\n",
        "    # Build with best parameters\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        num_class=3,\n",
        "        max_depth=3,\n",
        "        learning_rate=0.02845916357450999,\n",
        "        subsample=0.7552507762672391,\n",
        "        colsample_bytree=0.6666641910069,\n",
        "        gamma=4.394916003559231,\n",
        "        min_child_weight=5,\n",
        "        reg_alpha=0.5856294446650139,\n",
        "        reg_lambda=1.838450350300456,\n",
        "        n_estimators=300,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_clf.fit(X_tr_tab, y_tr_tab)\n",
        "\n",
        "    # Predict\n",
        "    oof_xgb[val_idx] = xgb_clf.predict_proba(X_va_tab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlbAkv81hL4f",
        "outputId": "263bbe18-1b8c-4562-a489-ab329c386d11"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating XGB OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack all model predictions for meta-learner\n",
        "meta_X_train = np.hstack([oof_cnn, oof_lstm, oof_xgb])\n",
        "meta_y_train = y_all_mapped.values  # already mapped to (0,1,2)\n",
        "\n",
        "print(\"✅ OOF generation complete!\")\n",
        "print(\"Meta-train shape:\", meta_X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oypZH8ABhQFk",
        "outputId": "a165024e-8e83-41b9-9aa0-0d219041f5b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OOF generation complete!\n",
            "Meta-train shape: (25188, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# Save OOF predictions and labels\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_all_mapped.values\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5i8N1lJps85",
        "outputId": "c5a7030b-f982-4ffd-8724-58810e79f85c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 OOF predictions saved to oof_preds.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# META LEARNER"
      ],
      "metadata": {
        "id": "IhKOAKMNxrMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A — Load OOF predictions and align\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "# Try to load previously saved OOF predictions. If you already have them in memory,\n",
        "# replace this with the arrays directly (oof_cnn, oof_lstm, oof_xgb, y).\n",
        "oof_path = \"oof_preds.pkl\"\n",
        "obj = joblib.load(oof_path)  # expects dict with \"oof_cnn\",\"oof_lstm\",\"oof_xgb\",\"y\"\n",
        "\n",
        "oof_cnn = obj[\"oof_cnn\"]    # shape (n_samples, 3)\n",
        "oof_lstm = obj[\"oof_lstm\"]\n",
        "oof_xgb = obj[\"oof_xgb\"]\n",
        "y_raw   = obj[\"y\"]          # ground-truth labels used during OOF (mapped 0/1/2 or original)\n",
        "\n",
        "# Make numpy arrays and check sizes\n",
        "oof_cnn = np.asarray(oof_cnn)\n",
        "oof_lstm = np.asarray(oof_lstm)\n",
        "oof_xgb = np.asarray(oof_xgb)\n",
        "y_raw = np.asarray(y_raw).ravel()\n",
        "\n",
        "print(\"Shapes:\", oof_cnn.shape, oof_lstm.shape, oof_xgb.shape, y_raw.shape)\n",
        "\n",
        "# Basic sanity checks\n",
        "n = len(y_raw)\n",
        "assert oof_cnn.shape[0] == n and oof_lstm.shape[0] == n and oof_xgb.shape[0] == n, \"OOF arrays must align with labels\"\n",
        "\n",
        "# If your y is in -1/0/1 mapping, map to 0/1/2 (consistent)\n",
        "# Detect automatically if values are -1/0/1 and map to 0/1/2\n",
        "if set(np.unique(y_raw)).issuperset({-1,0,1}) and set(np.unique(y_raw)).difference({-1,0,1})==set():\n",
        "    print(\"Detected labels in {-1,0,1} — remapping to {0,1,2}\")\n",
        "    map_arr = np.array([0 if v==-1 else (1 if v==0 else 2) for v in y_raw])\n",
        "    y = map_arr\n",
        "else:\n",
        "    # assume already 0/1/2\n",
        "    y = y_raw.copy()\n",
        "\n",
        "# Confirm class distribution\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"Label distribution (mapped):\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UY6W_zKg-fS",
        "outputId": "7343297f-9c8e-45e8-d3b4-54a738f0ed1b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (25188, 3) (25188, 3) (25188, 3) (25188,)\n",
            "Label distribution (mapped): {np.int64(0): np.int64(5522), np.int64(1): np.int64(13470), np.int64(2): np.int64(6196)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — meta-features construction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model probabilities as features\n",
        "meta_probs = np.hstack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 9)\n",
        "\n",
        "# Add engineered meta-features derived from base model outputs:\n",
        "# - per-sample mean/std/max/min across base model probs\n",
        "# - disagreements (max prob - 2nd max prob) for confidence\n",
        "def meta_stats_from_probs(probs_block):\n",
        "    # probs_block shape (n, n_models * n_classes)\n",
        "    n_classes = 3\n",
        "    n_models = probs_block.shape[1] // n_classes\n",
        "    block = probs_block.reshape(len(probs_block), n_models, n_classes)\n",
        "    # per model best class prob and best class\n",
        "    best_probs = block.max(axis=2)                 # (n, n_models)\n",
        "    best_classes = block.argmax(axis=2)             # (n, n_models)\n",
        "    # statistics across models on best_probs\n",
        "    mean_best = best_probs.mean(axis=1)\n",
        "    std_best = best_probs.std(axis=1)\n",
        "    max_best = best_probs.max(axis=1)\n",
        "    min_best = best_probs.min(axis=1)\n",
        "    # disagreement: how many models agree with majority class\n",
        "    from scipy.stats import mode\n",
        "    mode_vals, mode_counts = mode(best_classes, axis=1)\n",
        "    agree_fraction = (mode_counts.ravel() / n_models)\n",
        "    # confidence gap: top prob - second top prob per model averaged\n",
        "    def gap_per_row(row_block):\n",
        "        # row_block shape (n_models, n_classes)\n",
        "        gaps = []\n",
        "        for m in range(row_block.shape[0]):\n",
        "            arr = np.sort(row_block[m])[::-1]\n",
        "            gaps.append(arr[0] - (arr[1] if arr.shape[0] > 1 else 0.0))\n",
        "        return np.mean(gaps)\n",
        "    gap = np.array([gap_per_row(row) for row in block])\n",
        "\n",
        "    stats = np.vstack([mean_best, std_best, max_best, min_best, agree_fraction, gap]).T\n",
        "    stats_cols = [\"mean_best_prob\", \"std_best_prob\", \"max_best_prob\", \"min_best_prob\", \"agree_frac\", \"avg_top_gap\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_probs(meta_probs)\n",
        "\n",
        "# Optionally add a few simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# For now, we'll build final meta_X from probs + stats\n",
        "meta_X = np.hstack([meta_probs, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_p{c}\" for c in range(3)] +\n",
        "    [f\"lstm_p{c}\" for c in range(3)] +\n",
        "    [f\"xgb_p{c}\" for c in range(3)] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F859Av3p0qf",
        "outputId": "d1076f89-2dba-48a6-9689-ad1a4f412af7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta X shape: (25188, 15)\n",
            "Feature names: ['cnn_p0', 'cnn_p1', 'cnn_p2', 'lstm_p0', 'lstm_p1', 'lstm_p2', 'xgb_p0', 'xgb_p1', 'xgb_p2', 'mean_best_prob', 'std_best_prob', 'max_best_prob', 'min_best_prob', 'agree_frac', 'avg_top_gap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — Enhanced Meta-Learner Training with TimeSeriesSplit CV and Calibration\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)  # silence early_stopping msg\n",
        "\n",
        "# ==== Config ====\n",
        "n_splits = 5\n",
        "random_state = 42\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Hyperparameter candidates — can be extended for full grid/random search\n",
        "param_grid = [\n",
        "    {\"max_iter\": 200, \"learning_rate\": 0.05, \"max_depth\": 6},\n",
        "    {\"max_iter\": 300, \"learning_rate\": 0.03, \"max_depth\": 8},\n",
        "    {\"max_iter\": 200, \"learning_rate\": 0.1,  \"max_depth\": 4},\n",
        "]\n",
        "\n",
        "best_cfg = None\n",
        "best_score = -1\n",
        "best_oof_probs = None\n",
        "\n",
        "print(\"=== Meta-Learner Training with TimeSeriesSplit ===\")\n",
        "for cfg in param_grid:\n",
        "    print(f\"\\nTesting config: {cfg}\")\n",
        "    cfg_val_probs = np.zeros((len(meta_X), 3))\n",
        "    fold_scores = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(meta_X), 1):\n",
        "        X_tr, X_va = meta_X[tr_idx], meta_X[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        # Class balancing\n",
        "        sample_weight = compute_sample_weight(class_weight=\"balanced\", y=y_tr)\n",
        "\n",
        "        # Train fold model\n",
        "        model = HistGradientBoostingClassifier(\n",
        "            **cfg, early_stopping=True, scoring=\"f1_macro\", random_state=random_state\n",
        "        )\n",
        "        model.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
        "\n",
        "        # Predict\n",
        "        probs = model.predict_proba(X_va)\n",
        "        cfg_val_probs[va_idx] = probs\n",
        "\n",
        "        preds = probs.argmax(axis=1)\n",
        "        f1 = f1_score(y_va, preds, average=\"macro\", zero_division=0)\n",
        "        fold_scores.append(f1)\n",
        "        print(f\"  Fold {fold}/{n_splits} — F1_macro: {f1:.4f}\")\n",
        "\n",
        "    mean_f1 = np.mean(fold_scores)\n",
        "    print(f\"  Mean F1_macro: {mean_f1:.4f}\")\n",
        "\n",
        "    # Track best config\n",
        "    if mean_f1 > best_score:\n",
        "        best_score = mean_f1\n",
        "        best_cfg = cfg\n",
        "        best_oof_probs = cfg_val_probs.copy()\n",
        "\n",
        "print(\"\\n=== Best Config ===\")\n",
        "print(best_cfg, \"with mean F1_macro:\", round(best_score, 4))\n",
        "\n",
        "# ==== Train final model ====\n",
        "print(\"\\nTraining final meta-learner on full data...\")\n",
        "sample_weight_full = compute_sample_weight(class_weight=\"balanced\", y=y)\n",
        "final_model = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=random_state)\n",
        "final_model.fit(meta_X, y, sample_weight=sample_weight_full)\n",
        "\n",
        "# ==== Calibrate with time-aware CV ====\n",
        "# We’ll use TimeSeriesSplit again for calibration instead of random CV\n",
        "print(\"Calibrating probabilities (sigmoid)...\")\n",
        "calibrated_models = []\n",
        "for tr_idx, va_idx in tscv.split(meta_X):\n",
        "    model_clone = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=random_state)\n",
        "    model_clone.fit(meta_X[tr_idx], y[tr_idx], sample_weight=compute_sample_weight(class_weight=\"balanced\", y=y[tr_idx]))\n",
        "    calibrator = CalibratedClassifierCV(model_clone, method=\"sigmoid\", cv=\"prefit\")\n",
        "    calibrator.fit(meta_X[va_idx], y[va_idx])\n",
        "    calibrated_models.append(calibrator)\n",
        "\n",
        "# Save both raw and calibrated versions\n",
        "joblib.dump({\n",
        "    \"meta_model\": final_model,\n",
        "    \"calibrators\": calibrated_models,\n",
        "    \"best_cfg\": best_cfg,\n",
        "    \"meta_feature_names\": meta_feature_names\n",
        "}, \"meta_model.pkl\")\n",
        "\n",
        "print(\"✅ Saved meta_model.pkl with best config and calibration.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJul1btp2JA",
        "outputId": "0431fdea-fdfe-4f64-b733-e842ed70ec12"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Meta-Learner Training with TimeSeriesSplit ===\n",
            "\n",
            "Testing config: {'max_iter': 200, 'learning_rate': 0.05, 'max_depth': 6}\n",
            "  Fold 1/5 — F1_macro: 0.1415\n",
            "  Fold 2/5 — F1_macro: 0.7609\n",
            "  Fold 3/5 — F1_macro: 0.7892\n",
            "  Fold 4/5 — F1_macro: 0.3063\n",
            "  Fold 5/5 — F1_macro: 0.2378\n",
            "  Mean F1_macro: 0.4472\n",
            "\n",
            "Testing config: {'max_iter': 300, 'learning_rate': 0.03, 'max_depth': 8}\n",
            "  Fold 1/5 — F1_macro: 0.1415\n",
            "  Fold 2/5 — F1_macro: 0.7512\n",
            "  Fold 3/5 — F1_macro: 0.7888\n",
            "  Fold 4/5 — F1_macro: 0.3074\n",
            "  Fold 5/5 — F1_macro: 0.2378\n",
            "  Mean F1_macro: 0.4453\n",
            "\n",
            "Testing config: {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
            "  Fold 1/5 — F1_macro: 0.1415\n",
            "  Fold 2/5 — F1_macro: 0.7493\n",
            "  Fold 3/5 — F1_macro: 0.7938\n",
            "  Fold 4/5 — F1_macro: 0.3083\n",
            "  Fold 5/5 — F1_macro: 0.2378\n",
            "  Mean F1_macro: 0.4461\n",
            "\n",
            "=== Best Config ===\n",
            "{'max_iter': 200, 'learning_rate': 0.05, 'max_depth': 6} with mean F1_macro: 0.4472\n",
            "\n",
            "Training final meta-learner on full data...\n",
            "Calibrating probabilities (sigmoid)...\n",
            "✅ Saved meta_model.pkl with best config and calibration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D — Load Meta-Learner and Predict\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# ==== Load saved meta-model ====\n",
        "obj = joblib.load(\"meta_model.pkl\")\n",
        "\n",
        "# ==== Get features (replace with your actual prepared features) ====\n",
        "# meta_X should already be prepared with the same preprocessing as during training\n",
        "# y is the true labels (optional if you're only predicting)\n",
        "# Example:\n",
        "# meta_X = ...\n",
        "# y = ...\n",
        "\n",
        "# ==== Predict probabilities ====\n",
        "if \"calibrators\" in obj and obj[\"calibrators\"]:\n",
        "    # Average predictions from calibrated models\n",
        "    print(\"Using calibrated models...\")\n",
        "    calibrators = obj[\"calibrators\"]\n",
        "    probs_list = [cal.predict_proba(meta_X) for cal in calibrators]\n",
        "    probs = np.mean(probs_list, axis=0)\n",
        "else:\n",
        "    # Fall back to raw meta-model\n",
        "    print(\"Using raw meta-model...\")\n",
        "    probs = obj[\"meta_model\"].predict_proba(meta_X)\n",
        "\n",
        "# ==== Get predicted classes ====\n",
        "preds = probs.argmax(axis=1)\n",
        "\n",
        "# ==== If you want metrics ====\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "if 'y' in locals():\n",
        "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
        "    print(\"F1_macro:\", f1_score(y, preds, average=\"macro\", zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSvckCSp8Mr",
        "outputId": "5b32ecfa-258e-4ab9-bc24-a09d8533cc25"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using calibrated models...\n",
            "Accuracy: 0.683023662061299\n",
            "F1_macro: 0.5938662715673404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "X1nvP47MjnKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "5nGTwsv4qpi6",
        "outputId": "bb47f85a-f320-4a00-ea1c-c8cbf587b18d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['meta_learner.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TdtsuwkPaxcH",
        "outputId": "b34ba46c-7997-4391-85ae-3b1be04bea8c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a3e3902b-4a27-4858-88ba-19d09935b065\", \"meta_learner.pkl\", 699848)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}