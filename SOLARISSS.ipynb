{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris/blob/main/SOLARISSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Libraries"
      ],
      "metadata": {
        "id": "XUR0zNCpOy7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "dfbd620a-53d7-47e6-c973-9062a75679c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "3hev1JrVPjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\"AAPL\", \"SPY\", \"TSLA\", \"NVDA\", \"QQQ\"]  # note: ^VIX for Yahoo\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "a8d4f0a4-dfb5-4e1c-fca9-4c03962c764e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-09-19 13:30:00 to 2025-08-14 19:30:00\n",
            "SPY: 5075 rows from 2022-09-19 13:30:00 to 2025-08-14 19:30:00\n",
            "TSLA: 5075 rows from 2022-09-19 13:30:00 to 2025-08-14 19:30:00\n",
            "NVDA: 5075 rows from 2022-09-19 13:30:00 to 2025-08-14 19:30:00\n",
            "QQQ: 5075 rows from 2022-09-19 13:30:00 to 2025-08-14 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL         SPY        TSLA        NVDA  \\\n",
            "Datetime                                                              \n",
            "2025-08-14 15:30:00  232.009995  643.090027  331.406708  181.143494   \n",
            "2025-08-14 16:30:00  232.927307  645.000671  333.962708  182.164993   \n",
            "2025-08-14 17:30:00  232.729996  644.085022  332.970001  181.524994   \n",
            "2025-08-14 18:30:00  232.945007  645.030029  334.369995  181.960007   \n",
            "2025-08-14 19:30:00  232.830002  644.940002  335.570007  182.000000   \n",
            "\n",
            "                            QQQ  \n",
            "Datetime                         \n",
            "2025-08-14 15:30:00  578.950012  \n",
            "2025-08-14 16:30:00  581.169983  \n",
            "2025-08-14 17:30:00  579.375000  \n",
            "2025-08-14 18:30:00  579.989990  \n",
            "2025-08-14 19:30:00  579.869995  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Creation"
      ],
      "metadata": {
        "id": "jLnkdkzRRvVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Features"
      ],
      "metadata": {
        "id": "omLPzq5TDwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    macd = ta.trend.MACD(price_series)\n",
        "    feat_tmp[\"macd\"] = macd.macd()\n",
        "    feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"SPY\", \"QQQ\", \"NVDA\"]:\n",
        "        if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    if \"^VIX\" in aligned_ffill.columns:\n",
        "        feat_tmp[\"vix_ret_1h\"] = aligned_ffill[\"^VIX\"].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    feat_tmp = feat_tmp.dropna(subset=[col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]])\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = ticker\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())\n"
      ],
      "metadata": {
        "id": "MFIHXqY5R2fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57526c2f-4cc1-420a-93b7-b3ad52c520a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created features for 5 tickers\n",
            "Shape: (25210, 26)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.003686  0.001806 -0.019188 -0.017386 -0.047719  0.006357  0.006648   \n",
            "1  0.004941  0.005536  0.000466 -0.004695 -0.035440  0.003717  0.006550   \n",
            "2  0.020446  0.029267  0.023574  0.010223 -0.016853  0.008810  0.008808   \n",
            "3 -0.012190  0.012987  0.014816 -0.004535 -0.033662  0.010752  0.009553   \n",
            "4 -0.005588  0.002373  0.007923 -0.008105 -0.038450  0.011262  0.009665   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...      ema_20  vol_change_1h  \\\n",
            "0  0.006764  37.061693 -1.187992  ...  151.946558       0.316526   \n",
            "1  0.006788  41.472095 -1.145950  ...  151.809742       0.027499   \n",
            "2  0.008124  55.452386 -0.854469  ...  151.979033       1.025282   \n",
            "3  0.008357  47.948022 -0.765720  ...  151.953887      -0.471326   \n",
            "4  0.008398  44.979708 -0.755092  ...  151.850393      -0.057154   \n",
            "\n",
            "     vol_ma_24h  SPY_ret_1h  QQQ_ret_1h  NVDA_ret_1h  hour  day_of_week  \\\n",
            "0  1.242050e+07    0.003865    0.003293     0.007870    18            4   \n",
            "1  1.241664e+07    0.004669    0.004851     0.007567    19            4   \n",
            "2  1.289230e+07    0.005137    0.013048     0.006152    13            0   \n",
            "3  1.289168e+07   -0.010505   -0.012611    -0.018580    14            0   \n",
            "4  1.290172e+07   -0.003471   -0.004263    -0.005097    15            0   \n",
            "\n",
            "             datetime  ticker  \n",
            "0 2022-09-23 18:30:00    AAPL  \n",
            "1 2022-09-23 19:30:00    AAPL  \n",
            "2 2022-09-26 13:30:00    AAPL  \n",
            "3 2022-09-26 14:30:00    AAPL  \n",
            "4 2022-09-26 15:30:00    AAPL  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation"
      ],
      "metadata": {
        "id": "TKZHysWZZsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "vol_lookback = 24         # hours to compute rolling volatility\n",
        "vol_multiplier = 0.5      # threshold scaling vs volatility\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Volatility-based threshold\n",
        "    rolling_vol = price_series.pct_change().rolling(vol_lookback).std()\n",
        "    threshold = rolling_vol * vol_multiplier\n",
        "\n",
        "    # Label creation\n",
        "    label = future_ret.copy()\n",
        "    label[future_ret > threshold] = 1    # Up\n",
        "    label[future_ret < -threshold] = -1  # Down\n",
        "    label[(future_ret <= threshold) & (future_ret >= -threshold)] = 0  # Neutral\n",
        "\n",
        "    # Drop NaNs\n",
        "    label = label.dropna()\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": label.index,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[label.index],\n",
        "        \"label\": label.values,\n",
        "        \"future_ret\": future_ret.loc[label.index],\n",
        "        \"volatility\": rolling_vol.loc[label.index]\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "print(labels_df[\"label\"].value_counts(normalize=True))\n",
        "labels_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "00704ddc-3bbf-4207-ac43-32105e916aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (25370, 6)\n",
            "label\n",
            " 0.000000    0.532795\n",
            " 1.000000    0.245132\n",
            "-1.000000    0.217343\n",
            "-0.002381    0.000039\n",
            " 0.007971    0.000039\n",
            "               ...   \n",
            "-0.012474    0.000039\n",
            "-0.008574    0.000039\n",
            "-0.005088    0.000039\n",
            " 0.002861    0.000039\n",
            "-0.000553    0.000039\n",
            "Name: proportion, Length: 123, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime ticker       price     label  future_ret  volatility\n",
              "0 2022-09-19 13:30:00   AAPL  151.220001  0.005026    0.005026         NaN\n",
              "1 2022-09-19 14:30:00   AAPL  151.979996  0.002166    0.002166         NaN\n",
              "2 2022-09-19 15:30:00   AAPL  152.309204  0.006407    0.006407         NaN\n",
              "3 2022-09-19 16:30:00   AAPL  153.285004 -0.002381   -0.002381         NaN\n",
              "4 2022-09-19 17:30:00   AAPL  152.919998  0.007971    0.007971         NaN\n",
              "5 2022-09-19 18:30:00   AAPL  154.138901  0.002602    0.002602         NaN\n",
              "6 2022-09-19 19:30:00   AAPL  154.539993  0.001715    0.001715         NaN\n",
              "7 2022-09-20 13:30:00   AAPL  154.804993  0.011595    0.011595         NaN\n",
              "8 2022-09-20 14:30:00   AAPL  156.600006  0.004310    0.004310         NaN\n",
              "9 2022-09-20 15:30:00   AAPL  157.274994 -0.007852   -0.007852         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2da82c8-b772-4dac-a7d9-557d1b3c9d68\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>label</th>\n",
              "      <th>future_ret</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-19 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>151.220001</td>\n",
              "      <td>0.005026</td>\n",
              "      <td>0.005026</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-19 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>151.979996</td>\n",
              "      <td>0.002166</td>\n",
              "      <td>0.002166</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-19 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.309204</td>\n",
              "      <td>0.006407</td>\n",
              "      <td>0.006407</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-19 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.285004</td>\n",
              "      <td>-0.002381</td>\n",
              "      <td>-0.002381</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-19 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.919998</td>\n",
              "      <td>0.007971</td>\n",
              "      <td>0.007971</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-19 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.138901</td>\n",
              "      <td>0.002602</td>\n",
              "      <td>0.002602</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-19 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.539993</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-20 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.804993</td>\n",
              "      <td>0.011595</td>\n",
              "      <td>0.011595</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-09-20 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.600006</td>\n",
              "      <td>0.004310</td>\n",
              "      <td>0.004310</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-09-20 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.274994</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2da82c8-b772-4dac-a7d9-557d1b3c9d68')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2da82c8-b772-4dac-a7d9-557d1b3c9d68 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2da82c8-b772-4dac-a7d9-557d1b3c9d68');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25140612-83d2-494a-a02e-ea3fbe1054c0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25140612-83d2-494a-a02e-ea3fbe1054c0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25140612-83d2-494a-a02e-ea3fbe1054c0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 25370,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-19 13:30:00\",\n        \"max\": \"2025-08-14 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-09-14 14:30:00\",\n          \"2024-03-25 19:30:00\",\n          \"2022-09-23 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SPY\",\n          \"QQQ\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 165.32831435265314,\n        \"min\": 11.14999008178711,\n        \"max\": 645.030029296875,\n        \"num_unique_values\": 23052,\n        \"samples\": [\n          239.5800018310547,\n          480.0101013183594,\n          194.9080047607422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6795012585817204,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          0.003926530436366094,\n          -0.0006547931063202721,\n          -0.004610669822766942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009386619910488633,\n        \"min\": -0.13022686951739132,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          0.002014119220573458,\n          0.01151780360798585,\n          -0.002324266810067602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0055382303958601345,\n        \"min\": 0.0008914795917642343,\n        \"max\": 0.05414076773543391,\n        \"num_unique_values\": 25250,\n        \"samples\": [\n          0.015424837362076355,\n          0.003316791588976029,\n          0.002571113424960627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "rieWxNf5Mp44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1H-ATXHjSK6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Features"
      ],
      "metadata": {
        "id": "_PxZH38IebtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & labels\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y distribution:\\n\", y.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "OERLO3TNed16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dea936a-81e3-4184-bd2c-ecf4a9b8d2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25205, 26)\n",
            "y distribution:\n",
            " label\n",
            " 0.0    0.535489\n",
            " 1.0    0.246380\n",
            "-1.0    0.218131\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale"
      ],
      "metadata": {
        "id": "rpnDnFsiWa87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Label distribution in Train:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "4oxCtsXaSTrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fb6099-0e84-4bbc-d984-e5b3dcbd48b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train: (17631, 26), Val: (3778, 26), Test: (3779, 26)\n",
            "Label distribution in Train: label\n",
            " 0.0    0.525438\n",
            " 1.0    0.252680\n",
            "-1.0    0.221882\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence making - For LSTM AND CNN"
      ],
      "metadata": {
        "id": "euQxLDkaWdBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 24  # last 24 hours to predict next hour\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "id": "mn5XIK9DWlAN",
        "outputId": "c1cca580-48bd-4a8a-8cb0-3ca2768a68f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (17607, 24, 26), Val seq: (3754, 24, 26), Test seq: (3755, 24, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 — label encoding + class weights\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# mapping: -1 -> 0 (down), 0 -> 1 (neutral), 1 -> 2 (up)\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "\n",
        "# If your y_* are numpy arrays (seq labels), convert\n",
        "y_train_seq_mapped = np.vectorize(label_map.get)(y_train_seq)\n",
        "y_val_seq_mapped   = np.vectorize(label_map.get)(y_val_seq)\n",
        "y_test_seq_mapped  = np.vectorize(label_map.get)(y_test_seq)\n",
        "\n",
        "# one-hot for Keras\n",
        "y_train_cat = to_categorical(y_train_seq_mapped, num_classes=3)\n",
        "y_val_cat   = to_categorical(y_val_seq_mapped, num_classes=3)\n",
        "y_test_cat  = to_categorical(y_test_seq_mapped, num_classes=3)\n",
        "\n",
        "# compute class weights from training sequence labels\n",
        "classes = np.unique(y_train_seq_mapped)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_seq_mapped)\n",
        "class_weights_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "print(\"Train class distribution:\", np.bincount(y_train_seq_mapped) / len(y_train_seq_mapped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "3b45c9c0-9cb5-43fe-f136-e6444c647d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.5033299180327868), 1: np.float64(0.6340066976342228), 2: np.float64(1.3200629779577149)}\n",
            "Train class distribution: [0.22172999 0.5257568  0.2525132 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1jUYMhA9cSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, BatchNormalization, Activation, Dropout, SpatialDropout1D,\n",
        "    GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Add, Multiply, Concatenate\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# try to use AdamW (TF nightly / TF >=2.11 has experimental AdamW); fallback to classic Adam\n",
        "try:\n",
        "    from tensorflow.keras.optimizers import experimental as exp_optimizers\n",
        "    AdamW = exp_optimizers.AdamW\n",
        "    use_adamw = True\n",
        "except Exception:\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    AdamW = None\n",
        "    use_adamw = False\n",
        "\n",
        "def se_block(x, reduction=8):\n",
        "    \"\"\"Squeeze-and-Excitation block.\"\"\"\n",
        "    channels = int(x.shape[-1])\n",
        "    se = GlobalAveragePooling1D()(x)\n",
        "    se = tf.keras.layers.Dense(channels // reduction, activation='relu', kernel_initializer='he_normal')(se)\n",
        "    se = tf.keras.layers.Dense(channels, activation='sigmoid', kernel_initializer='he_normal')(se)\n",
        "    se = tf.keras.layers.Reshape((1, channels))(se)\n",
        "    return Multiply()([x, se])\n",
        "\n",
        "def residual_block(x, filters, kernel_size, dropout_rate=0.2, weight_decay=1e-4):\n",
        "    shortcut = x\n",
        "    # projection if channels mismatch\n",
        "    if x.shape[-1] != filters:\n",
        "        shortcut = Conv1D(filters, kernel_size=1, padding='same',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          kernel_regularizer=l2(weight_decay))(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same',\n",
        "               kernel_initializer='he_normal',\n",
        "               kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # spatial dropout is preferable for time-series channels\n",
        "    x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same',\n",
        "               kernel_initializer='he_normal',\n",
        "               kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_cnn_enhanced(input_shape, n_classes=3, dropout_rate=0.25, weight_decay=1e-4):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # optionally normalize channels at input\n",
        "    x = BatchNormalization()(inp)\n",
        "\n",
        "    # initial conv\n",
        "    x = Conv1D(64, kernel_size=3, padding='same',\n",
        "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # residual blocks (reduce complexity growth if dataset small)\n",
        "    x = residual_block(x, 64, 3, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "    x = residual_block(x, 128, 5, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "    x = residual_block(x, 256, 3, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # attention\n",
        "    x = se_block(x, reduction=8)\n",
        "\n",
        "    # pooling combination\n",
        "    gap = GlobalAveragePooling1D()(x)\n",
        "    gmp = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([gap, gmp])  # combined representation\n",
        "\n",
        "    x = Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "\n",
        "    # optimizer: try AdamW if available, otherwise Adam with weight decay via L2 above\n",
        "    if use_adamw and AdamW is not None:\n",
        "        opt = AdamW(learning_rate=1e-3, weight_decay=1e-5)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Build model (example)\n",
        "cnn_model = build_cnn_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25, weight_decay=1e-4)\n",
        "cnn_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "2mDqNrx0SddA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97957b50-b83d-4fbb-e8c8-42debe348421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │        \u001b[38;5;34m104\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m5,056\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m82,048\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m8,224\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m8,448\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m676,427\u001b[0m (2.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">676,427</span> (2.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m673,687\u001b[0m (2.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">673,687</span> (2.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,740\u001b[0m (10.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,740</span> (10.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "-p_nIYgVcWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, Bidirectional, LSTM, GRU, Dense, Dropout,\n",
        "    LayerNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
        "    Concatenate, Attention\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_lstm_enhanced(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = LayerNormalization()(inp)\n",
        "\n",
        "    # First BiLSTM layer\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Second BiGRU layer (faster and adds diversity in sequence modeling)\n",
        "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Self-Attention layer\n",
        "    attn_data = Attention()([x, x])\n",
        "    x = Concatenate()([x, attn_data])  # fuse original and attention output\n",
        "\n",
        "    # Pooling\n",
        "    x_avg = GlobalAveragePooling1D()(x)\n",
        "    x_max = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([x_avg, x_max])\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate model\n",
        "lstm_model = build_lstm_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "id": "IYtsddwpfp1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "32d9377e-acb4-4085-990d-d5a14fb9b15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │         \u001b[38;5;34m52\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m158,720\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m123,648\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,720</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "7FalnDi8fxYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---- Map labels safely to integers 0,1,2 ----\n",
        "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
        "# if y_train etc are pandas Series this is robust:\n",
        "y_train_tab = pd.Series(y_train).map(label_map).astype('int').to_numpy()\n",
        "y_val_tab   = pd.Series(y_val).map(label_map).astype('int').to_numpy()\n",
        "y_test_tab  = pd.Series(y_test).map(label_map).astype('int').to_numpy()\n",
        "\n",
        "# ---- Per-sample balanced weights (recommended for multiclass) ----\n",
        "sample_weight_train = compute_sample_weight('balanced', y_train_tab)\n",
        "# sample_weight_train is length n_train; pass it into .fit(..., sample_weight=...)\n",
        "\n",
        "# ---- Defensive: compute per-class counts (avoid division by zero) ----\n",
        "class_counts = np.bincount(y_train_tab, minlength=3)\n",
        "total = len(y_train_tab)\n",
        "n_classes = len(class_counts)\n",
        "per_class_scale = np.where(class_counts == 0, 0.0, total / (n_classes * class_counts))\n",
        "print(\"class_counts:\", class_counts, \"per_class_scale:\", per_class_scale)\n",
        "\n",
        "# If you prefer per-sample weights from per_class_scale:\n",
        "sample_weight_from_scale = np.array([per_class_scale[c] for c in y_train_tab])\n",
        "\n",
        "# ---- XGBoost classifier (multi-class) ----\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',    # multiclass probability output\n",
        "    num_class=3,                   # explicit number of classes (safe to include)\n",
        "    n_estimators=1000,             # set high + use early stopping\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    gamma=1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',            # 'gpu_hist' if you have GPU\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "EjSEPd16f61x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d01b5e-5836-4a9b-b242-1286037891b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_counts: [3912 9264 4455] per_class_scale: [1.50230061 0.63439119 1.31919192]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "TKR7NlqVaq34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cOvOaClz5nPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if supported\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile with lower LR initially for stability\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_cnn_full_model.keras',  # save full model, not just weights\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/cnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "abb563c5-30bb-4078-eb2d-b65be79a76dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.36950, saving model to best_cnn_full_model.keras\n",
            "138/138 - 71s - 512ms/step - accuracy: 0.3521 - loss: 1.4988 - val_accuracy: 0.5517 - val_loss: 1.3695 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss did not improve from 1.36950\n",
            "138/138 - 80s - 579ms/step - accuracy: 0.3604 - loss: 1.4345 - val_accuracy: 0.4939 - val_loss: 1.3912 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.36950\n",
            "138/138 - 80s - 577ms/step - accuracy: 0.3909 - loss: 1.4166 - val_accuracy: 0.4659 - val_loss: 1.3985 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 1.36950 to 1.36318, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 588ms/step - accuracy: 0.4269 - loss: 1.4009 - val_accuracy: 0.5061 - val_loss: 1.3632 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.36318\n",
            "138/138 - 83s - 602ms/step - accuracy: 0.4274 - loss: 1.3909 - val_accuracy: 0.4776 - val_loss: 1.3676 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.36318\n",
            "138/138 - 81s - 584ms/step - accuracy: 0.4458 - loss: 1.3769 - val_accuracy: 0.4473 - val_loss: 1.3745 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 1.36318 to 1.34550, saving model to best_cnn_full_model.keras\n",
            "138/138 - 41s - 297ms/step - accuracy: 0.4535 - loss: 1.3624 - val_accuracy: 0.4739 - val_loss: 1.3455 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 1.34550 to 1.33549, saving model to best_cnn_full_model.keras\n",
            "138/138 - 42s - 305ms/step - accuracy: 0.4542 - loss: 1.3485 - val_accuracy: 0.4798 - val_loss: 1.3355 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 1.33549 to 1.31400, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 589ms/step - accuracy: 0.4672 - loss: 1.3313 - val_accuracy: 0.4595 - val_loss: 1.3140 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 1.31400 to 1.30744, saving model to best_cnn_full_model.keras\n",
            "138/138 - 83s - 599ms/step - accuracy: 0.4733 - loss: 1.3166 - val_accuracy: 0.4678 - val_loss: 1.3074 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.30744\n",
            "138/138 - 41s - 295ms/step - accuracy: 0.4842 - loss: 1.3030 - val_accuracy: 0.4798 - val_loss: 1.3082 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 1.30744 to 1.29746, saving model to best_cnn_full_model.keras\n",
            "138/138 - 43s - 309ms/step - accuracy: 0.4929 - loss: 1.2858 - val_accuracy: 0.4739 - val_loss: 1.2975 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss improved from 1.29746 to 1.27616, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 588ms/step - accuracy: 0.4930 - loss: 1.2705 - val_accuracy: 0.4694 - val_loss: 1.2762 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.27616\n",
            "138/138 - 42s - 304ms/step - accuracy: 0.4989 - loss: 1.2552 - val_accuracy: 0.4523 - val_loss: 1.2970 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss improved from 1.27616 to 1.26600, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 585ms/step - accuracy: 0.5074 - loss: 1.2366 - val_accuracy: 0.4784 - val_loss: 1.2660 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.26600\n",
            "138/138 - 42s - 303ms/step - accuracy: 0.5070 - loss: 1.2207 - val_accuracy: 0.4294 - val_loss: 1.2871 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss improved from 1.26600 to 1.24405, saving model to best_cnn_full_model.keras\n",
            "138/138 - 42s - 305ms/step - accuracy: 0.5200 - loss: 1.2009 - val_accuracy: 0.4787 - val_loss: 1.2441 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss did not improve from 1.24405\n",
            "138/138 - 42s - 305ms/step - accuracy: 0.5229 - loss: 1.1798 - val_accuracy: 0.4193 - val_loss: 1.2964 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.24405\n",
            "138/138 - 41s - 296ms/step - accuracy: 0.5372 - loss: 1.1599 - val_accuracy: 0.4470 - val_loss: 1.2846 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.24405\n",
            "138/138 - 41s - 295ms/step - accuracy: 0.5399 - loss: 1.1409 - val_accuracy: 0.3910 - val_loss: 1.3375 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.24405\n",
            "138/138 - 43s - 311ms/step - accuracy: 0.5539 - loss: 1.1167 - val_accuracy: 0.3732 - val_loss: 1.3500 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 1.24405\n",
            "138/138 - 43s - 309ms/step - accuracy: 0.5758 - loss: 1.0746 - val_accuracy: 0.4225 - val_loss: 1.3048 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.24405\n",
            "138/138 - 42s - 306ms/step - accuracy: 0.5893 - loss: 1.0460 - val_accuracy: 0.3876 - val_loss: 1.3699 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.24405\n",
            "138/138 - 81s - 586ms/step - accuracy: 0.5921 - loss: 1.0258 - val_accuracy: 0.3897 - val_loss: 1.3862 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 1.24405\n",
            "138/138 - 86s - 620ms/step - accuracy: 0.6041 - loss: 1.0068 - val_accuracy: 0.3831 - val_loss: 1.4229 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_loss did not improve from 1.24405\n",
            "138/138 - 78s - 565ms/step - accuracy: 0.6257 - loss: 0.9685 - val_accuracy: 0.4017 - val_loss: 1.4443 - learning_rate: 1.2500e-04\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_loss did not improve from 1.24405\n",
            "138/138 - 42s - 307ms/step - accuracy: 0.6336 - loss: 0.9540 - val_accuracy: 0.3852 - val_loss: 1.4511 - learning_rate: 1.2500e-04\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yxu1niZ7gq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if GPU supports it (LSTMs benefit less than CNNs, but still good for speed)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile LSTM with gradient clipping (helps with exploding gradients in RNNs)\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_lstm_full_model.keras',  # Save entire model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/lstm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=120,  # Give it more room to converge\n",
        "    batch_size=96,  # Smaller batch size often helps LSTM generalization\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "93a8052e-5540-42e1-9e26-f45c294cee8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.08111, saving model to best_lstm_full_model.keras\n",
            "184/184 - 50s - 270ms/step - accuracy: 0.4008 - loss: 1.0909 - val_accuracy: 0.4001 - val_loss: 1.0811 - learning_rate: 3.0000e-04\n",
            "Epoch 2/120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 1.08111\n",
            "184/184 - 39s - 210ms/step - accuracy: 0.4335 - loss: 1.0765 - val_accuracy: 0.3775 - val_loss: 1.0885 - learning_rate: 3.0000e-04\n",
            "Epoch 3/120\n",
            "\n",
            "Epoch 3: val_loss improved from 1.08111 to 1.06926, saving model to best_lstm_full_model.keras\n",
            "184/184 - 42s - 226ms/step - accuracy: 0.4492 - loss: 1.0691 - val_accuracy: 0.4395 - val_loss: 1.0693 - learning_rate: 3.0000e-04\n",
            "Epoch 4/120\n",
            "\n",
            "Epoch 4: val_loss improved from 1.06926 to 1.06344, saving model to best_lstm_full_model.keras\n",
            "184/184 - 41s - 221ms/step - accuracy: 0.4567 - loss: 1.0615 - val_accuracy: 0.4518 - val_loss: 1.0634 - learning_rate: 3.0000e-04\n",
            "Epoch 5/120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.06344\n",
            "184/184 - 42s - 229ms/step - accuracy: 0.4670 - loss: 1.0517 - val_accuracy: 0.4433 - val_loss: 1.0809 - learning_rate: 3.0000e-04\n",
            "Epoch 6/120\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.06344\n",
            "184/184 - 40s - 216ms/step - accuracy: 0.4761 - loss: 1.0455 - val_accuracy: 0.4177 - val_loss: 1.0926 - learning_rate: 3.0000e-04\n",
            "Epoch 7/120\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.06344\n",
            "184/184 - 41s - 221ms/step - accuracy: 0.4817 - loss: 1.0330 - val_accuracy: 0.4302 - val_loss: 1.0916 - learning_rate: 3.0000e-04\n",
            "Epoch 8/120\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.06344\n",
            "184/184 - 41s - 220ms/step - accuracy: 0.4879 - loss: 1.0227 - val_accuracy: 0.4049 - val_loss: 1.0979 - learning_rate: 3.0000e-04\n",
            "Epoch 9/120\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.06344\n",
            "184/184 - 44s - 238ms/step - accuracy: 0.5089 - loss: 1.0001 - val_accuracy: 0.3998 - val_loss: 1.1261 - learning_rate: 1.5000e-04\n",
            "Epoch 10/120\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.06344\n",
            "184/184 - 39s - 213ms/step - accuracy: 0.5128 - loss: 0.9867 - val_accuracy: 0.4057 - val_loss: 1.1158 - learning_rate: 1.5000e-04\n",
            "Epoch 11/120\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.06344\n",
            "184/184 - 41s - 223ms/step - accuracy: 0.5245 - loss: 0.9734 - val_accuracy: 0.3879 - val_loss: 1.1361 - learning_rate: 1.5000e-04\n",
            "Epoch 12/120\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.06344\n",
            "184/184 - 39s - 214ms/step - accuracy: 0.5298 - loss: 0.9596 - val_accuracy: 0.3788 - val_loss: 1.1504 - learning_rate: 1.5000e-04\n",
            "Epoch 13/120\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.06344\n",
            "184/184 - 41s - 223ms/step - accuracy: 0.5426 - loss: 0.9406 - val_accuracy: 0.3865 - val_loss: 1.1506 - learning_rate: 7.5000e-05\n",
            "Epoch 14/120\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.06344\n",
            "184/184 - 42s - 228ms/step - accuracy: 0.5466 - loss: 0.9291 - val_accuracy: 0.3713 - val_loss: 1.1747 - learning_rate: 7.5000e-05\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "2RHWbvELgyIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- ensure label mapping (same as before) ---\n",
        "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
        "y_train_tab = pd.Series(y_train).map(label_map).astype(int).to_numpy()\n",
        "y_val_tab   = pd.Series(y_val).map(label_map).astype(int).to_numpy()\n",
        "y_test_tab  = pd.Series(y_test).map(label_map).astype(int).to_numpy()\n",
        "\n",
        "# --- sample weights (multiclass) ---\n",
        "sw_train = compute_sample_weight(class_weight='balanced', y=y_train_tab)\n",
        "sw_val   = compute_sample_weight(class_weight='balanced', y=y_val_tab)\n",
        "\n",
        "# helper: robust predict that works across xgboost versions\n",
        "def predict_with_best(booster: xgb.Booster, dmatrix: xgb.DMatrix):\n",
        "    \"\"\"\n",
        "    Try several predict call styles in order:\n",
        "      1) predict(..., iteration_range=(0, best_iteration+1)) if best_iteration exists\n",
        "      2) predict(..., ntree_limit=best_ntree_limit) if supported\n",
        "      3) fallback: predict(dmatrix)\n",
        "    \"\"\"\n",
        "    # 1) iteration_range (newer interface)\n",
        "    try:\n",
        "        if hasattr(booster, \"best_iteration\") and booster.best_iteration is not None:\n",
        "            return booster.predict(dmatrix, iteration_range=(0, int(booster.best_iteration) + 1))\n",
        "    except TypeError:\n",
        "        # some versions may not accept iteration_range\n",
        "        pass\n",
        "    # 2) ntree_limit (older interface)\n",
        "    try:\n",
        "        if hasattr(booster, \"best_ntree_limit\") and booster.best_ntree_limit is not None:\n",
        "            return booster.predict(dmatrix, ntree_limit=int(booster.best_ntree_limit))\n",
        "    except TypeError:\n",
        "        pass\n",
        "    # 3) plain predict fallback\n",
        "    return booster.predict(dmatrix)\n",
        "\n",
        "# prepare DMatrix for validation & test once outside objective (weights included)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_tab, weight=sw_val)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "# Optuna objective (robust)\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 3,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'hist',\n",
        "        'seed': 42,\n",
        "        'verbosity': 0,\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),\n",
        "    }\n",
        "\n",
        "    # create DMatrix for the training fold (weights applied)\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train_tab, weight=sw_train)\n",
        "\n",
        "    try:\n",
        "        bst = xgb.train(\n",
        "            params,\n",
        "            dtrain,\n",
        "            num_boost_round=1500,\n",
        "            evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "            early_stopping_rounds=50,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "        # robust predict\n",
        "        preds = predict_with_best(bst, dval)\n",
        "        pred_labels = np.argmax(preds, axis=1)\n",
        "        acc = accuracy_score(y_val_tab, pred_labels)\n",
        "        # store best_iteration (useful later)\n",
        "        trial.set_user_attr(\"best_iteration\", getattr(bst, \"best_iteration\", None))\n",
        "        return acc\n",
        "\n",
        "    except Exception as e:\n",
        "        # Log a warning and return a very low score so Optuna can continue.\n",
        "        # Avoid letting the exception bubble and stop the entire study.\n",
        "        print(f\"[Optuna objective] caught exception during training/predict: {e!r}\")\n",
        "        return 0.0\n",
        "\n",
        "# run the study\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters:\", study.best_params)\n",
        "print(\"Best validation accuracy:\", study.best_value)\n",
        "print(\"Best trial attrs:\", study.best_trial.user_attrs)\n",
        "\n",
        "# Train final model on same train/val with best params\n",
        "best_params = study.best_params.copy()\n",
        "best_params.update({\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 3,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'hist',\n",
        "    'seed': 42,\n",
        "    'verbosity': 1\n",
        "})\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_tab, weight=sw_train)\n",
        "dval   = xgb.DMatrix(X_val, label=y_val_tab, weight=sw_val)\n",
        "final_model = xgb.train(\n",
        "    best_params,\n",
        "    dtrain,\n",
        "    num_boost_round=3000,\n",
        "    evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")\n",
        "# -------------------------\n",
        "# Save & evaluate (fixed, saving to xgb_model.pkl)\n",
        "# -------------------------\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Defensive check\n",
        "if 'final_model' not in globals():\n",
        "    raise RuntimeError(\"final_model not found. Make sure xgb.train(...) completed and produced final_model.\")\n",
        "\n",
        "# 1) Save the trained Booster\n",
        "# (a) JSON copy — reliable XGBoost-native format\n",
        "final_model.save_model(\"xgb_model.json\")\n",
        "\n",
        "# (b) Pickle via joblib so filename is xgb_model.pkl as requested\n",
        "# joblib will serialize the Booster object; this is convenient for later joblib.load()\n",
        "joblib.dump(final_model, \"xgb_model.pkl\")\n",
        "\n",
        "# 2) How to reload later (examples)\n",
        "# loaded_bst = joblib.load(\"xgb_model.pkl\")\n",
        "# OR\n",
        "# loaded_bst = xgb.Booster()\n",
        "# loaded_bst.load_model(\"xgb_model.json\")\n",
        "\n",
        "# 3) Evaluate on test set using the robust predict helper\n",
        "y_prob = predict_with_best(final_model, dtest)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"Final Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a651132806dc4e52b29c1c00de2adf8b",
            "3949ede736434da797f59c93d0ddf914",
            "89863e9996b94dc6af9cb45aef33db41",
            "4e2133ef34314e8c993e517573edcee7",
            "cad59ececc6e4a6cbd59059bcc2d07dc",
            "f6a6d529ec6e464e9a6a8c908ea9654c",
            "c7a763a91266440cbe16bc4e608355a2",
            "17a2049ba79e4536956b5eb4dfa03236",
            "6f3ec663ff254acca475c37f74906a24",
            "08731bb09b034977a218c20abe3f894d",
            "e684c1e817ad478ebe5b83a88851011f"
          ]
        },
        "id": "lOUy9Yd0g-6E",
        "outputId": "3740f320-feee-4be4-abbf-c583d3c0f1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/395.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-15 03:16:00,414] A new study created in memory with name: no-name-4e1876f4-e630-4d86-814a-c67b4b31e2d2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a651132806dc4e52b29c1c00de2adf8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-08-15 03:16:01,725] Trial 0 finished with value: 0.47591318157755425 and parameters: {'max_depth': 5, 'learning_rate': 0.2536999076681772, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'gamma': 0.7800932022121826, 'min_child_weight': 2, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 2.665440364437338}. Best is trial 0 with value: 0.47591318157755425.\n",
            "[I 2025-08-15 03:16:05,074] Trial 1 finished with value: 0.46823716251985176 and parameters: {'max_depth': 7, 'learning_rate': 0.11114989443094977, 'subsample': 0.608233797718321, 'colsample_bytree': 0.9879639408647978, 'gamma': 4.162213204002109, 'min_child_weight': 3, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 0.9585112746335845}. Best is trial 0 with value: 0.47591318157755425.\n",
            "[I 2025-08-15 03:16:06,864] Trial 2 finished with value: 0.47856008470089995 and parameters: {'max_depth': 5, 'learning_rate': 0.05958389350068958, 'subsample': 0.7727780074568463, 'colsample_bytree': 0.7164916560792167, 'gamma': 3.0592644736118975, 'min_child_weight': 2, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 1.4159046082342293}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:08,143] Trial 3 finished with value: 0.46982530439385917 and parameters: {'max_depth': 6, 'learning_rate': 0.14447746112718687, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'gamma': 2.9620728443102124, 'min_child_weight': 1, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 0.9263103092182288}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:09,030] Trial 4 finished with value: 0.4655902593965061 and parameters: {'max_depth': 3, 'learning_rate': 0.2521267904777921, 'subsample': 0.9862528132298237, 'colsample_bytree': 0.9233589392465844, 'gamma': 1.5230688458668533, 'min_child_weight': 1, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 1.6003812343490034}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:11,038] Trial 5 finished with value: 0.4737956590788777 and parameters: {'max_depth': 3, 'learning_rate': 0.05388108577817234, 'subsample': 0.6137554084460873, 'colsample_bytree': 0.9637281608315128, 'gamma': 1.2938999080000846, 'min_child_weight': 7, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 1.800170052944527}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:18,251] Trial 6 finished with value: 0.47776601376389627 and parameters: {'max_depth': 7, 'learning_rate': 0.01875220945578641, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'gamma': 4.697494707820946, 'min_child_weight': 9, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 2.804685587557792}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:22,339] Trial 7 finished with value: 0.47591318157755425 and parameters: {'max_depth': 3, 'learning_rate': 0.01947558230629543, 'subsample': 0.6180909155642152, 'colsample_bytree': 0.7301321323053057, 'gamma': 1.9433864484474102, 'min_child_weight': 3, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 1.3918833167339733}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:24,303] Trial 8 finished with value: 0.47697194282689254 and parameters: {'max_depth': 5, 'learning_rate': 0.06333268775321842, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'gamma': 0.3727532183988541, 'min_child_weight': 10, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 0.996789203835431}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:25,368] Trial 9 finished with value: 0.47697194282689254 and parameters: {'max_depth': 3, 'learning_rate': 0.1601531217136121, 'subsample': 0.8827429375390468, 'colsample_bytree': 0.8916028672163949, 'gamma': 3.8563517334297286, 'min_child_weight': 1, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 0.7896726488128243}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:38,777] Trial 10 finished with value: 0.47194282689253575 and parameters: {'max_depth': 10, 'learning_rate': 0.010206070557576998, 'subsample': 0.747491509088439, 'colsample_bytree': 0.6071847502459278, 'gamma': 2.846562513261506, 'min_child_weight': 5, 'reg_alpha': 0.9597707459454197, 'reg_lambda': 2.1671456877064457}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:44,277] Trial 11 finished with value: 0.47432503970354684 and parameters: {'max_depth': 8, 'learning_rate': 0.028630293828335575, 'subsample': 0.804004491087283, 'colsample_bytree': 0.7078349435778688, 'gamma': 4.812789789973256, 'min_child_weight': 9, 'reg_alpha': 0.4727140066579486, 'reg_lambda': 2.860691969571424}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:47,658] Trial 12 finished with value: 0.476707252514558 and parameters: {'max_depth': 8, 'learning_rate': 0.03918131591409241, 'subsample': 0.7965196835644142, 'colsample_bytree': 0.7168169453253019, 'gamma': 3.594761906730942, 'min_child_weight': 6, 'reg_alpha': 0.49253767676861326, 'reg_lambda': 2.224840294496338}. Best is trial 2 with value: 0.47856008470089995.\n",
            "[I 2025-08-15 03:16:54,231] Trial 13 finished with value: 0.48120698782424565 and parameters: {'max_depth': 5, 'learning_rate': 0.016102327351172684, 'subsample': 0.9702326925165274, 'colsample_bytree': 0.6526916860188784, 'gamma': 4.9319947803367805, 'min_child_weight': 8, 'reg_alpha': 0.2723787159722502, 'reg_lambda': 2.4142705958891533}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:16:55,961] Trial 14 finished with value: 0.476707252514558 and parameters: {'max_depth': 5, 'learning_rate': 0.08248124888741833, 'subsample': 0.9036729826669196, 'colsample_bytree': 0.6222381666918573, 'gamma': 3.3291140251275317, 'min_child_weight': 5, 'reg_alpha': 0.2104081387467914, 'reg_lambda': 2.3314443817921453}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:01,995] Trial 15 finished with value: 0.47697194282689254 and parameters: {'max_depth': 4, 'learning_rate': 0.011311689080273567, 'subsample': 0.7292781235655527, 'colsample_bytree': 0.6662225125541512, 'gamma': 2.2616315643880416, 'min_child_weight': 7, 'reg_alpha': 0.03482205016234696, 'reg_lambda': 0.5226883842841974}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:07,140] Trial 16 finished with value: 0.47591318157755425 and parameters: {'max_depth': 6, 'learning_rate': 0.03305522462432077, 'subsample': 0.8436816638205235, 'colsample_bytree': 0.757617495265744, 'gamma': 4.2486482620297785, 'min_child_weight': 4, 'reg_alpha': 0.32612827547325707, 'reg_lambda': 1.8435848965132617}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:11,844] Trial 17 finished with value: 0.47961884595023824 and parameters: {'max_depth': 4, 'learning_rate': 0.016925694920845034, 'subsample': 0.9362148766913249, 'colsample_bytree': 0.6643686748109008, 'gamma': 4.963718221870779, 'min_child_weight': 8, 'reg_alpha': 0.1995428923613113, 'reg_lambda': 1.3189875679197511}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:18,760] Trial 18 finished with value: 0.4782953943885654 and parameters: {'max_depth': 4, 'learning_rate': 0.017918544372383955, 'subsample': 0.9406069544760227, 'colsample_bytree': 0.6748679171498804, 'gamma': 4.995482180873948, 'min_child_weight': 8, 'reg_alpha': 0.21924313337258355, 'reg_lambda': 2.491196722355262}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:25,051] Trial 19 finished with value: 0.4804129168872419 and parameters: {'max_depth': 4, 'learning_rate': 0.014087738024522485, 'subsample': 0.9431257979856223, 'colsample_bytree': 0.6461818881789246, 'gamma': 4.322478497401882, 'min_child_weight': 10, 'reg_alpha': 0.12404974246760797, 'reg_lambda': 2.056941355251962}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:31,331] Trial 20 finished with value: 0.4716781365802012 and parameters: {'max_depth': 10, 'learning_rate': 0.025342408734938118, 'subsample': 0.9534903068285625, 'colsample_bytree': 0.7906953119250892, 'gamma': 4.302873220094304, 'min_child_weight': 10, 'reg_alpha': 0.10087922983598385, 'reg_lambda': 2.0022520026966655}. Best is trial 13 with value: 0.48120698782424565.\n",
            "[I 2025-08-15 03:17:37,620] Trial 21 finished with value: 0.4822657490735839 and parameters: {'max_depth': 4, 'learning_rate': 0.013671580481098287, 'subsample': 0.938389723418732, 'colsample_bytree': 0.6478795649886951, 'gamma': 4.5946546156577135, 'min_child_weight': 8, 'reg_alpha': 0.15614938989473925, 'reg_lambda': 1.2968564899903916}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:17:46,330] Trial 22 finished with value: 0.4782953943885654 and parameters: {'max_depth': 4, 'learning_rate': 0.013470696756513634, 'subsample': 0.852172802060192, 'colsample_bytree': 0.6393330140399617, 'gamma': 4.373791679562274, 'min_child_weight': 9, 'reg_alpha': 0.133043217708939, 'reg_lambda': 2.5193985534223695}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:17:55,540] Trial 23 finished with value: 0.48173636844891476 and parameters: {'max_depth': 6, 'learning_rate': 0.013461245842221685, 'subsample': 0.9606081989667096, 'colsample_bytree': 0.6036068397455835, 'gamma': 3.80926579671009, 'min_child_weight': 8, 'reg_alpha': 0.40179038868366646, 'reg_lambda': 1.9553972970723523}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:17:59,654] Trial 24 finished with value: 0.48120698782424565 and parameters: {'max_depth': 6, 'learning_rate': 0.023562638093443975, 'subsample': 0.9890740959358136, 'colsample_bytree': 0.6025610227633125, 'gamma': 3.949385767134908, 'min_child_weight': 7, 'reg_alpha': 0.4388519587685783, 'reg_lambda': 1.5715881778366279}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:03,076] Trial 25 finished with value: 0.47432503970354684 and parameters: {'max_depth': 7, 'learning_rate': 0.040383700461943804, 'subsample': 0.911498818028119, 'colsample_bytree': 0.6820835729577146, 'gamma': 3.7173783207413993, 'min_child_weight': 8, 'reg_alpha': 0.397600502414718, 'reg_lambda': 1.1837027362337136}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:12,025] Trial 26 finished with value: 0.47961884595023824 and parameters: {'max_depth': 8, 'learning_rate': 0.013634014971122054, 'subsample': 0.9622664721138563, 'colsample_bytree': 0.6347264216551218, 'gamma': 4.654632029507973, 'min_child_weight': 6, 'reg_alpha': 0.549882420594233, 'reg_lambda': 2.9968617997542055}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:21,899] Trial 27 finished with value: 0.47803070407623083 and parameters: {'max_depth': 6, 'learning_rate': 0.011342239653456244, 'subsample': 0.8547950106714948, 'colsample_bytree': 0.7652526767198677, 'gamma': 3.364173367413742, 'min_child_weight': 8, 'reg_alpha': 0.2825137975289681, 'reg_lambda': 1.9348790086952918}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:26,124] Trial 28 finished with value: 0.47961884595023824 and parameters: {'max_depth': 5, 'learning_rate': 0.02134337220157372, 'subsample': 0.9174475209511994, 'colsample_bytree': 0.6908583164135388, 'gamma': 4.625193861128026, 'min_child_weight': 7, 'reg_alpha': 0.004907013905033064, 'reg_lambda': 1.668828366779842}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:33,444] Trial 29 finished with value: 0.476707252514558 and parameters: {'max_depth': 5, 'learning_rate': 0.014718953162784088, 'subsample': 0.8788198503202759, 'colsample_bytree': 0.8316515050566602, 'gamma': 2.5278800687196186, 'min_child_weight': 9, 'reg_alpha': 0.41360705058584807, 'reg_lambda': 2.4244862707557755}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:37,883] Trial 30 finished with value: 0.4804129168872419 and parameters: {'max_depth': 9, 'learning_rate': 0.027833149557055445, 'subsample': 0.9940830990281094, 'colsample_bytree': 0.6008785554162813, 'gamma': 3.9862036399622847, 'min_child_weight': 6, 'reg_alpha': 0.231379172910068, 'reg_lambda': 1.1617929995116973}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:43,745] Trial 31 finished with value: 0.476707252514558 and parameters: {'max_depth': 6, 'learning_rate': 0.02328050904759553, 'subsample': 0.9612677378270623, 'colsample_bytree': 0.6009310419553493, 'gamma': 3.929177009375048, 'min_child_weight': 7, 'reg_alpha': 0.4432264080713056, 'reg_lambda': 1.5774609012015952}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:49,548] Trial 32 finished with value: 0.4772366331392271 and parameters: {'max_depth': 6, 'learning_rate': 0.015914465984810115, 'subsample': 0.9698853107971247, 'colsample_bytree': 0.6466080149349189, 'gamma': 3.520324906402199, 'min_child_weight': 8, 'reg_alpha': 0.36097962142844814, 'reg_lambda': 1.4805858277844994}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:18:59,627] Trial 33 finished with value: 0.4804129168872419 and parameters: {'max_depth': 7, 'learning_rate': 0.011882880552122232, 'subsample': 0.9199273310870789, 'colsample_bytree': 0.6264354772597605, 'gamma': 4.474139524046728, 'min_child_weight': 7, 'reg_alpha': 0.5424190214777809, 'reg_lambda': 2.608862627945571}. Best is trial 21 with value: 0.4822657490735839.\n",
            "[I 2025-08-15 03:19:03,365] Trial 34 finished with value: 0.48358920063525673 and parameters: {'max_depth': 5, 'learning_rate': 0.021252314132139415, 'subsample': 0.9993134344664013, 'colsample_bytree': 0.6557973311506957, 'gamma': 4.095657288735421, 'min_child_weight': 9, 'reg_alpha': 0.2712577538771415, 'reg_lambda': 1.2076972565720974}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:08,372] Trial 35 finished with value: 0.473001588141874 and parameters: {'max_depth': 5, 'learning_rate': 0.03767998029395567, 'subsample': 0.9716585843408655, 'colsample_bytree': 0.6999873527418379, 'gamma': 3.1563673093501787, 'min_child_weight': 9, 'reg_alpha': 0.26286178546062144, 'reg_lambda': 1.24371607009001}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:18,019] Trial 36 finished with value: 0.47961884595023824 and parameters: {'max_depth': 4, 'learning_rate': 0.01044374563824683, 'subsample': 0.9250097045336113, 'colsample_bytree': 0.7475274828347369, 'gamma': 4.568854034166775, 'min_child_weight': 10, 'reg_alpha': 0.1659400706440154, 'reg_lambda': 1.0891555219072864}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:22,629] Trial 37 finished with value: 0.47353096876654316 and parameters: {'max_depth': 5, 'learning_rate': 0.016979875300110376, 'subsample': 0.8843686544824075, 'colsample_bytree': 0.6577572200526265, 'gamma': 2.750051421555253, 'min_child_weight': 9, 'reg_alpha': 0.2742870794387995, 'reg_lambda': 0.9125794493535961}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:27,677] Trial 38 finished with value: 0.47803070407623083 and parameters: {'max_depth': 7, 'learning_rate': 0.020347287470989982, 'subsample': 0.97802637820856, 'colsample_bytree': 0.686735172473941, 'gamma': 4.116395145812624, 'min_child_weight': 8, 'reg_alpha': 0.08983205340563472, 'reg_lambda': 1.7017075429287778}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:31,269] Trial 39 finished with value: 0.47856008470089995 and parameters: {'max_depth': 3, 'learning_rate': 0.05393148763493746, 'subsample': 0.9918486712000473, 'colsample_bytree': 0.7304041915286984, 'gamma': 1.4060893518801032, 'min_child_weight': 9, 'reg_alpha': 0.35696785229669864, 'reg_lambda': 0.6592970754872816}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:34,410] Trial 40 finished with value: 0.47511911064055057 and parameters: {'max_depth': 5, 'learning_rate': 0.03140811175024811, 'subsample': 0.9998830202561267, 'colsample_bytree': 0.623582700541477, 'gamma': 0.861746909439679, 'min_child_weight': 8, 'reg_alpha': 0.06001645902441244, 'reg_lambda': 1.4207291669544782}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:39,008] Trial 41 finished with value: 0.47697194282689254 and parameters: {'max_depth': 6, 'learning_rate': 0.021252362409098925, 'subsample': 0.951081590814063, 'colsample_bytree': 0.6157720335453716, 'gamma': 4.1116709024106095, 'min_child_weight': 7, 'reg_alpha': 0.42940386966374494, 'reg_lambda': 1.8263417411627363}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:49,100] Trial 42 finished with value: 0.47961884595023824 and parameters: {'max_depth': 6, 'learning_rate': 0.01306991631337191, 'subsample': 0.9761759480687405, 'colsample_bytree': 0.6536899979144016, 'gamma': 3.7954817901039872, 'min_child_weight': 6, 'reg_alpha': 0.6617566681533864, 'reg_lambda': 1.5626011719857211}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:19:54,627] Trial 43 finished with value: 0.47750132345156165 and parameters: {'max_depth': 6, 'learning_rate': 0.024160074723444874, 'subsample': 0.9351990641236746, 'colsample_bytree': 0.6357414351137447, 'gamma': 4.793218203734016, 'min_child_weight': 7, 'reg_alpha': 0.3282045528761529, 'reg_lambda': 1.27156664608516}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:20:00,181] Trial 44 finished with value: 0.47353096876654316 and parameters: {'max_depth': 5, 'learning_rate': 0.01609458834076481, 'subsample': 0.9994522038157034, 'colsample_bytree': 0.8747774740116366, 'gamma': 0.007250058963767181, 'min_child_weight': 8, 'reg_alpha': 0.16402116032294642, 'reg_lambda': 2.175289874428401}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:20:06,867] Trial 45 finished with value: 0.48173636844891476 and parameters: {'max_depth': 5, 'learning_rate': 0.018718338855538055, 'subsample': 0.894976291257687, 'colsample_bytree': 0.6137066296074505, 'gamma': 4.067876205945985, 'min_child_weight': 9, 'reg_alpha': 0.38605811889362673, 'reg_lambda': 1.0494440604657997}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:20:07,690] Trial 46 finished with value: 0.47776601376389627 and parameters: {'max_depth': 4, 'learning_rate': 0.1685531379743863, 'subsample': 0.8950221438496071, 'colsample_bytree': 0.9643309908483702, 'gamma': 4.460974290031883, 'min_child_weight': 10, 'reg_alpha': 0.24478740297188106, 'reg_lambda': 1.0426824947708133}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:20:15,879] Trial 47 finished with value: 0.4764425622022234 and parameters: {'max_depth': 3, 'learning_rate': 0.01004799231897612, 'subsample': 0.8694137992154976, 'colsample_bytree': 0.6729116303809537, 'gamma': 1.771291535654584, 'min_child_weight': 9, 'reg_alpha': 0.3850938066561234, 'reg_lambda': 0.8724390194269136}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:20:18,954] Trial 48 finished with value: 0.4782953943885654 and parameters: {'max_depth': 5, 'learning_rate': 0.07145129711866048, 'subsample': 0.8193936830742344, 'colsample_bytree': 0.711926158066181, 'gamma': 3.5903458445596756, 'min_child_weight': 9, 'reg_alpha': 0.3096145238130313, 'reg_lambda': 0.693281993589495}. Best is trial 34 with value: 0.48358920063525673.\n",
            "[I 2025-08-15 03:20:20,273] Trial 49 finished with value: 0.4806776071995765 and parameters: {'max_depth': 4, 'learning_rate': 0.1051640508244555, 'subsample': 0.8978945139679064, 'colsample_bytree': 0.6221046803842243, 'gamma': 4.800062123862296, 'min_child_weight': 2, 'reg_alpha': 0.17616473387047044, 'reg_lambda': 1.3273291117569646}. Best is trial 34 with value: 0.48358920063525673.\n",
            "\n",
            "Best parameters: {'max_depth': 5, 'learning_rate': 0.021252314132139415, 'subsample': 0.9993134344664013, 'colsample_bytree': 0.6557973311506957, 'gamma': 4.095657288735421, 'min_child_weight': 9, 'reg_alpha': 0.2712577538771415, 'reg_lambda': 1.2076972565720974}\n",
            "Best validation accuracy: 0.48358920063525673\n",
            "Best trial attrs: {'best_iteration': 297}\n",
            "[0]\ttrain-mlogloss:1.09730\teval-mlogloss:1.09770\n",
            "[50]\ttrain-mlogloss:1.05129\teval-mlogloss:1.07510\n",
            "[100]\ttrain-mlogloss:1.02625\teval-mlogloss:1.06846\n",
            "[150]\ttrain-mlogloss:1.01389\teval-mlogloss:1.06590\n",
            "[200]\ttrain-mlogloss:1.01007\teval-mlogloss:1.06414\n",
            "[250]\ttrain-mlogloss:1.00799\teval-mlogloss:1.06311\n",
            "[300]\ttrain-mlogloss:1.00747\teval-mlogloss:1.06277\n",
            "[347]\ttrain-mlogloss:1.00745\teval-mlogloss:1.06277\n",
            "Final Test Accuracy: 0.18576342947869806\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.00      0.00      0.00       752\n",
            "         0.0       0.42      0.13      0.20      2132\n",
            "         1.0       0.18      0.47      0.26       895\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.19      3779\n",
            "   macro avg       0.15      0.15      0.11      3779\n",
            "weighted avg       0.28      0.19      0.17      3779\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0  157  391  204]\n",
            " [   0  279 1586  267]\n",
            " [   0  222  423  250]\n",
            " [   0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-O-F Predictions"
      ],
      "metadata": {
        "id": "Di2jwJEwhUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ==== Combine your split data back into one dataset ====\n",
        "X_tab = np.vstack([X_train, X_val, X_test])\n",
        "y_tab = np.concatenate([y_train, y_val, y_test])\n",
        "y_tab = pd.Series(y_tab)  # needed for .map()\n",
        "\n",
        "# ==== Time series split config ====\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# ==== Label remap (-1, 0, 1) -> (0, 1, 2) ====\n",
        "label_map = {-1: 0, 0: 1, 1: 2}\n",
        "\n",
        "# ==== One-hot encoder for DL models ====\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "y_all_mapped = y_tab.map(label_map)\n",
        "y_all_oh = enc.fit_transform(y_all_mapped.values.reshape(-1, 1))\n",
        "\n",
        "# ==== Storage for OOF predictions ====\n",
        "oof_cnn = np.zeros((len(X_tab), 3))\n",
        "oof_lstm = np.zeros((len(X_tab), 3))\n",
        "oof_xgb = np.zeros((len(X_tab), 3))\n",
        "\n",
        "# ==== Ensure tabular and sequence data match in length ====\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_all_mapped))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_all_mapped_aligned = y_all_mapped.iloc[:min_len]\n",
        "y_all_oh_aligned = y_all_oh[:min_len]\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_all_mapped_aligned.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BstRtL0ehVta",
        "outputId": "fea5295d-30d2-48b1-f911-c7d33946c9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(17607, 26), seq=(17607, 24, 26), y=(17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: create aligned copies (recommended, non-destructive)\n",
        "import numpy as np\n",
        "\n",
        "# require oof_idx_xgb exists\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found; re-run XGB OOF generation which should set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "# create aligned versions of CNN/LSTM that match oof_xgb's rows\n",
        "oof_cnn_aligned = np.asarray(oof_cnn)[idx]\n",
        "oof_lstm_aligned = np.asarray(oof_lstm)[idx]\n",
        "oof_xgb_aligned = np.asarray(oof_xgb)  # already aligned to idx\n",
        "\n",
        "print(\"Aligned shapes:\")\n",
        "print(\" oof_cnn_aligned:\", oof_cnn_aligned.shape)\n",
        "print(\" oof_lstm_aligned:\", oof_lstm_aligned.shape)\n",
        "print(\" oof_xgb_aligned:\", oof_xgb_aligned.shape)\n",
        "\n",
        "# Keep originals for debugging; set globals for convenience\n",
        "globals()['oof_cnn_aligned'] = oof_cnn_aligned\n",
        "globals()['oof_lstm_aligned'] = oof_lstm_aligned\n",
        "globals()['oof_xgb_aligned'] = oof_xgb_aligned\n",
        "\n",
        "# If later code expects oof_cnn/oof_lstm to be same length as oof_xgb, use these aligned ones.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "tdfTKCaeTHcX",
        "outputId": "a0034b3f-34e5-4c2f-bf6e-9def3ebb9da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "oof_idx_xgb not found; re-run XGB OOF generation which should set oof_idx_xgb.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3610083715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# require oof_idx_xgb exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'oof_idx_xgb'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"oof_idx_xgb not found; re-run XGB OOF generation which should set oof_idx_xgb.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_idx_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: oof_idx_xgb not found; re-run XGB OOF generation which should set oof_idx_xgb."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    cnn_model = build_cnn_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "id": "nc3NN2CkhDvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    lstm_model = build_lstm_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "id": "zjUIXAYdhGJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Tabular split\n",
        "    X_tr_tab, X_va_tab = X_tab_aligned[train_idx], X_tab_aligned[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_all_mapped_aligned.iloc[train_idx], y_all_mapped_aligned.iloc[val_idx]\n",
        "\n",
        "    # Build with best parameters\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        num_class=3,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.0182014870849285,\n",
        "        subsample=0.8218430665716767,\n",
        "        colsample_bytree=0.7628150155615464,\n",
        "        gamma=0.7186090872199041,\n",
        "        min_child_weight=8,\n",
        "        reg_alpha=0.5856294446650139,\n",
        "        reg_lambda=2.9006322365170183,\n",
        "        n_estimators=300,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_clf.fit(X_tr_tab, y_tr_tab)\n",
        "\n",
        "    # Predict\n",
        "    oof_xgb[val_idx] = xgb_clf.predict_proba(X_va_tab)\n"
      ],
      "metadata": {
        "id": "MlbAkv81hL4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: create aligned copies (non-destructive)\n",
        "import numpy as np\n",
        "\n",
        "# require index mapping produced when generating XGB OOF\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found. Re-run the XGB OOF cell which should set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "n_full = oof_cnn.shape[0]\n",
        "if idx.min() < 0 or idx.max() >= n_full:\n",
        "    raise RuntimeError(f\"oof_idx_xgb values out of range for full length {n_full}\")\n",
        "\n",
        "# create aligned versions\n",
        "oof_cnn_aligned = np.asarray(oof_cnn)[idx]\n",
        "oof_lstm_aligned = np.asarray(oof_lstm)[idx]\n",
        "oof_xgb_aligned = np.asarray(oof_xgb)   # already the right smaller length\n",
        "\n",
        "print(\"Aligned shapes:\")\n",
        "print(\" oof_cnn_aligned:\", oof_cnn_aligned.shape)\n",
        "print(\" oof_lstm_aligned:\", oof_lstm_aligned.shape)\n",
        "print(\" oof_xgb_aligned:\", oof_xgb_aligned.shape)\n",
        "\n",
        "# set globals (convenience)\n",
        "globals()['oof_cnn_aligned'] = oof_cnn_aligned\n",
        "globals()['oof_lstm_aligned'] = oof_lstm_aligned\n",
        "globals()['oof_xgb_aligned'] = oof_xgb_aligned\n"
      ],
      "metadata": {
        "id": "oypZH8ABhQFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# Save OOF predictions and labels\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_all_mapped.values\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")\n"
      ],
      "metadata": {
        "id": "Z5i8N1lJps85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# META LEARNER"
      ],
      "metadata": {
        "id": "IhKOAKMNxrMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Replace np.hstack([oof_cnn, oof_lstm, oof_xgb]) with this ---\n",
        "import numpy as np\n",
        "\n",
        "# 1) Ensure the XGB index mapping exists\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found. Re-run XGB OOF generation to set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "\n",
        "# 2) Select aligned rows from CNN/LSTM using that mapping\n",
        "aligned_cnn = np.asarray(oof_cnn)[idx]\n",
        "aligned_lstm = np.asarray(oof_lstm)[idx]\n",
        "aligned_xgb = np.asarray(oof_xgb)  # already matches idx\n",
        "\n",
        "# 3) Sanity checks\n",
        "assert aligned_cnn.shape[0] == aligned_lstm.shape[0] == aligned_xgb.shape[0], \\\n",
        "       f\"Aligned shapes mismatch: cnn {aligned_cnn.shape} lstm {aligned_lstm.shape} xgb {aligned_xgb.shape}\"\n",
        "\n",
        "# 4) Build meta matrices (stacked probabilities)\n",
        "meta_X_train = np.hstack([aligned_cnn, aligned_lstm, aligned_xgb])  # shape: (N_aligned, 9)\n",
        "# Use the y that already matches XGB (you indicated y_all_mapped_aligned is length 17607)\n",
        "meta_y_train = np.asarray(y_all_mapped_aligned)\n",
        "\n",
        "print(\"meta_X_train shape:\", meta_X_train.shape)\n",
        "print(\"meta_y_train shape:\", meta_y_train.shape)\n"
      ],
      "metadata": {
        "id": "_UY6W_zKg-fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: overwrite original oof_* so downstream code that expects the smaller length works\n",
        "oof_cnn = aligned_cnn\n",
        "oof_lstm = aligned_lstm\n",
        "oof_xgb = aligned_xgb\n",
        "globals().update({'oof_cnn': oof_cnn, 'oof_lstm': oof_lstm, 'oof_xgb': oof_xgb})\n"
      ],
      "metadata": {
        "id": "qdu9LhULVsE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — meta-features construction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model probabilities as features\n",
        "meta_probs = np.hstack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 9)\n",
        "\n",
        "# Add engineered meta-features derived from base model outputs:\n",
        "# - per-sample mean/std/max/min across base model probs\n",
        "# - disagreements (max prob - 2nd max prob) for confidence\n",
        "def meta_stats_from_probs(probs_block):\n",
        "    # probs_block shape (n, n_models * n_classes)\n",
        "    n_classes = 3\n",
        "    n_models = probs_block.shape[1] // n_classes\n",
        "    block = probs_block.reshape(len(probs_block), n_models, n_classes)\n",
        "    # per model best class prob and best class\n",
        "    best_probs = block.max(axis=2)                 # (n, n_models)\n",
        "    best_classes = block.argmax(axis=2)             # (n, n_models)\n",
        "    # statistics across models on best_probs\n",
        "    mean_best = best_probs.mean(axis=1)\n",
        "    std_best = best_probs.std(axis=1)\n",
        "    max_best = best_probs.max(axis=1)\n",
        "    min_best = best_probs.min(axis=1)\n",
        "    # disagreement: how many models agree with majority class\n",
        "    from scipy.stats import mode\n",
        "    mode_vals, mode_counts = mode(best_classes, axis=1)\n",
        "    agree_fraction = (mode_counts.ravel() / n_models)\n",
        "    # confidence gap: top prob - second top prob per model averaged\n",
        "    def gap_per_row(row_block):\n",
        "        # row_block shape (n_models, n_classes)\n",
        "        gaps = []\n",
        "        for m in range(row_block.shape[0]):\n",
        "            arr = np.sort(row_block[m])[::-1]\n",
        "            gaps.append(arr[0] - (arr[1] if arr.shape[0] > 1 else 0.0))\n",
        "        return np.mean(gaps)\n",
        "    gap = np.array([gap_per_row(row) for row in block])\n",
        "\n",
        "    stats = np.vstack([mean_best, std_best, max_best, min_best, agree_fraction, gap]).T\n",
        "    stats_cols = [\"mean_best_prob\", \"std_best_prob\", \"max_best_prob\", \"min_best_prob\", \"agree_frac\", \"avg_top_gap\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_probs(meta_probs)\n",
        "\n",
        "# Optionally add a few simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# For now, we'll build final meta_X from probs + stats\n",
        "meta_X = np.hstack([meta_probs, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_p{c}\" for c in range(3)] +\n",
        "    [f\"lstm_p{c}\" for c in range(3)] +\n",
        "    [f\"xgb_p{c}\" for c in range(3)] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)\n"
      ],
      "metadata": {
        "id": "4F859Av3p0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Train final meta-learner on aligned meta features (fix mismatch) ----------\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Use aligned meta arrays produced earlier\n",
        "if 'meta_X_train' in globals() and 'meta_y_train' in globals():\n",
        "    X_meta = np.asarray(meta_X_train)\n",
        "    y_meta = np.asarray(meta_y_train)\n",
        "else:\n",
        "    raise RuntimeError(\"Aligned meta arrays not found. Make sure meta_X_train and meta_y_train exist.\")\n",
        "\n",
        "print(\"Shapes before fit: X_meta:\", X_meta.shape, \"y_meta:\", y_meta.shape)\n",
        "\n",
        "# sanity\n",
        "if X_meta.shape[0] != y_meta.shape[0]:\n",
        "    raise ValueError(f\"Shape mismatch: X_meta rows {X_meta.shape[0]} != y_meta {y_meta.shape[0]}\")\n",
        "\n",
        "# compute balanced sample weights for the meta set\n",
        "sample_weight_meta = compute_sample_weight(class_weight=\"balanced\", y=y_meta)\n",
        "\n",
        "# build final model with the best hyperparameters found earlier (best_cfg)\n",
        "# make sure best_cfg exists; if not, you can hardcode the best config you printed\n",
        "try:\n",
        "    best_cfg  # noqa: F821\n",
        "except NameError:\n",
        "    # fallback: use the best config you printed: {'max_iter':200,'learning_rate':0.1,'max_depth':4}\n",
        "    best_cfg = {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
        "\n",
        "final_model = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=42)\n",
        "final_model.fit(X_meta, y_meta, sample_weight=sample_weight_meta)\n",
        "\n",
        "# Save the trained meta model\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n",
        "print(\"Final meta_learner model trained and saved to meta_laerner.pkl\")\n",
        "\n",
        "# Quick train-set diagnostics\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
        "pred_train = final_model.predict(X_meta)\n",
        "print(\"Train balanced accuracy:\", balanced_accuracy_score(y_meta, pred_train))\n",
        "print(\"Train classification report:\\n\", classification_report(y_meta, pred_train, digits=4))\n"
      ],
      "metadata": {
        "id": "QpJul1btp2JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust: Load meta model (or ensemble object) and predict probabilities / classes\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from typing import Optional\n",
        "\n",
        "def load_and_predict(\n",
        "    model_path: str,\n",
        "    meta_X: np.ndarray,\n",
        "    y: Optional[np.ndarray] = None,\n",
        "    threshold: Optional[np.ndarray] = None,\n",
        "    label_map_back: Optional[dict] = None,  # e.g. {0:-1.0, 1:0.0, 2:1.0}\n",
        "    verbose: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a saved meta model (or a dict with 'meta_model' and optional 'calibrators'),\n",
        "    predicts probabilities and classes on meta_X, applies optional thresholding,\n",
        "    and returns (probs, preds, preds_mapped_if_label_map).\n",
        "    \"\"\"\n",
        "    assert isinstance(meta_X, np.ndarray), \"meta_X must be a numpy array\"\n",
        "    # load artifact\n",
        "    obj = joblib.load(model_path)\n",
        "    # object can be:\n",
        "    # - a fitted estimator with predict_proba\n",
        "    # - a dict: {'meta_model': estimator, 'calibrators': [cal1, cal2, ...]} or similar\n",
        "    if isinstance(obj, dict):\n",
        "        if verbose:\n",
        "            print(\"Loaded dict artifact with keys:\", list(obj.keys()))\n",
        "        meta_model = obj.get(\"meta_model\") or obj.get(\"model\") or obj.get(\"estimator\")\n",
        "        calibrators = obj.get(\"calibrators\", None)\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"Loaded estimator directly from\", model_path)\n",
        "        meta_model = obj\n",
        "        calibrators = None\n",
        "\n",
        "    if meta_model is None:\n",
        "        raise RuntimeError(\"No 'meta_model' found in artifact and artifact is not a direct estimator.\")\n",
        "\n",
        "    # Get probabilities\n",
        "    if calibrators:\n",
        "        if verbose:\n",
        "            print(\"Using calibrators to produce averaged probabilities (len calibrators):\", len(calibrators))\n",
        "        probs_list = []\n",
        "        for cal in calibrators:\n",
        "            # prefer calibrator.predict_proba if it's a calibrator, otherwise fall back\n",
        "            if hasattr(cal, \"predict_proba\"):\n",
        "                probs_list.append(cal.predict_proba(meta_X))\n",
        "            elif hasattr(cal, \"predict\"):\n",
        "                # if calibrator returns labels, convert to one-hot-ish fallback (not ideal)\n",
        "                preds = cal.predict(meta_X)\n",
        "                onehot = np.zeros((len(preds), np.max(preds)+1))\n",
        "                onehot[np.arange(len(preds)), preds] = 1.0\n",
        "                probs_list.append(onehot)\n",
        "            else:\n",
        "                raise RuntimeError(\"Calibrator does not support predict_proba or predict.\")\n",
        "        probs = np.mean(probs_list, axis=0)\n",
        "    else:\n",
        "        if not hasattr(meta_model, \"predict_proba\"):\n",
        "            raise RuntimeError(\"Loaded meta_model has no predict_proba method.\")\n",
        "        probs = meta_model.predict_proba(meta_X)\n",
        "\n",
        "    # Optional thresholding (vector of length n_classes or None)\n",
        "    if threshold is not None:\n",
        "        threshold = np.asarray(threshold)\n",
        "        if threshold.shape[0] != probs.shape[1]:\n",
        "            raise ValueError(\"threshold must have length equal to number of classes\")\n",
        "        # Score = prob - threshold, then pick argmax (falls back to argmax of prob if all below)\n",
        "        scores = probs - threshold.reshape((1, -1))\n",
        "        preds = np.argmax(scores, axis=1)\n",
        "    else:\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Map back to original labels if requested\n",
        "    preds_mapped = None\n",
        "    if label_map_back is not None:\n",
        "        # label_map_back maps internal ints -> original labels\n",
        "        preds_mapped = np.array([label_map_back[int(p)] for p in preds])\n",
        "\n",
        "    # Diagnostics if ground-truth y provided\n",
        "    if y is not None:\n",
        "        if len(y) != len(preds):\n",
        "            raise ValueError(f\"Length mismatch: y ({len(y)}) vs preds ({len(preds)})\")\n",
        "        acc = accuracy_score(y, preds)\n",
        "        f1m = f1_score(y, preds, average=\"macro\", zero_division=0)\n",
        "        if verbose:\n",
        "            print(f\"Accuracy: {acc:.4f}   F1_macro: {f1m:.4f}\")\n",
        "            print(classification_report(y, preds, digits=4))\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"No ground-truth y provided; returning predictions only.\")\n",
        "\n",
        "    return probs, preds, preds_mapped\n",
        "\n",
        "# -------------------------\n",
        "# Example usage (replace meta_X and y with your data)\n",
        "# -------------------------\n",
        "# meta_X must be numpy array shaped like training-time meta features (e.g. meta_X_train shape)\n",
        "# y is optional\n",
        "# label_map_back = {0:-1.0, 1:0.0, 2:1.0}  # if you want original labels back\n",
        "probs, preds, preds_mapped = load_and_predict(\"meta_model.pkl\", meta_X=meta_X, y=None, threshold=None, label_map_back=None, verbose=True)\n",
        "\n",
        "# Inspect outputs\n",
        "print(\"probs.shape:\", probs.shape)\n",
        "print(\"preds.shape:\", preds.shape)\n",
        "if preds_mapped is not None:\n",
        "    print(\"preds_mapped[:10]:\", preds_mapped[:10])\n"
      ],
      "metadata": {
        "id": "LoSvckCSp8Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "X1nvP47MjnKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "5nGTwsv4qpi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "TdtsuwkPaxcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save the three base models\n",
        "joblib.dump(cnn_model, \"cnn_model.pkl\")\n",
        "joblib.dump(lstm_model, \"lstm_model.pkl\")\n",
        "joblib.dump(xgb_clf, \"xgb_model.pkl\")  # change to your actual XGB var name\n",
        "\n",
        "# Download them\n",
        "files.download(\"cnn_model.pkl\")\n",
        "files.download(\"lstm_model.pkl\")\n",
        "files.download(\"xgb_model.pkl\")\n"
      ],
      "metadata": {
        "id": "SF20g9Ys68Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "files.download(\"scaler.pkl\")"
      ],
      "metadata": {
        "id": "layD2Oi7Tymv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a651132806dc4e52b29c1c00de2adf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3949ede736434da797f59c93d0ddf914",
              "IPY_MODEL_89863e9996b94dc6af9cb45aef33db41",
              "IPY_MODEL_4e2133ef34314e8c993e517573edcee7"
            ],
            "layout": "IPY_MODEL_cad59ececc6e4a6cbd59059bcc2d07dc"
          }
        },
        "3949ede736434da797f59c93d0ddf914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a6d529ec6e464e9a6a8c908ea9654c",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a763a91266440cbe16bc4e608355a2",
            "value": "Best trial: 34. Best value: 0.483589: 100%"
          }
        },
        "89863e9996b94dc6af9cb45aef33db41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a2049ba79e4536956b5eb4dfa03236",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f3ec663ff254acca475c37f74906a24",
            "value": 50
          }
        },
        "4e2133ef34314e8c993e517573edcee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08731bb09b034977a218c20abe3f894d",
            "placeholder": "​",
            "style": "IPY_MODEL_e684c1e817ad478ebe5b83a88851011f",
            "value": " 50/50 [04:19&lt;00:00,  3.80s/it]"
          }
        },
        "cad59ececc6e4a6cbd59059bcc2d07dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a6d529ec6e464e9a6a8c908ea9654c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a763a91266440cbe16bc4e608355a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a2049ba79e4536956b5eb4dfa03236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f3ec663ff254acca475c37f74906a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08731bb09b034977a218c20abe3f894d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e684c1e817ad478ebe5b83a88851011f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}