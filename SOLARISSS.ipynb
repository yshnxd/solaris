{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris/blob/main/SOLARISSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Libraries"
      ],
      "metadata": {
        "id": "XUR0zNCpOy7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "1563b680-172e-4803-86e1-6abf6cf9541c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "3hev1JrVPjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\"AAPL\", \"SPY\", \"TSLA\", \"NVDA\", \"QQQ\"]  # note: ^VIX for Yahoo\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "cba782ca-31aa-4fb6-a29a-58f64fa26b78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "SPY: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "TSLA: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "NVDA: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "QQQ: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL         SPY        TSLA        NVDA  \\\n",
            "Datetime                                                              \n",
            "2025-08-12 15:30:00  229.779999  641.379272  338.031494  182.274994   \n",
            "2025-08-12 16:30:00  229.774994  641.539978  338.790009  182.240005   \n",
            "2025-08-12 17:30:00  229.570007  642.219971  339.413696  183.065002   \n",
            "2025-08-12 18:30:00  229.182999  642.320007  340.859985  182.784500   \n",
            "2025-08-12 19:30:00  229.649994  642.630005  340.755005  183.100006   \n",
            "\n",
            "                            QQQ  \n",
            "Datetime                         \n",
            "2025-08-12 15:30:00  578.659973  \n",
            "2025-08-12 16:30:00  578.887085  \n",
            "2025-08-12 17:30:00  579.619995  \n",
            "2025-08-12 18:30:00  579.744995  \n",
            "2025-08-12 19:30:00  580.020020  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Creation"
      ],
      "metadata": {
        "id": "jLnkdkzRRvVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Features"
      ],
      "metadata": {
        "id": "omLPzq5TDwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    macd = ta.trend.MACD(price_series)\n",
        "    feat_tmp[\"macd\"] = macd.macd()\n",
        "    feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"SPY\", \"QQQ\", \"NVDA\"]:\n",
        "        if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    if \"^VIX\" in aligned_ffill.columns:\n",
        "        feat_tmp[\"vix_ret_1h\"] = aligned_ffill[\"^VIX\"].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    feat_tmp = feat_tmp.dropna(subset=[col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]])\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = ticker\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())\n"
      ],
      "metadata": {
        "id": "MFIHXqY5R2fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04ad809-6165-46a6-b270-0dff544c0511"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created features for 5 tickers\n",
            "Shape: (25210, 26)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.003927 -0.009147 -0.007584  0.005846  0.046665  0.007817  0.007090   \n",
            "1 -0.012844 -0.022400 -0.023381 -0.018455  0.029676  0.008701  0.007126   \n",
            "2 -0.008392 -0.017286 -0.023793 -0.030869  0.015118  0.008742  0.007124   \n",
            "3 -0.007873 -0.028836 -0.037719 -0.030889  0.002985  0.007122  0.007125   \n",
            "4  0.005376 -0.010910 -0.033066 -0.026802  0.010589  0.008245  0.007425   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...      ema_20  vol_change_1h  \\\n",
            "0  0.005565  54.275636  0.990354  ...  155.298311       0.531565   \n",
            "1  0.006314  44.979346  0.740424  ...  155.147044      -0.481519   \n",
            "2  0.006528  40.196954  0.433265  ...  154.887325       0.716998   \n",
            "3  0.006707  36.327580  0.091949  ...  154.538056      -0.441574   \n",
            "4  0.006770  40.506051 -0.111656  ...  154.299480      -0.340051   \n",
            "\n",
            "     vol_ma_24h  SPY_ret_1h  QQQ_ret_1h  NVDA_ret_1h  hour  day_of_week  \\\n",
            "0  1.222141e+07   -0.000655    0.000349     0.006716    18            2   \n",
            "1  1.245613e+07   -0.010903   -0.012474    -0.017339    19            2   \n",
            "2  1.298858e+07   -0.004611   -0.008574    -0.036974    13            3   \n",
            "3  1.299329e+07   -0.003620   -0.005088    -0.014084    14            3   \n",
            "4  1.284415e+07    0.002056    0.002861     0.002052    15            3   \n",
            "\n",
            "             datetime  ticker  \n",
            "0 2022-09-21 18:30:00    AAPL  \n",
            "1 2022-09-21 19:30:00    AAPL  \n",
            "2 2022-09-22 13:30:00    AAPL  \n",
            "3 2022-09-22 14:30:00    AAPL  \n",
            "4 2022-09-22 15:30:00    AAPL  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation"
      ],
      "metadata": {
        "id": "TKZHysWZZsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "vol_lookback = 24         # hours to compute rolling volatility\n",
        "vol_multiplier = 0.5      # threshold scaling vs volatility\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Volatility-based threshold\n",
        "    rolling_vol = price_series.pct_change().rolling(vol_lookback).std()\n",
        "    threshold = rolling_vol * vol_multiplier\n",
        "\n",
        "    # Label creation\n",
        "    label = future_ret.copy()\n",
        "    label[future_ret > threshold] = 1    # Up\n",
        "    label[future_ret < -threshold] = -1  # Down\n",
        "    label[(future_ret <= threshold) & (future_ret >= -threshold)] = 0  # Neutral\n",
        "\n",
        "    # Drop NaNs\n",
        "    label = label.dropna()\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": label.index,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[label.index],\n",
        "        \"label\": label.values,\n",
        "        \"future_ret\": future_ret.loc[label.index],\n",
        "        \"volatility\": rolling_vol.loc[label.index]\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "print(labels_df[\"label\"].value_counts(normalize=True))\n",
        "labels_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "19e6572a-3700-4399-f712-01f0848e88d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (25370, 6)\n",
            "label\n",
            " 0.000000    0.532519\n",
            " 1.000000    0.244974\n",
            "-1.000000    0.217777\n",
            "-0.005652    0.000039\n",
            "-0.010207    0.000039\n",
            "               ...   \n",
            " 0.001342    0.000039\n",
            "-0.007730    0.000039\n",
            " 0.003572    0.000039\n",
            "-0.000854    0.000039\n",
            "-0.006713    0.000039\n",
            "Name: proportion, Length: 123, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime ticker       price     label  future_ret  volatility\n",
              "0 2022-09-15 13:30:00   AAPL  153.809998 -0.006306   -0.006306         NaN\n",
              "1 2022-09-15 14:30:00   AAPL  152.839996 -0.002486   -0.002486         NaN\n",
              "2 2022-09-15 15:30:00   AAPL  152.460007  0.009543    0.009543         NaN\n",
              "3 2022-09-15 16:30:00   AAPL  153.914993 -0.005652   -0.005652         NaN\n",
              "4 2022-09-15 17:30:00   AAPL  153.044998 -0.010207   -0.010207         NaN\n",
              "5 2022-09-15 18:30:00   AAPL  151.482895  0.005724    0.005724         NaN\n",
              "6 2022-09-15 19:30:00   AAPL  152.350006 -0.018969   -0.018969         NaN\n",
              "7 2022-09-16 13:30:00   AAPL  149.460007 -0.002141   -0.002141         NaN\n",
              "8 2022-09-16 14:30:00   AAPL  149.139999 -0.002496   -0.002496         NaN\n",
              "9 2022-09-16 15:30:00   AAPL  148.767807  0.003443    0.003443         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-427dce0d-266d-4478-907d-b3ca8f17f6ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>label</th>\n",
              "      <th>future_ret</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-15 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.809998</td>\n",
              "      <td>-0.006306</td>\n",
              "      <td>-0.006306</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-15 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.839996</td>\n",
              "      <td>-0.002486</td>\n",
              "      <td>-0.002486</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-15 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.460007</td>\n",
              "      <td>0.009543</td>\n",
              "      <td>0.009543</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-15 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.914993</td>\n",
              "      <td>-0.005652</td>\n",
              "      <td>-0.005652</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-15 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.044998</td>\n",
              "      <td>-0.010207</td>\n",
              "      <td>-0.010207</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-15 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>151.482895</td>\n",
              "      <td>0.005724</td>\n",
              "      <td>0.005724</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-15 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.350006</td>\n",
              "      <td>-0.018969</td>\n",
              "      <td>-0.018969</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-16 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>149.460007</td>\n",
              "      <td>-0.002141</td>\n",
              "      <td>-0.002141</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-09-16 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>149.139999</td>\n",
              "      <td>-0.002496</td>\n",
              "      <td>-0.002496</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-09-16 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>148.767807</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-427dce0d-266d-4478-907d-b3ca8f17f6ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-427dce0d-266d-4478-907d-b3ca8f17f6ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-427dce0d-266d-4478-907d-b3ca8f17f6ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1bf649b1-f489-4bbc-850f-928b010d6eac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bf649b1-f489-4bbc-850f-928b010d6eac')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1bf649b1-f489-4bbc-850f-928b010d6eac button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 25370,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-15 13:30:00\",\n        \"max\": \"2025-08-12 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-09-12 14:30:00\",\n          \"2024-03-21 19:30:00\",\n          \"2022-09-21 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SPY\",\n          \"QQQ\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 165.11083447929246,\n        \"min\": 11.14999008178711,\n        \"max\": 642.3200073242188,\n        \"num_unique_values\": 23045,\n        \"samples\": [\n          242.14999389648438,\n          191.10499572753906,\n          431.9898986816406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6797279165912652,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          0.007970851441836842,\n          0.0072432008287813265,\n          -0.01168479035640154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009395578829484894,\n        \"min\": -0.13022686951739132,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          -0.005606060362088802,\n          0.0012366833336945582,\n          0.0012739324415828206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005538061301030855,\n        \"min\": 0.0008907621389855575,\n        \"max\": 0.05414076773543391,\n        \"num_unique_values\": 25250,\n        \"samples\": [\n          0.018300016743778326,\n          0.005301061408171196,\n          0.001343384396674201\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "rieWxNf5Mp44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1H-ATXHjSK6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Features"
      ],
      "metadata": {
        "id": "_PxZH38IebtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & labels\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y distribution:\\n\", y.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "OERLO3TNed16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa60869b-b588-48ac-80aa-0947dd9aea03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25205, 26)\n",
            "y distribution:\n",
            " label\n",
            " 0.0    0.535013\n",
            " 1.0    0.246102\n",
            "-1.0    0.218885\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale"
      ],
      "metadata": {
        "id": "rpnDnFsiWa87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Label distribution in Train:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "4oxCtsXaSTrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6112046f-e2bb-460b-cfa0-533484bee7d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train: (17631, 26), Val: (3778, 26), Test: (3779, 26)\n",
            "Label distribution in Train: label\n",
            " 0.0    0.525665\n",
            " 1.0    0.251943\n",
            "-1.0    0.222392\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence making - For LSTM AND CNN"
      ],
      "metadata": {
        "id": "euQxLDkaWdBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 24  # last 24 hours to predict next hour\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "id": "mn5XIK9DWlAN",
        "outputId": "92510b42-674c-46de-d7df-436ac8e07683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (17607, 24, 26), Val seq: (3754, 24, 26), Test seq: (3755, 24, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 — label encoding + class weights\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# mapping: -1 -> 0 (down), 0 -> 1 (neutral), 1 -> 2 (up)\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "\n",
        "# If your y_* are numpy arrays (seq labels), convert\n",
        "y_train_seq_mapped = np.vectorize(label_map.get)(y_train_seq)\n",
        "y_val_seq_mapped   = np.vectorize(label_map.get)(y_val_seq)\n",
        "y_test_seq_mapped  = np.vectorize(label_map.get)(y_test_seq)\n",
        "\n",
        "# one-hot for Keras\n",
        "y_train_cat = to_categorical(y_train_seq_mapped, num_classes=3)\n",
        "y_val_cat   = to_categorical(y_val_seq_mapped, num_classes=3)\n",
        "y_test_cat  = to_categorical(y_test_seq_mapped, num_classes=3)\n",
        "\n",
        "# compute class weights from training sequence labels\n",
        "classes = np.unique(y_train_seq_mapped)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_seq_mapped)\n",
        "class_weights_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "print(\"Train class distribution:\", np.bincount(y_train_seq_mapped) / len(y_train_seq_mapped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "918d5e84-dbec-4f09-c9b5-1fa5f01c357a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.5025601638504864), 1: np.float64(0.6336644353271431), 2: np.float64(1.322144627168281)}\n",
            "Train class distribution: [0.22184358 0.52604078 0.25211564]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1jUYMhA9cSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, BatchNormalization, Activation, Dropout,\n",
        "    GlobalAveragePooling1D, Dense, Add\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def residual_block(x, filters, kernel_size, dropout_rate=0.2):\n",
        "    # Shortcut projection if needed\n",
        "    shortcut = x\n",
        "    if x.shape[-1] != filters:\n",
        "        shortcut = Conv1D(filters, kernel_size=1, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_cnn_enhanced(input_shape, n_classes=3, dropout_rate=0.3):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution\n",
        "    x = Conv1D(64, kernel_size=3, padding='same')(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks with increasing filters\n",
        "    x = residual_block(x, 64, 3, dropout_rate=dropout_rate)\n",
        "    x = residual_block(x, 128, 5, dropout_rate=dropout_rate)\n",
        "    x = residual_block(x, 256, 3, dropout_rate=dropout_rate)\n",
        "\n",
        "    # Global pooling + Dense layers\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "cnn_model = build_cnn_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.3)\n",
        "cnn_model.summary()\n"
      ],
      "metadata": {
        "id": "2mDqNrx0SddA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30923b4b-9430-4518-bfde-2326a46d000d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m5,056\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m82,048\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m594,115\u001b[0m (2.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">594,115</span> (2.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m591,427\u001b[0m (2.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,427</span> (2.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,688\u001b[0m (10.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> (10.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "-p_nIYgVcWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, Bidirectional, LSTM, GRU, Dense, Dropout,\n",
        "    LayerNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
        "    Concatenate, Attention\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_lstm_enhanced(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = LayerNormalization()(inp)\n",
        "\n",
        "    # First BiLSTM layer\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Second BiGRU layer (faster and adds diversity in sequence modeling)\n",
        "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Self-Attention layer\n",
        "    attn_data = Attention()([x, x])\n",
        "    x = Concatenate()([x, attn_data])  # fuse original and attention output\n",
        "\n",
        "    # Pooling\n",
        "    x_avg = GlobalAveragePooling1D()(x)\n",
        "    x_max = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([x_avg, x_max])\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate model\n",
        "lstm_model = build_lstm_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "id": "IYtsddwpfp1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "ce1b42e4-da22-4a59-daf2-bc9fa3417ccb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │         \u001b[38;5;34m52\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m158,720\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m123,648\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,720</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "7FalnDi8fxYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import numpy as np\n",
        "\n",
        "# Map labels to 0,1,2\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "y_train_tab = np.vectorize(label_map.get)(y_train)\n",
        "y_val_tab   = np.vectorize(label_map.get)(y_val)\n",
        "y_test_tab  = np.vectorize(label_map.get)(y_test)\n",
        "\n",
        "# Class-balanced sample weights\n",
        "sample_weight = compute_sample_weight('balanced', y_train_tab)\n",
        "\n",
        "# Class imbalance handling (per-class scaling)\n",
        "class_counts = np.bincount(y_train_tab)\n",
        "total = len(y_train_tab)\n",
        "scale_weights = [total / (len(class_counts) * c) for c in class_counts]\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=3,\n",
        "    n_estimators=600,               # more trees for better learning\n",
        "    learning_rate=0.03,             # lower LR for more stable learning\n",
        "    max_depth=6,                    # slightly deeper trees\n",
        "    max_leaves=32,                   # controls tree complexity\n",
        "    min_child_weight=3,              # avoids too-specific splits\n",
        "    gamma=1,                         # min loss reduction to split\n",
        "    subsample=0.85,                  # random row sampling\n",
        "    colsample_bytree=0.85,           # random feature sampling\n",
        "    reg_alpha=0.1,                   # L1 regularization\n",
        "    reg_lambda=1.0,                  # L2 regularization\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',              # fast CPU method; use 'gpu_hist' if GPU is available\n",
        "    scale_pos_weight=scale_weights[1], # handles imbalance for the positive class (for binary) — here we might ignore for multi\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EjSEPd16f61x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "TKR7NlqVaq34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cOvOaClz5nPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if supported\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile with lower LR initially for stability\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_cnn_full_model.keras',  # save full model, not just weights\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/cnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "cdd2e85f-ad31-4ec6-f6ea-87d1d48830a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.04029, saving model to best_cnn_full_model.keras\n",
            "138/138 - 71s - 512ms/step - accuracy: 0.3712 - loss: 1.1075 - val_accuracy: 0.5210 - val_loss: 1.0403 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.04029 to 1.03289, saving model to best_cnn_full_model.keras\n",
            "138/138 - 78s - 566ms/step - accuracy: 0.4226 - loss: 1.0860 - val_accuracy: 0.5218 - val_loss: 1.0329 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.03289 to 1.02560, saving model to best_cnn_full_model.keras\n",
            "138/138 - 77s - 561ms/step - accuracy: 0.4412 - loss: 1.0740 - val_accuracy: 0.4899 - val_loss: 1.0256 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.02560\n",
            "138/138 - 46s - 334ms/step - accuracy: 0.4487 - loss: 1.0697 - val_accuracy: 0.4531 - val_loss: 1.0604 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.02560\n",
            "138/138 - 79s - 576ms/step - accuracy: 0.4589 - loss: 1.0630 - val_accuracy: 0.4385 - val_loss: 1.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.02560\n",
            "138/138 - 84s - 612ms/step - accuracy: 0.4695 - loss: 1.0560 - val_accuracy: 0.4475 - val_loss: 1.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.02560\n",
            "138/138 - 80s - 583ms/step - accuracy: 0.4754 - loss: 1.0480 - val_accuracy: 0.4172 - val_loss: 1.1060 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.02560\n",
            "138/138 - 82s - 595ms/step - accuracy: 0.4962 - loss: 1.0305 - val_accuracy: 0.4470 - val_loss: 1.0719 - learning_rate: 2.5000e-04\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.02560\n",
            "138/138 - 45s - 325ms/step - accuracy: 0.4964 - loss: 1.0184 - val_accuracy: 0.4576 - val_loss: 1.0687 - learning_rate: 2.5000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.02560\n",
            "138/138 - 83s - 600ms/step - accuracy: 0.4975 - loss: 1.0106 - val_accuracy: 0.4172 - val_loss: 1.1004 - learning_rate: 2.5000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.02560\n",
            "138/138 - 81s - 587ms/step - accuracy: 0.5045 - loss: 1.0040 - val_accuracy: 0.3873 - val_loss: 1.1518 - learning_rate: 2.5000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.02560\n",
            "138/138 - 44s - 316ms/step - accuracy: 0.5152 - loss: 0.9868 - val_accuracy: 0.3668 - val_loss: 1.1714 - learning_rate: 1.2500e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.02560\n",
            "138/138 - 45s - 326ms/step - accuracy: 0.5248 - loss: 0.9774 - val_accuracy: 0.3649 - val_loss: 1.1927 - learning_rate: 1.2500e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yxu1niZ7gq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if GPU supports it (LSTMs benefit less than CNNs, but still good for speed)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile LSTM with gradient clipping (helps with exploding gradients in RNNs)\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_lstm_full_model.keras',  # Save entire model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/lstm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=120,  # Give it more room to converge\n",
        "    batch_size=96,  # Smaller batch size often helps LSTM generalization\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "a4a38fed-534a-4b22-bb39-4cedb8f74da5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.11007, saving model to best_lstm_full_model.keras\n",
            "184/184 - 52s - 282ms/step - accuracy: 0.4028 - loss: 1.0911 - val_accuracy: 0.3559 - val_loss: 1.1101 - learning_rate: 3.0000e-04\n",
            "Epoch 2/120\n",
            "\n",
            "Epoch 2: val_loss improved from 1.11007 to 1.10278, saving model to best_lstm_full_model.keras\n",
            "184/184 - 83s - 449ms/step - accuracy: 0.4341 - loss: 1.0773 - val_accuracy: 0.3974 - val_loss: 1.1028 - learning_rate: 3.0000e-04\n",
            "Epoch 3/120\n",
            "\n",
            "Epoch 3: val_loss improved from 1.10278 to 1.09241, saving model to best_lstm_full_model.keras\n",
            "184/184 - 83s - 452ms/step - accuracy: 0.4436 - loss: 1.0696 - val_accuracy: 0.4012 - val_loss: 1.0924 - learning_rate: 3.0000e-04\n",
            "Epoch 4/120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.09241\n",
            "184/184 - 81s - 439ms/step - accuracy: 0.4447 - loss: 1.0633 - val_accuracy: 0.3934 - val_loss: 1.0939 - learning_rate: 3.0000e-04\n",
            "Epoch 5/120\n",
            "\n",
            "Epoch 5: val_loss improved from 1.09241 to 1.07823, saving model to best_lstm_full_model.keras\n",
            "184/184 - 45s - 243ms/step - accuracy: 0.4569 - loss: 1.0528 - val_accuracy: 0.4294 - val_loss: 1.0782 - learning_rate: 3.0000e-04\n",
            "Epoch 6/120\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.07823\n",
            "184/184 - 80s - 435ms/step - accuracy: 0.4685 - loss: 1.0421 - val_accuracy: 0.4361 - val_loss: 1.0839 - learning_rate: 3.0000e-04\n",
            "Epoch 7/120\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.07823\n",
            "184/184 - 81s - 439ms/step - accuracy: 0.4786 - loss: 1.0315 - val_accuracy: 0.4153 - val_loss: 1.0980 - learning_rate: 3.0000e-04\n",
            "Epoch 8/120\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.07823\n",
            "184/184 - 87s - 470ms/step - accuracy: 0.4905 - loss: 1.0158 - val_accuracy: 0.4347 - val_loss: 1.0802 - learning_rate: 3.0000e-04\n",
            "Epoch 9/120\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.07823\n",
            "184/184 - 78s - 421ms/step - accuracy: 0.4963 - loss: 0.9998 - val_accuracy: 0.4204 - val_loss: 1.0988 - learning_rate: 3.0000e-04\n",
            "Epoch 10/120\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.07823\n",
            "184/184 - 46s - 250ms/step - accuracy: 0.5208 - loss: 0.9744 - val_accuracy: 0.3903 - val_loss: 1.1377 - learning_rate: 1.5000e-04\n",
            "Epoch 11/120\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.07823\n",
            "184/184 - 78s - 423ms/step - accuracy: 0.5323 - loss: 0.9547 - val_accuracy: 0.3905 - val_loss: 1.1384 - learning_rate: 1.5000e-04\n",
            "Epoch 12/120\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.07823\n",
            "184/184 - 42s - 228ms/step - accuracy: 0.5371 - loss: 0.9436 - val_accuracy: 0.3926 - val_loss: 1.1468 - learning_rate: 1.5000e-04\n",
            "Epoch 13/120\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.07823\n",
            "184/184 - 44s - 241ms/step - accuracy: 0.5406 - loss: 0.9264 - val_accuracy: 0.3751 - val_loss: 1.1764 - learning_rate: 1.5000e-04\n",
            "Epoch 14/120\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.07823\n",
            "184/184 - 80s - 433ms/step - accuracy: 0.5621 - loss: 0.9038 - val_accuracy: 0.3775 - val_loss: 1.1840 - learning_rate: 7.5000e-05\n",
            "Epoch 15/120\n",
            "\n",
            "Epoch 15: val_loss did not improve from 1.07823\n",
            "184/184 - 83s - 452ms/step - accuracy: 0.5652 - loss: 0.8927 - val_accuracy: 0.3783 - val_loss: 1.1931 - learning_rate: 7.5000e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "2RHWbvELgyIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ============================\n",
        "# Optuna objective function\n",
        "# ============================\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 3,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'hist',  # Change to 'gpu_hist' if GPU available\n",
        "        'seed': 42,\n",
        "\n",
        "        # Hyperparameters to tune\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),\n",
        "    }\n",
        "\n",
        "    # DMatrix objects\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train_tab)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val_tab)\n",
        "\n",
        "    # Train with early stopping\n",
        "    evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "    model = xgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=1000,\n",
        "        evals=evals,\n",
        "        early_stopping_rounds=30,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "\n",
        "    # Validation predictions\n",
        "    preds = model.predict(dval)\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "    return accuracy_score(y_val_tab, pred_labels)\n",
        "\n",
        "# ============================\n",
        "# Run Optuna study\n",
        "# ============================\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # Try 50 parameter sets\n",
        "\n",
        "print(\"\\nBest parameters:\", study.best_params)\n",
        "print(\"Best validation accuracy:\", study.best_value)\n",
        "\n",
        "# ============================\n",
        "# Train final model with best params\n",
        "# ============================\n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 3,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'hist',  # Or 'gpu_hist'\n",
        "    'seed': 42\n",
        "})\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_tab)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_tab)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "final_model = xgb.train(\n",
        "    best_params,\n",
        "    dtrain,\n",
        "    num_boost_round=1500,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=30,\n",
        "    verbose_eval=50\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# Evaluate on test set\n",
        "# ============================\n",
        "y_prob = final_model.predict(dtest)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "test_acc = accuracy_score(y_test_tab, y_pred)\n",
        "print(\"\\nFinal Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOUy9Yd0g-6E",
        "outputId": "2c3bb8c6-9d08-41ad-9de5-325bc9f6edfa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-12 23:33:49,893] A new study created in memory with name: no-name-d29689a2-a78a-403a-8628-9b36e807b56c\n",
            "[I 2025-08-12 23:33:52,083] Trial 0 finished with value: 0.5592906299629433 and parameters: {'max_depth': 5, 'learning_rate': 0.07600332647265602, 'subsample': 0.8710189653961591, 'colsample_bytree': 0.9211959760616713, 'gamma': 2.5316284341212425, 'min_child_weight': 10, 'reg_alpha': 0.48571488465098556, 'reg_lambda': 1.1757206283351085}. Best is trial 0 with value: 0.5592906299629433.\n",
            "[I 2025-08-12 23:34:02,593] Trial 1 finished with value: 0.55214399152991 and parameters: {'max_depth': 10, 'learning_rate': 0.033405949784497437, 'subsample': 0.9950728988132826, 'colsample_bytree': 0.8221532660173048, 'gamma': 1.4716349328574752, 'min_child_weight': 4, 'reg_alpha': 0.8892515189914093, 'reg_lambda': 1.4341069571961513}. Best is trial 0 with value: 0.5592906299629433.\n",
            "[I 2025-08-12 23:34:08,179] Trial 2 finished with value: 0.542350449973531 and parameters: {'max_depth': 9, 'learning_rate': 0.1150618819762495, 'subsample': 0.7775126011020782, 'colsample_bytree': 0.8873923167644543, 'gamma': 1.0766490081927582, 'min_child_weight': 4, 'reg_alpha': 0.07826041001788075, 'reg_lambda': 2.4763008831400457}. Best is trial 0 with value: 0.5592906299629433.\n",
            "[I 2025-08-12 23:34:13,100] Trial 3 finished with value: 0.5667019587083113 and parameters: {'max_depth': 7, 'learning_rate': 0.021934190802386396, 'subsample': 0.7954306402039599, 'colsample_bytree': 0.9637287606297265, 'gamma': 3.753386094905249, 'min_child_weight': 4, 'reg_alpha': 0.7862314751450973, 'reg_lambda': 2.4592692806480634}. Best is trial 3 with value: 0.5667019587083113.\n",
            "[I 2025-08-12 23:34:14,359] Trial 4 finished with value: 0.5494970884065643 and parameters: {'max_depth': 6, 'learning_rate': 0.18211283701337747, 'subsample': 0.6341099612651563, 'colsample_bytree': 0.9782247962961715, 'gamma': 0.6521696281825184, 'min_child_weight': 5, 'reg_alpha': 0.32663885149161753, 'reg_lambda': 2.591440259206096}. Best is trial 3 with value: 0.5667019587083113.\n",
            "[I 2025-08-12 23:34:25,169] Trial 5 finished with value: 0.5643197458973002 and parameters: {'max_depth': 5, 'learning_rate': 0.011729403183231315, 'subsample': 0.8550760629215051, 'colsample_bytree': 0.956293861944964, 'gamma': 0.12326923431973835, 'min_child_weight': 7, 'reg_alpha': 0.7087041741947724, 'reg_lambda': 1.6528001959266432}. Best is trial 3 with value: 0.5667019587083113.\n",
            "[I 2025-08-12 23:34:28,367] Trial 6 finished with value: 0.5526733721545791 and parameters: {'max_depth': 7, 'learning_rate': 0.08691834583045417, 'subsample': 0.7068090622164647, 'colsample_bytree': 0.9021905061699399, 'gamma': 0.9414861460291024, 'min_child_weight': 1, 'reg_alpha': 0.4776654494971747, 'reg_lambda': 0.5818091098432233}. Best is trial 3 with value: 0.5667019587083113.\n",
            "[I 2025-08-12 23:34:29,682] Trial 7 finished with value: 0.5587612493382742 and parameters: {'max_depth': 10, 'learning_rate': 0.20119325432162075, 'subsample': 0.661179363152658, 'colsample_bytree': 0.8086271114702398, 'gamma': 3.375866511365232, 'min_child_weight': 3, 'reg_alpha': 0.21674495046525888, 'reg_lambda': 2.240735690358863}. Best is trial 3 with value: 0.5667019587083113.\n",
            "[I 2025-08-12 23:34:32,674] Trial 8 finished with value: 0.5497617787188989 and parameters: {'max_depth': 8, 'learning_rate': 0.19002611846323908, 'subsample': 0.9945207044804253, 'colsample_bytree': 0.6195746880152379, 'gamma': 1.0977603052783818, 'min_child_weight': 6, 'reg_alpha': 0.8429740151983477, 'reg_lambda': 1.1122216626485928}. Best is trial 3 with value: 0.5667019587083113.\n",
            "[I 2025-08-12 23:34:34,418] Trial 9 finished with value: 0.5685547908946532 and parameters: {'max_depth': 7, 'learning_rate': 0.0643430847733715, 'subsample': 0.8364049488010266, 'colsample_bytree': 0.7565864907091722, 'gamma': 4.877539054107746, 'min_child_weight': 5, 'reg_alpha': 0.4691538725307093, 'reg_lambda': 2.107226029502216}. Best is trial 9 with value: 0.5685547908946532.\n",
            "[I 2025-08-12 23:34:37,095] Trial 10 finished with value: 0.5696135521439916 and parameters: {'max_depth': 3, 'learning_rate': 0.0440945956128724, 'subsample': 0.9007067629045601, 'colsample_bytree': 0.6748722287234654, 'gamma': 4.999674245935457, 'min_child_weight': 8, 'reg_alpha': 0.6153634009301684, 'reg_lambda': 2.9598179984112605}. Best is trial 10 with value: 0.5696135521439916.\n",
            "[I 2025-08-12 23:34:38,836] Trial 11 finished with value: 0.5672313393329804 and parameters: {'max_depth': 3, 'learning_rate': 0.042515490214647345, 'subsample': 0.8988604993234859, 'colsample_bytree': 0.6740174479674066, 'gamma': 4.973111980329821, 'min_child_weight': 8, 'reg_alpha': 0.663216862655624, 'reg_lambda': 2.9697044427441064}. Best is trial 10 with value: 0.5696135521439916.\n",
            "[I 2025-08-12 23:34:44,763] Trial 12 finished with value: 0.5706723133933298 and parameters: {'max_depth': 3, 'learning_rate': 0.025142329046448857, 'subsample': 0.9425397184511817, 'colsample_bytree': 0.7126184411765935, 'gamma': 4.961892466201912, 'min_child_weight': 9, 'reg_alpha': 0.5876106520340865, 'reg_lambda': 2.029338516327145}. Best is trial 12 with value: 0.5706723133933298.\n",
            "[I 2025-08-12 23:34:48,253] Trial 13 finished with value: 0.5706723133933298 and parameters: {'max_depth': 3, 'learning_rate': 0.02168899457320418, 'subsample': 0.9321076835349991, 'colsample_bytree': 0.7110893532620008, 'gamma': 4.089085860148662, 'min_child_weight': 10, 'reg_alpha': 0.6249277170520513, 'reg_lambda': 2.9899941739161267}. Best is trial 12 with value: 0.5706723133933298.\n",
            "[I 2025-08-12 23:34:53,127] Trial 14 finished with value: 0.5690841715193224 and parameters: {'max_depth': 4, 'learning_rate': 0.01766479631379262, 'subsample': 0.9420531883263594, 'colsample_bytree': 0.7335414989949353, 'gamma': 3.9363971875974366, 'min_child_weight': 10, 'reg_alpha': 0.6202791294510268, 'reg_lambda': 1.9632894716789873}. Best is trial 12 with value: 0.5706723133933298.\n",
            "[I 2025-08-12 23:34:58,399] Trial 15 finished with value: 0.5709370037056644 and parameters: {'max_depth': 4, 'learning_rate': 0.023077855512057485, 'subsample': 0.944048431462186, 'colsample_bytree': 0.7153850944737571, 'gamma': 4.2436939595727825, 'min_child_weight': 9, 'reg_alpha': 0.9964541710993902, 'reg_lambda': 1.7790917727640438}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:04,920] Trial 16 finished with value: 0.5690841715193224 and parameters: {'max_depth': 4, 'learning_rate': 0.013344650883956144, 'subsample': 0.9517419644716153, 'colsample_bytree': 0.7788619127615737, 'gamma': 3.1354234011273077, 'min_child_weight': 8, 'reg_alpha': 0.9540389934877735, 'reg_lambda': 1.7249801200825636}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:09,933] Trial 17 finished with value: 0.5667019587083113 and parameters: {'max_depth': 4, 'learning_rate': 0.02629310229746725, 'subsample': 0.7462349338409571, 'colsample_bytree': 0.6109313344816489, 'gamma': 4.373313141880116, 'min_child_weight': 9, 'reg_alpha': 0.9788863935092778, 'reg_lambda': 1.4984768435030649}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:13,187] Trial 18 finished with value: 0.5661725780836422 and parameters: {'max_depth': 5, 'learning_rate': 0.03172451032115524, 'subsample': 0.8270366349060655, 'colsample_bytree': 0.8501955571738352, 'gamma': 2.3362473529861747, 'min_child_weight': 9, 'reg_alpha': 0.32763285932474245, 'reg_lambda': 1.9328244962982577}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:18,759] Trial 19 finished with value: 0.567496029645315 and parameters: {'max_depth': 6, 'learning_rate': 0.015962141471814364, 'subsample': 0.9629285365716085, 'colsample_bytree': 0.6719670904722432, 'gamma': 4.346438198337119, 'min_child_weight': 7, 'reg_alpha': 0.7740209574175354, 'reg_lambda': 0.8152293303282221}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:28,618] Trial 20 finished with value: 0.5667019587083113 and parameters: {'max_depth': 4, 'learning_rate': 0.01088999436311888, 'subsample': 0.9027336366770193, 'colsample_bytree': 0.7148802364773357, 'gamma': 2.8439813436846184, 'min_child_weight': 7, 'reg_alpha': 0.07914163721997014, 'reg_lambda': 1.2909209436631126}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:31,937] Trial 21 finished with value: 0.5709370037056644 and parameters: {'max_depth': 3, 'learning_rate': 0.0253018503064059, 'subsample': 0.9256856539734183, 'colsample_bytree': 0.7219172345821485, 'gamma': 4.330393352284256, 'min_child_weight': 10, 'reg_alpha': 0.559572320545067, 'reg_lambda': 2.7046047797505057}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:35,640] Trial 22 finished with value: 0.5690841715193224 and parameters: {'max_depth': 3, 'learning_rate': 0.0444384429022931, 'subsample': 0.9184797162847456, 'colsample_bytree': 0.7534738731204143, 'gamma': 4.4343261240142935, 'min_child_weight': 9, 'reg_alpha': 0.3949919411016022, 'reg_lambda': 2.655496182297124}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:40,420] Trial 23 finished with value: 0.5704076230809952 and parameters: {'max_depth': 3, 'learning_rate': 0.02857752365764309, 'subsample': 0.9759294007013899, 'colsample_bytree': 0.6542053603639733, 'gamma': 3.5894104729795324, 'min_child_weight': 9, 'reg_alpha': 0.5617075812320158, 'reg_lambda': 2.251926639205975}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:45,006] Trial 24 finished with value: 0.5685547908946532 and parameters: {'max_depth': 4, 'learning_rate': 0.02011721914036019, 'subsample': 0.876756415707431, 'colsample_bytree': 0.7158643940292195, 'gamma': 4.698774867792135, 'min_child_weight': 10, 'reg_alpha': 0.21396664212542893, 'reg_lambda': 1.895901144545984}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:47,239] Trial 25 finished with value: 0.5571731074642668 and parameters: {'max_depth': 5, 'learning_rate': 0.2998782345270222, 'subsample': 0.9574256713888075, 'colsample_bytree': 0.7778154622988278, 'gamma': 2.0288365544642253, 'min_child_weight': 8, 'reg_alpha': 0.7240062937619889, 'reg_lambda': 2.7278055359323945}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:49,451] Trial 26 finished with value: 0.569348861831657 and parameters: {'max_depth': 3, 'learning_rate': 0.0359998859577088, 'subsample': 0.9313726790147249, 'colsample_bytree': 0.6397045230872243, 'gamma': 4.10013304326533, 'min_child_weight': 9, 'reg_alpha': 0.5531216501400473, 'reg_lambda': 2.2722248223374395}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:35:54,297] Trial 27 finished with value: 0.569348861831657 and parameters: {'max_depth': 4, 'learning_rate': 0.015306071662993189, 'subsample': 0.882942652209057, 'colsample_bytree': 0.6941738505919169, 'gamma': 4.572312256171504, 'min_child_weight': 6, 'reg_alpha': 0.8886867155526589, 'reg_lambda': 1.6555784822485333}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:36:00,230] Trial 28 finished with value: 0.5672313393329804 and parameters: {'max_depth': 6, 'learning_rate': 0.02438156583188946, 'subsample': 0.8303242980492946, 'colsample_bytree': 0.8358370538876286, 'gamma': 3.4522693926480694, 'min_child_weight': 10, 'reg_alpha': 0.3741703666432054, 'reg_lambda': 2.105922108236978}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:36:02,010] Trial 29 finished with value: 0.5659078877713075 and parameters: {'max_depth': 5, 'learning_rate': 0.05659556701746744, 'subsample': 0.8650049144809617, 'colsample_bytree': 0.7446327527544452, 'gamma': 2.948016044951943, 'min_child_weight': 9, 'reg_alpha': 0.21815445281148427, 'reg_lambda': 1.0442646923191754}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:36:03,134] Trial 30 finished with value: 0.5696135521439916 and parameters: {'max_depth': 3, 'learning_rate': 0.09529518646499895, 'subsample': 0.9832307882892752, 'colsample_bytree': 0.7903021224214436, 'gamma': 4.045281520937926, 'min_child_weight': 8, 'reg_alpha': 0.5471364389200933, 'reg_lambda': 1.4616272584206889}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:36:07,317] Trial 31 finished with value: 0.5706723133933298 and parameters: {'max_depth': 3, 'learning_rate': 0.019800827928399753, 'subsample': 0.9246378696757819, 'colsample_bytree': 0.7040035137842245, 'gamma': 4.080873592573093, 'min_child_weight': 10, 'reg_alpha': 0.45011469631209006, 'reg_lambda': 2.8380559228281395}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:36:12,121] Trial 32 finished with value: 0.5698782424563261 and parameters: {'max_depth': 4, 'learning_rate': 0.024494282244337712, 'subsample': 0.9339670578245703, 'colsample_bytree': 0.7285792164912607, 'gamma': 4.624052071632288, 'min_child_weight': 10, 'reg_alpha': 0.6377563285367162, 'reg_lambda': 2.7701475241194586}. Best is trial 15 with value: 0.5709370037056644.\n",
            "[I 2025-08-12 23:36:15,107] Trial 33 finished with value: 0.571731074642668 and parameters: {'max_depth': 3, 'learning_rate': 0.03407386996058154, 'subsample': 0.9629923068450824, 'colsample_bytree': 0.6923315161482684, 'gamma': 3.7653520980292194, 'min_child_weight': 10, 'reg_alpha': 0.7741452443185516, 'reg_lambda': 2.3570454993861536}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:18,075] Trial 34 finished with value: 0.5701429327686607 and parameters: {'max_depth': 4, 'learning_rate': 0.035495557118003965, 'subsample': 0.9940062029047503, 'colsample_bytree': 0.6409302980434395, 'gamma': 3.740890617206687, 'min_child_weight': 9, 'reg_alpha': 0.9059283454400778, 'reg_lambda': 2.4602888236590164}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:20,987] Trial 35 finished with value: 0.5706723133933298 and parameters: {'max_depth': 3, 'learning_rate': 0.03059350712255753, 'subsample': 0.9651043358565358, 'colsample_bytree': 0.6808235038371064, 'gamma': 3.2788021794621196, 'min_child_weight': 10, 'reg_alpha': 0.7887125572154869, 'reg_lambda': 2.379250309167789}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:25,355] Trial 36 finished with value: 0.5659078877713075 and parameters: {'max_depth': 8, 'learning_rate': 0.04872324486823513, 'subsample': 0.7568407916203804, 'colsample_bytree': 0.7576090061206648, 'gamma': 3.7192011144588983, 'min_child_weight': 7, 'reg_alpha': 0.8341758590938736, 'reg_lambda': 2.546324012477084}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:28,706] Trial 37 finished with value: 0.5629962943356274 and parameters: {'max_depth': 5, 'learning_rate': 0.03691167899660012, 'subsample': 0.9092978266903511, 'colsample_bytree': 0.6549685593027761, 'gamma': 1.880116803392284, 'min_child_weight': 1, 'reg_alpha': 0.6741483105836891, 'reg_lambda': 2.083761937387346}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:30,150] Trial 38 finished with value: 0.5677607199576495 and parameters: {'max_depth': 3, 'learning_rate': 0.06373981633630679, 'subsample': 0.8528002194948635, 'colsample_bytree': 0.6941005766094983, 'gamma': 4.280764090422299, 'min_child_weight': 3, 'reg_alpha': 0.7379459935077182, 'reg_lambda': 1.853720354873232}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:37,141] Trial 39 finished with value: 0.5698782424563261 and parameters: {'max_depth': 4, 'learning_rate': 0.012855293895462177, 'subsample': 0.9732929519648492, 'colsample_bytree': 0.6028016706083487, 'gamma': 4.789873804422365, 'min_child_weight': 8, 'reg_alpha': 0.9340649850781472, 'reg_lambda': 2.393798992822659}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:42,227] Trial 40 finished with value: 0.5709370037056644 and parameters: {'max_depth': 3, 'learning_rate': 0.018169566495504587, 'subsample': 0.8006612849478167, 'colsample_bytree': 0.858606821094286, 'gamma': 3.856228148276696, 'min_child_weight': 9, 'reg_alpha': 0.8404029248217271, 'reg_lambda': 1.5424357678855543}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:45,149] Trial 41 finished with value: 0.5704076230809952 and parameters: {'max_depth': 3, 'learning_rate': 0.024456726938374973, 'subsample': 0.7003411690006538, 'colsample_bytree': 0.8793388057744698, 'gamma': 3.8432966305916607, 'min_child_weight': 9, 'reg_alpha': 0.7643510069198269, 'reg_lambda': 1.7879654230612472}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:36:51,907] Trial 42 finished with value: 0.5680254102699841 and parameters: {'max_depth': 3, 'learning_rate': 0.017526311099655176, 'subsample': 0.803428845674556, 'colsample_bytree': 0.8679528393354364, 'gamma': 4.5591357502623335, 'min_child_weight': 10, 'reg_alpha': 0.8569024516075914, 'reg_lambda': 1.3265032863024917}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:04,130] Trial 43 finished with value: 0.563790365272631 and parameters: {'max_depth': 9, 'learning_rate': 0.010125500024602439, 'subsample': 0.6167207833522158, 'colsample_bytree': 0.9393780490871542, 'gamma': 3.560061018416866, 'min_child_weight': 9, 'reg_alpha': 0.8142362123991402, 'reg_lambda': 1.576552209670671}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:11,957] Trial 44 finished with value: 0.569348861831657 and parameters: {'max_depth': 4, 'learning_rate': 0.014115556736351023, 'subsample': 0.9997317529181806, 'colsample_bytree': 0.8180272118007876, 'gamma': 4.232267863285701, 'min_child_weight': 10, 'reg_alpha': 0.9974582601997588, 'reg_lambda': 2.2250441203684157}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:17,944] Trial 45 finished with value: 0.567496029645315 and parameters: {'max_depth': 3, 'learning_rate': 0.019986739924165556, 'subsample': 0.6735936931204439, 'colsample_bytree': 0.7696249767760939, 'gamma': 2.717242117689617, 'min_child_weight': 8, 'reg_alpha': 0.692676607069767, 'reg_lambda': 2.0130334089902933}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:21,157] Trial 46 finished with value: 0.5701429327686607 and parameters: {'max_depth': 3, 'learning_rate': 0.02941679494872955, 'subsample': 0.8872801982695263, 'colsample_bytree': 0.7994586392505177, 'gamma': 3.139355594865701, 'min_child_weight': 7, 'reg_alpha': 0.5095259182287376, 'reg_lambda': 2.58808456353353}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:28,634] Trial 47 finished with value: 0.5685547908946532 and parameters: {'max_depth': 5, 'learning_rate': 0.017590998624809267, 'subsample': 0.7745148640078688, 'colsample_bytree': 0.9061937130282204, 'gamma': 4.772511275376513, 'min_child_weight': 10, 'reg_alpha': 0.8850553349711486, 'reg_lambda': 1.7673563762013866}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:31,900] Trial 48 finished with value: 0.5677607199576495 and parameters: {'max_depth': 4, 'learning_rate': 0.022263426215250702, 'subsample': 0.9534205218924715, 'colsample_bytree': 0.9930299084441173, 'gamma': 4.987037383018939, 'min_child_weight': 9, 'reg_alpha': 0.5863571357373378, 'reg_lambda': 2.160323855517841}. Best is trial 33 with value: 0.571731074642668.\n",
            "[I 2025-08-12 23:37:35,862] Trial 49 finished with value: 0.5680254102699841 and parameters: {'max_depth': 3, 'learning_rate': 0.027105807753805895, 'subsample': 0.810077396381715, 'colsample_bytree': 0.730974890863068, 'gamma': 0.11288556117381932, 'min_child_weight': 4, 'reg_alpha': 0.9608666648724559, 'reg_lambda': 1.6289509658310672}. Best is trial 33 with value: 0.571731074642668.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters: {'max_depth': 3, 'learning_rate': 0.03407386996058154, 'subsample': 0.9629923068450824, 'colsample_bytree': 0.6923315161482684, 'gamma': 3.7653520980292194, 'min_child_weight': 10, 'reg_alpha': 0.7741452443185516, 'reg_lambda': 2.3570454993861536}\n",
            "Best validation accuracy: 0.571731074642668\n",
            "[0]\ttrain-mlogloss:1.09280\teval-mlogloss:1.09255\n",
            "[50]\ttrain-mlogloss:0.98363\teval-mlogloss:0.98191\n",
            "[100]\ttrain-mlogloss:0.96570\teval-mlogloss:0.96710\n",
            "[150]\ttrain-mlogloss:0.95835\teval-mlogloss:0.96328\n",
            "[200]\ttrain-mlogloss:0.95464\teval-mlogloss:0.96199\n",
            "[250]\ttrain-mlogloss:0.95196\teval-mlogloss:0.96152\n",
            "[300]\ttrain-mlogloss:0.95103\teval-mlogloss:0.96135\n",
            "[350]\ttrain-mlogloss:0.95042\teval-mlogloss:0.96133\n",
            "[352]\ttrain-mlogloss:0.95042\teval-mlogloss:0.96133\n",
            "\n",
            "Final Test Accuracy: 0.5792537708388462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-O-F Predictions"
      ],
      "metadata": {
        "id": "Di2jwJEwhUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ==== Combine your split data back into one dataset ====\n",
        "X_tab = np.vstack([X_train, X_val, X_test])\n",
        "y_tab = np.concatenate([y_train, y_val, y_test])\n",
        "y_tab = pd.Series(y_tab)  # needed for .map()\n",
        "\n",
        "# ==== Time series split config ====\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# ==== Label remap (-1, 0, 1) -> (0, 1, 2) ====\n",
        "label_map = {-1: 0, 0: 1, 1: 2}\n",
        "\n",
        "# ==== One-hot encoder for DL models ====\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "y_all_mapped = y_tab.map(label_map)\n",
        "y_all_oh = enc.fit_transform(y_all_mapped.values.reshape(-1, 1))\n",
        "\n",
        "# ==== Storage for OOF predictions ====\n",
        "oof_cnn = np.zeros((len(X_tab), 3))\n",
        "oof_lstm = np.zeros((len(X_tab), 3))\n",
        "oof_xgb = np.zeros((len(X_tab), 3))\n",
        "\n",
        "# ==== Ensure tabular and sequence data match in length ====\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_all_mapped))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_all_mapped_aligned = y_all_mapped.iloc[:min_len]\n",
        "y_all_oh_aligned = y_all_oh[:min_len]\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_all_mapped_aligned.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BstRtL0ehVta",
        "outputId": "d75ade4b-bdcc-4896-fe48-16566f0ee435"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(17607, 26), seq=(17607, 24, 26), y=(17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    cnn_model = build_cnn_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3NN2CkhDvJ",
        "outputId": "70b62038-eecb-49f0-933b-a7a8fa5a8af6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating CNN OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    lstm_model = build_lstm_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUIXAYdhGJ4",
        "outputId": "7c259d4b-6819-4c49-a71a-57a915dc19a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating LSTM OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Tabular split\n",
        "    X_tr_tab, X_va_tab = X_tab_aligned[train_idx], X_tab_aligned[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_all_mapped_aligned.iloc[train_idx], y_all_mapped_aligned.iloc[val_idx]\n",
        "\n",
        "    # Build with best parameters\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        num_class=3,\n",
        "        max_depth=3,\n",
        "        learning_rate=0.02845916357450999,\n",
        "        subsample=0.7552507762672391,\n",
        "        colsample_bytree=0.6666641910069,\n",
        "        gamma=4.394916003559231,\n",
        "        min_child_weight=5,\n",
        "        reg_alpha=0.5856294446650139,\n",
        "        reg_lambda=1.838450350300456,\n",
        "        n_estimators=300,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_clf.fit(X_tr_tab, y_tr_tab)\n",
        "\n",
        "    # Predict\n",
        "    oof_xgb[val_idx] = xgb_clf.predict_proba(X_va_tab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlbAkv81hL4f",
        "outputId": "cb68e21c-9d44-49d7-a6cc-289a8dce6c67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating XGB OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack all model predictions for meta-learner\n",
        "meta_X_train = np.hstack([oof_cnn, oof_lstm, oof_xgb])\n",
        "meta_y_train = y_all_mapped.values  # already mapped to (0,1,2)\n",
        "\n",
        "print(\"✅ OOF generation complete!\")\n",
        "print(\"Meta-train shape:\", meta_X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oypZH8ABhQFk",
        "outputId": "1b516a9e-1df2-44e4-f3da-add708265f84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OOF generation complete!\n",
            "Meta-train shape: (25188, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# Save OOF predictions and labels\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_all_mapped.values\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5i8N1lJps85",
        "outputId": "59e91e90-7b81-42df-e958-d9e2ee1819c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 OOF predictions saved to oof_preds.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# META LEARNER"
      ],
      "metadata": {
        "id": "IhKOAKMNxrMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A — Load OOF predictions and align\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "# Try to load previously saved OOF predictions. If you already have them in memory,\n",
        "# replace this with the arrays directly (oof_cnn, oof_lstm, oof_xgb, y).\n",
        "oof_path = \"oof_preds.pkl\"\n",
        "obj = joblib.load(oof_path)  # expects dict with \"oof_cnn\",\"oof_lstm\",\"oof_xgb\",\"y\"\n",
        "\n",
        "oof_cnn = obj[\"oof_cnn\"]    # shape (n_samples, 3)\n",
        "oof_lstm = obj[\"oof_lstm\"]\n",
        "oof_xgb = obj[\"oof_xgb\"]\n",
        "y_raw   = obj[\"y\"]          # ground-truth labels used during OOF (mapped 0/1/2 or original)\n",
        "\n",
        "# Make numpy arrays and check sizes\n",
        "oof_cnn = np.asarray(oof_cnn)\n",
        "oof_lstm = np.asarray(oof_lstm)\n",
        "oof_xgb = np.asarray(oof_xgb)\n",
        "y_raw = np.asarray(y_raw).ravel()\n",
        "\n",
        "print(\"Shapes:\", oof_cnn.shape, oof_lstm.shape, oof_xgb.shape, y_raw.shape)\n",
        "\n",
        "# Basic sanity checks\n",
        "n = len(y_raw)\n",
        "assert oof_cnn.shape[0] == n and oof_lstm.shape[0] == n and oof_xgb.shape[0] == n, \"OOF arrays must align with labels\"\n",
        "\n",
        "# If your y is in -1/0/1 mapping, map to 0/1/2 (consistent)\n",
        "# Detect automatically if values are -1/0/1 and map to 0/1/2\n",
        "if set(np.unique(y_raw)).issuperset({-1,0,1}) and set(np.unique(y_raw)).difference({-1,0,1})==set():\n",
        "    print(\"Detected labels in {-1,0,1} — remapping to {0,1,2}\")\n",
        "    map_arr = np.array([0 if v==-1 else (1 if v==0 else 2) for v in y_raw])\n",
        "    y = map_arr\n",
        "else:\n",
        "    # assume already 0/1/2\n",
        "    y = y_raw.copy()\n",
        "\n",
        "# Confirm class distribution\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"Label distribution (mapped):\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UY6W_zKg-fS",
        "outputId": "0ad6a49d-ddfd-4542-852f-5906ba5bdd9d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (25188, 3) (25188, 3) (25188, 3) (25188,)\n",
            "Label distribution (mapped): {np.int64(0): np.int64(5515), np.int64(1): np.int64(13474), np.int64(2): np.int64(6199)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — meta-features construction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model probabilities as features\n",
        "meta_probs = np.hstack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 9)\n",
        "\n",
        "# Add engineered meta-features derived from base model outputs:\n",
        "# - per-sample mean/std/max/min across base model probs\n",
        "# - disagreements (max prob - 2nd max prob) for confidence\n",
        "def meta_stats_from_probs(probs_block):\n",
        "    # probs_block shape (n, n_models * n_classes)\n",
        "    n_classes = 3\n",
        "    n_models = probs_block.shape[1] // n_classes\n",
        "    block = probs_block.reshape(len(probs_block), n_models, n_classes)\n",
        "    # per model best class prob and best class\n",
        "    best_probs = block.max(axis=2)                 # (n, n_models)\n",
        "    best_classes = block.argmax(axis=2)             # (n, n_models)\n",
        "    # statistics across models on best_probs\n",
        "    mean_best = best_probs.mean(axis=1)\n",
        "    std_best = best_probs.std(axis=1)\n",
        "    max_best = best_probs.max(axis=1)\n",
        "    min_best = best_probs.min(axis=1)\n",
        "    # disagreement: how many models agree with majority class\n",
        "    from scipy.stats import mode\n",
        "    mode_vals, mode_counts = mode(best_classes, axis=1)\n",
        "    agree_fraction = (mode_counts.ravel() / n_models)\n",
        "    # confidence gap: top prob - second top prob per model averaged\n",
        "    def gap_per_row(row_block):\n",
        "        # row_block shape (n_models, n_classes)\n",
        "        gaps = []\n",
        "        for m in range(row_block.shape[0]):\n",
        "            arr = np.sort(row_block[m])[::-1]\n",
        "            gaps.append(arr[0] - (arr[1] if arr.shape[0] > 1 else 0.0))\n",
        "        return np.mean(gaps)\n",
        "    gap = np.array([gap_per_row(row) for row in block])\n",
        "\n",
        "    stats = np.vstack([mean_best, std_best, max_best, min_best, agree_fraction, gap]).T\n",
        "    stats_cols = [\"mean_best_prob\", \"std_best_prob\", \"max_best_prob\", \"min_best_prob\", \"agree_frac\", \"avg_top_gap\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_probs(meta_probs)\n",
        "\n",
        "# Optionally add a few simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# For now, we'll build final meta_X from probs + stats\n",
        "meta_X = np.hstack([meta_probs, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_p{c}\" for c in range(3)] +\n",
        "    [f\"lstm_p{c}\" for c in range(3)] +\n",
        "    [f\"xgb_p{c}\" for c in range(3)] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F859Av3p0qf",
        "outputId": "28730553-acaf-406f-bcf5-faa4a8c92df1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta X shape: (25188, 15)\n",
            "Feature names: ['cnn_p0', 'cnn_p1', 'cnn_p2', 'lstm_p0', 'lstm_p1', 'lstm_p2', 'xgb_p0', 'xgb_p1', 'xgb_p2', 'mean_best_prob', 'std_best_prob', 'max_best_prob', 'min_best_prob', 'agree_frac', 'avg_top_gap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — Enhanced Meta-Learner Training with TimeSeriesSplit CV and Calibration\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)  # silence early_stopping msg\n",
        "\n",
        "# ==== Config ====\n",
        "n_splits = 5\n",
        "random_state = 42\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Hyperparameter candidates — can be extended for full grid/random search\n",
        "param_grid = [\n",
        "    {\"max_iter\": 200, \"learning_rate\": 0.05, \"max_depth\": 6},\n",
        "    {\"max_iter\": 300, \"learning_rate\": 0.03, \"max_depth\": 8},\n",
        "    {\"max_iter\": 200, \"learning_rate\": 0.1,  \"max_depth\": 4},\n",
        "]\n",
        "\n",
        "best_cfg = None\n",
        "best_score = -1\n",
        "best_oof_probs = None\n",
        "\n",
        "print(\"=== Meta-Learner Training with TimeSeriesSplit ===\")\n",
        "for cfg in param_grid:\n",
        "    print(f\"\\nTesting config: {cfg}\")\n",
        "    cfg_val_probs = np.zeros((len(meta_X), 3))\n",
        "    fold_scores = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(meta_X), 1):\n",
        "        X_tr, X_va = meta_X[tr_idx], meta_X[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        # Class balancing\n",
        "        sample_weight = compute_sample_weight(class_weight=\"balanced\", y=y_tr)\n",
        "\n",
        "        # Train fold model\n",
        "        model = HistGradientBoostingClassifier(\n",
        "            **cfg, early_stopping=True, scoring=\"f1_macro\", random_state=random_state\n",
        "        )\n",
        "        model.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
        "\n",
        "        # Predict\n",
        "        probs = model.predict_proba(X_va)\n",
        "        cfg_val_probs[va_idx] = probs\n",
        "\n",
        "        preds = probs.argmax(axis=1)\n",
        "        f1 = f1_score(y_va, preds, average=\"macro\", zero_division=0)\n",
        "        fold_scores.append(f1)\n",
        "        print(f\"  Fold {fold}/{n_splits} — F1_macro: {f1:.4f}\")\n",
        "\n",
        "    mean_f1 = np.mean(fold_scores)\n",
        "    print(f\"  Mean F1_macro: {mean_f1:.4f}\")\n",
        "\n",
        "    # Track best config\n",
        "    if mean_f1 > best_score:\n",
        "        best_score = mean_f1\n",
        "        best_cfg = cfg\n",
        "        best_oof_probs = cfg_val_probs.copy()\n",
        "\n",
        "print(\"\\n=== Best Config ===\")\n",
        "print(best_cfg, \"with mean F1_macro:\", round(best_score, 4))\n",
        "\n",
        "# ==== Train final model ====\n",
        "print(\"\\nTraining final meta-learner on full data...\")\n",
        "sample_weight_full = compute_sample_weight(class_weight=\"balanced\", y=y)\n",
        "final_model = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=random_state)\n",
        "final_model.fit(meta_X, y, sample_weight=sample_weight_full)\n",
        "\n",
        "# ==== Calibrate with time-aware CV ====\n",
        "# We’ll use TimeSeriesSplit again for calibration instead of random CV\n",
        "print(\"Calibrating probabilities (sigmoid)...\")\n",
        "calibrated_models = []\n",
        "for tr_idx, va_idx in tscv.split(meta_X):\n",
        "    model_clone = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=random_state)\n",
        "    model_clone.fit(meta_X[tr_idx], y[tr_idx], sample_weight=compute_sample_weight(class_weight=\"balanced\", y=y[tr_idx]))\n",
        "    calibrator = CalibratedClassifierCV(model_clone, method=\"sigmoid\", cv=\"prefit\")\n",
        "    calibrator.fit(meta_X[va_idx], y[va_idx])\n",
        "    calibrated_models.append(calibrator)\n",
        "\n",
        "# Save both raw and calibrated versions\n",
        "joblib.dump({\n",
        "    \"meta_model\": final_model,\n",
        "    \"calibrators\": calibrated_models,\n",
        "    \"best_cfg\": best_cfg,\n",
        "    \"meta_feature_names\": meta_feature_names\n",
        "}, \"meta_model.pkl\")\n",
        "\n",
        "print(\"✅ Saved meta_model.pkl with best config and calibration.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJul1btp2JA",
        "outputId": "34d39e63-e89f-4dce-f934-69e3f5e6f779"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Meta-Learner Training with TimeSeriesSplit ===\n",
            "\n",
            "Testing config: {'max_iter': 200, 'learning_rate': 0.05, 'max_depth': 6}\n",
            "  Fold 1/5 — F1_macro: 0.1233\n",
            "  Fold 2/5 — F1_macro: 0.7219\n",
            "  Fold 3/5 — F1_macro: 0.6729\n",
            "  Fold 4/5 — F1_macro: 0.2829\n",
            "  Fold 5/5 — F1_macro: 0.2378\n",
            "  Mean F1_macro: 0.4078\n",
            "\n",
            "Testing config: {'max_iter': 300, 'learning_rate': 0.03, 'max_depth': 8}\n",
            "  Fold 1/5 — F1_macro: 0.1233\n",
            "  Fold 2/5 — F1_macro: 0.7176\n",
            "  Fold 3/5 — F1_macro: 0.6772\n",
            "  Fold 4/5 — F1_macro: 0.2826\n",
            "  Fold 5/5 — F1_macro: 0.2378\n",
            "  Mean F1_macro: 0.4077\n",
            "\n",
            "Testing config: {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
            "  Fold 1/5 — F1_macro: 0.1233\n",
            "  Fold 2/5 — F1_macro: 0.7223\n",
            "  Fold 3/5 — F1_macro: 0.6788\n",
            "  Fold 4/5 — F1_macro: 0.2820\n",
            "  Fold 5/5 — F1_macro: 0.2378\n",
            "  Mean F1_macro: 0.4089\n",
            "\n",
            "=== Best Config ===\n",
            "{'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4} with mean F1_macro: 0.4089\n",
            "\n",
            "Training final meta-learner on full data...\n",
            "Calibrating probabilities (sigmoid)...\n",
            "✅ Saved meta_model.pkl with best config and calibration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D — Load Meta-Learner and Predict\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# ==== Load saved meta-model ====\n",
        "obj = joblib.load(\"meta_model.pkl\")\n",
        "\n",
        "# ==== Get features (replace with your actual prepared features) ====\n",
        "# meta_X should already be prepared with the same preprocessing as during training\n",
        "# y is the true labels (optional if you're only predicting)\n",
        "# Example:\n",
        "# meta_X = ...\n",
        "# y = ...\n",
        "\n",
        "# ==== Predict probabilities ====\n",
        "if \"calibrators\" in obj and obj[\"calibrators\"]:\n",
        "    # Average predictions from calibrated models\n",
        "    print(\"Using calibrated models...\")\n",
        "    calibrators = obj[\"calibrators\"]\n",
        "    probs_list = [cal.predict_proba(meta_X) for cal in calibrators]\n",
        "    probs = np.mean(probs_list, axis=0)\n",
        "else:\n",
        "    # Fall back to raw meta-model\n",
        "    print(\"Using raw meta-model...\")\n",
        "    probs = obj[\"meta_model\"].predict_proba(meta_X)\n",
        "\n",
        "# ==== Get predicted classes ====\n",
        "preds = probs.argmax(axis=1)\n",
        "\n",
        "# ==== If you want metrics ====\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "if 'y' in locals():\n",
        "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
        "    print(\"F1_macro:\", f1_score(y, preds, average=\"macro\", zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSvckCSp8Mr",
        "outputId": "b696e609-37a1-460b-bfa8-782371b77825"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using calibrated models...\n",
            "Accuracy: 0.664641892964904\n",
            "F1_macro: 0.5611559559107249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "X1nvP47MjnKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "5nGTwsv4qpi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b865d8-d7c0-46ea-f68c-668e853f56c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['meta_learner.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "TdtsuwkPaxcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fc82d8ff-1dd4-4d21-cf53-877256c1218f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_51652834-9d17-449d-95a0-78fc57f620a0\", \"meta_learner.pkl\", 390160)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save the three base models\n",
        "joblib.dump(cnn_model, \"cnn_model.pkl\")\n",
        "joblib.dump(lstm_model, \"lstm_model.pkl\")\n",
        "joblib.dump(xgb_clf, \"xgb_model.pkl\")  # change to your actual XGB var name\n",
        "\n",
        "# Download them\n",
        "files.download(\"cnn_model.pkl\")\n",
        "files.download(\"lstm_model.pkl\")\n",
        "files.download(\"xgb_model.pkl\")\n"
      ],
      "metadata": {
        "id": "SF20g9Ys68Nb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "93cd293f-31ec-4ae3-ca63-4050b5a54657"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c93a2930-f411-4c24-8c8b-b043bc5d42b4\", \"cnn_model.pkl\", 7279069)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_893c1d9d-67a6-4408-a2bb-95d858e3a2eb\", \"lstm_model.pkl\", 5459372)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b15a960b-1bf1-44e4-906a-633018747c9a\", \"xgb_model.pkl\", 814998)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "files.download(\"scaler.pkl\")"
      ],
      "metadata": {
        "id": "layD2Oi7Tymv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d910b4a8-c595-4b6c-fe39-c1f6464f4c6c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8648ec87-5633-42e5-8922-5ad4c6c1c998\", \"scaler.pkl\", 1751)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}