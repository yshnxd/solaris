{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris/blob/main/SOLARISSS%20stablezzz%20pianakafinal%2C%2080%20percent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Libraries"
      ],
      "metadata": {
        "id": "XUR0zNCpOy7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "24804694-e50b-44cf-f341-f7286389138a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "3hev1JrVPjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\"AAPL\", \"SPY\", \"TSLA\", \"NVDA\", \"QQQ\"]  # note: ^VIX for Yahoo\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "ff611d8f-7f50-4b8f-b9b4-9d4b9907af1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-09-20 13:30:00 to 2025-08-15 19:30:00\n",
            "SPY: 5075 rows from 2022-09-20 13:30:00 to 2025-08-15 19:30:00\n",
            "TSLA: 5075 rows from 2022-09-20 13:30:00 to 2025-08-15 19:30:00\n",
            "NVDA: 5075 rows from 2022-09-20 13:30:00 to 2025-08-15 19:30:00\n",
            "QQQ: 5075 rows from 2022-09-20 13:30:00 to 2025-08-15 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL         SPY        TSLA        NVDA  \\\n",
            "Datetime                                                              \n",
            "2025-08-15 15:30:00  230.740005  643.289978  327.940002  178.929993   \n",
            "2025-08-15 16:30:00  230.570007  644.165405  330.899994  179.700104   \n",
            "2025-08-15 17:30:00  230.850006  644.530029  329.829987  180.179993   \n",
            "2025-08-15 18:30:00  231.360001  643.799988  329.059998  179.970001   \n",
            "2025-08-15 19:30:00  231.649994  643.460022  330.600006  180.440002   \n",
            "\n",
            "                            QQQ  \n",
            "Datetime                         \n",
            "2025-08-15 15:30:00  576.309998  \n",
            "2025-08-15 16:30:00  577.275024  \n",
            "2025-08-15 17:30:00  577.719971  \n",
            "2025-08-15 18:30:00  577.335022  \n",
            "2025-08-15 19:30:00  577.229980  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Creation"
      ],
      "metadata": {
        "id": "jLnkdkzRRvVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Features"
      ],
      "metadata": {
        "id": "omLPzq5TDwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    macd = ta.trend.MACD(price_series)\n",
        "    feat_tmp[\"macd\"] = macd.macd()\n",
        "    feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()Cross-Asset Contextual Features: To capture broader market interactions, one-hour returns of SPY, QQQ, NVDA, and the volatility index (VIX) were aligned and included as contextual explanatory variables:\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"SPY\", \"QQQ\", \"NVDA\"]:\n",
        "        if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    if \"^VIX\" in aligned_ffill.columns:\n",
        "        feat_tmp[\"vix_ret_1h\"] = aligned_ffill[\"^VIX\"].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    feat_tmp = feat_tmp.dropna(subset=[col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]])\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = tickerCross-Asset Contextual Features: To capture broader market interactions, one-hour returns of SPY, QQQ, NVDA, and the volatility index (VIX) were aligned and included as contextual explanatory variables:\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())\n"
      ],
      "metadata": {
        "id": "MFIHXqY5R2fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702d0b39-32c1-48d2-a3d9-c1c2305ab7c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created features for 5 tickers\n",
            "Shape: (25210, 26)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.006804  0.005354  0.007740  0.008210 -0.034823  0.011265  0.008024   \n",
            "1 -0.005307  0.000796 -0.017692  0.005465 -0.040462  0.006372  0.008163   \n",
            "2  0.012726  0.014204  0.007085  0.022006 -0.014901  0.007212  0.008755   \n",
            "3 -0.006773  0.000527  0.005885  0.013854 -0.025400  0.007447  0.009105   \n",
            "4 -0.005993 -0.000162  0.000634  0.010893 -0.018636  0.007982  0.009266   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...      ema_20  vol_change_1h  \\\n",
            "0  0.008250  47.831019 -0.843695  ...  151.731845       0.155673   \n",
            "1  0.008276  44.579805 -0.811825  ...  151.649764       0.064564   \n",
            "2  0.008375  52.817108 -0.624450  ...  151.758349       0.991185   \n",
            "3  0.008409  48.621926 -0.553085  ...  151.758030      -0.467397   \n",
            "4  0.008101  45.222387 -0.563423  ...  151.671123       0.085019   \n",
            "\n",
            "     vol_ma_24h  SPY_ret_1h  QQQ_ret_1h  NVDA_ret_1h  hour  day_of_week  \\\n",
            "0  1.262300e+07    0.004510    0.004703     0.006107    18            0   \n",
            "1  1.280486e+07   -0.003147   -0.005116    -0.010764    19            0   \n",
            "2  1.296843e+07    0.006835    0.010030     0.029371    13            1   \n",
            "3  1.237456e+07   -0.004648   -0.004766    -0.005007    14            1   \n",
            "4  1.232170e+07   -0.007957   -0.008740    -0.015297    15            1   \n",
            "\n",
            "             datetime  ticker  \n",
            "0 2022-09-26 18:30:00    AAPL  \n",
            "1 2022-09-26 19:30:00    AAPL  \n",
            "2 2022-09-27 13:30:00    AAPL  \n",
            "3 2022-09-27 14:30:00    AAPL  \n",
            "4 2022-09-27 15:30:00    AAPL  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation"
      ],
      "metadata": {
        "id": "TKZHysWZZsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "vol_lookback = 24         # hours to compute rolling volatility\n",
        "vol_multiplier = 0.5      # threshold scaling vs volatility\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Volatility-based threshold\n",
        "    rolling_vol = price_series.pct_change().rolling(vol_lookback).std()\n",
        "    threshold = rolling_vol * vol_multiplier\n",
        "\n",
        "    # Label creation\n",
        "    label = future_ret.copy()\n",
        "    label[future_ret > threshold] = 1    # Up\n",
        "    label[future_ret < -threshold] = -1  # Down\n",
        "    label[(future_ret <= threshold) & (future_ret >= -threshold)] = 0  # Neutral\n",
        "\n",
        "    # Drop NaNs\n",
        "    label = label.dropna()\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": label.index,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[label.index],\n",
        "        \"label\": label.values,\n",
        "        \"future_ret\": future_ret.loc[label.index],\n",
        "        \"volatility\": rolling_vol.loc[label.index]\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "print(labels_df[\"label\"].value_counts(normalize=True))\n",
        "labels_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "5e30c037-cb3f-4bb5-da35-dafa28ffa5e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (25370, 6)\n",
            "label\n",
            " 0.000000    0.532755\n",
            " 1.000000    0.245250\n",
            "-1.000000    0.217264\n",
            " 0.001154    0.000039\n",
            " 0.004992    0.000039\n",
            "               ...   \n",
            "-0.005434    0.000039\n",
            "-0.013390    0.000039\n",
            "-0.002570    0.000039\n",
            "-0.006481    0.000039\n",
            " 0.001337    0.000039\n",
            "Name: proportion, Length: 123, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime ticker       price     label  future_ret  volatility\n",
              "0 2022-09-20 13:30:00   AAPL  154.804993  0.011595    0.011595         NaN\n",
              "1 2022-09-20 14:30:00   AAPL  156.600006  0.004310    0.004310         NaN\n",
              "2 2022-09-20 15:30:00   AAPL  157.274994 -0.007852   -0.007852         NaN\n",
              "3 2022-09-20 16:30:00   AAPL  156.039993  0.001154    0.001154         NaN\n",
              "4 2022-09-20 17:30:00   AAPL  156.220093  0.004992    0.004992         NaN\n",
              "5 2022-09-20 18:30:00   AAPL  157.000000 -0.000637   -0.000637         NaN\n",
              "6 2022-09-20 19:30:00   AAPL  156.899994  0.003123    0.003123         NaN\n",
              "7 2022-09-21 13:30:00   AAPL  157.389999 -0.007974   -0.007974         NaN\n",
              "8 2022-09-21 14:30:00   AAPL  156.134995  0.006484    0.006484         NaN\n",
              "9 2022-09-21 15:30:00   AAPL  157.147400  0.000538    0.000538         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90bbfe47-9afc-4244-8320-3dea74e428fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>label</th>\n",
              "      <th>future_ret</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-20 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.804993</td>\n",
              "      <td>0.011595</td>\n",
              "      <td>0.011595</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-20 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.600006</td>\n",
              "      <td>0.004310</td>\n",
              "      <td>0.004310</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-20 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.274994</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-20 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.039993</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-20 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.220093</td>\n",
              "      <td>0.004992</td>\n",
              "      <td>0.004992</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-20 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-20 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.899994</td>\n",
              "      <td>0.003123</td>\n",
              "      <td>0.003123</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-21 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.389999</td>\n",
              "      <td>-0.007974</td>\n",
              "      <td>-0.007974</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-09-21 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.134995</td>\n",
              "      <td>0.006484</td>\n",
              "      <td>0.006484</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-09-21 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.147400</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90bbfe47-9afc-4244-8320-3dea74e428fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90bbfe47-9afc-4244-8320-3dea74e428fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90bbfe47-9afc-4244-8320-3dea74e428fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4b9b026c-a0f0-48c6-b121-a37d5c531b19\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b9b026c-a0f0-48c6-b121-a37d5c531b19')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4b9b026c-a0f0-48c6-b121-a37d5c531b19 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 25370,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-20 13:30:00\",\n        \"max\": \"2025-08-15 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-09-15 14:30:00\",\n          \"2024-03-26 19:30:00\",\n          \"2022-09-26 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SPY\",\n          \"QQQ\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 165.43583164997645,\n        \"min\": 11.14999008178711,\n        \"max\": 645.030029296875,\n        \"num_unique_values\": 23050,\n        \"samples\": [\n          235.13499450683594,\n          486.7950134277344,\n          193.13999938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6795225134255317,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          0.010322103894993854,\n          0.004836332821893788,\n          -0.014617464379915599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00938636261848106,\n        \"min\": -0.13022686951739132,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          -0.00730334240086603,\n          -0.06651588927781282,\n          0.0011840426113428418\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005540006308536305,\n        \"min\": 0.0008914795917642343,\n        \"max\": 0.054140767735433915,\n        \"num_unique_values\": 25250,\n        \"samples\": [\n          0.007165885199837074,\n          0.002953745838014375,\n          0.002694405766104616\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "rieWxNf5Mp44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1H-ATXHjSK6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Features"
      ],
      "metadata": {
        "id": "_PxZH38IebtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & labels\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y distribution:\\n\", y.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "OERLO3TNed16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39816c8d-3b4c-45b0-d3f3-506793e606bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25205, 26)\n",
            "y distribution:\n",
            " label\n",
            " 0.0    0.535529\n",
            " 1.0    0.246181\n",
            "-1.0    0.218290\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale"
      ],
      "metadata": {
        "id": "rpnDnFsiWa87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Label distribution in Train:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "4oxCtsXaSTrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add0f74a-073f-4112-8185-826d42c1a57c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train: (17631, 26), Val: (3778, 26), Test: (3779, 26)\n",
            "Label distribution in Train: label\n",
            " 0.0    0.525552\n",
            " 1.0    0.252567\n",
            "-1.0    0.221882\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence making - For LSTM AND CNN"
      ],
      "metadata": {
        "id": "euQxLDkaWdBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 24  # last 24 hours to predict next hour\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "id": "mn5XIK9DWlAN",
        "outputId": "f2a1d099-abad-48ba-bfda-2c1b952a3613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (17607, 24, 26), Val seq: (3754, 24, 26), Test seq: (3755, 24, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 — label encoding + class weights\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# mapping: -1 -> 0 (down), 0 -> 1 (neutral), 1 -> 2 (up)\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "\n",
        "# If your y_* are numpy arrays (seq labels), convert\n",
        "y_train_seq_mapped = np.vectorize(label_map.get)(y_train_seq)\n",
        "y_val_seq_mapped   = np.vectorize(label_map.get)(y_val_seq)\n",
        "y_test_seq_mapped  = np.vectorize(label_map.get)(y_test_seq)\n",
        "\n",
        "# one-hot for Keras\n",
        "y_train_cat = to_categorical(y_train_seq_mapped, num_classes=3)\n",
        "y_val_cat   = to_categorical(y_val_seq_mapped, num_classes=3)\n",
        "y_test_cat  = to_categorical(y_test_seq_mapped, num_classes=3)\n",
        "\n",
        "# compute class weights from training sequence labels\n",
        "classes = np.unique(y_train_seq_mapped)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_seq_mapped)\n",
        "class_weights_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "print(\"Train class distribution:\", np.bincount(y_train_seq_mapped) / len(y_train_seq_mapped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "0d7d8a82-b83b-4cad-b0c8-9cde126cbdea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.5052577583995896), 1: np.float64(0.6338012958963283), 2: np.float64(1.3194694244604317)}\n",
            "Train class distribution: [0.22144602 0.52592719 0.2526268 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1jUYMhA9cSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, BatchNormalization, Activation, Dropout, SpatialDropout1D,\n",
        "    GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Add, Multiply, Concatenate\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# try to use AdamW (TF nightly / TF >=2.11 has experimental AdamW); fallback to classic Adam\n",
        "try:\n",
        "    from tensorflow.keras.optimizers import experimental as exp_optimizers\n",
        "    AdamW = exp_optimizers.AdamW\n",
        "    use_adamw = True\n",
        "except Exception:\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    AdamW = None\n",
        "    use_adamw = False\n",
        "\n",
        "def se_block(x, reduction=8):\n",
        "    \"\"\"Squeeze-and-Excitation block.\"\"\"\n",
        "    channels = int(x.shape[-1])\n",
        "    se = GlobalAveragePooling1D()(x)\n",
        "    se = tf.keras.layers.Dense(channels // reduction, activation='relu', kernel_initializer='he_normal')(se)\n",
        "    se = tf.keras.layers.Dense(channels, activation='sigmoid', kernel_initializer='he_normal')(se)\n",
        "    se = tf.keras.layers.Reshape((1, channels))(se)\n",
        "    return Multiply()([x, se])\n",
        "\n",
        "def residual_block(x, filters, kernel_size, dropout_rate=0.2, weight_decay=1e-4):\n",
        "    shortcut = x\n",
        "    # projection if channels mismatch\n",
        "    if x.shape[-1] != filters:\n",
        "        shortcut = Conv1D(filters, kernel_size=1, padding='same',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          kernel_regularizer=l2(weight_decay))(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same',\n",
        "               kernel_initializer='he_normal',\n",
        "               kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # spatial dropout is preferable for time-series channels\n",
        "    x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same',\n",
        "               kernel_initializer='he_normal',\n",
        "               kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_cnn_enhanced(input_shape, n_classes=3, dropout_rate=0.25, weight_decay=1e-4):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # optionally normalize channels at input\n",
        "    x = BatchNormalization()(inp)\n",
        "\n",
        "    # initial conv\n",
        "    x = Conv1D(64, kernel_size=3, padding='same',\n",
        "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # residual blocks (reduce complexity growth if dataset small)\n",
        "    x = residual_block(x, 64, 3, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "    x = residual_block(x, 128, 5, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "    x = residual_block(x, 256, 3, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # attention\n",
        "    x = se_block(x, reduction=8)\n",
        "\n",
        "    # pooling combination\n",
        "    gap = GlobalAveragePooling1D()(x)\n",
        "    gmp = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([gap, gmp])  # combined representation\n",
        "\n",
        "    x = Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "\n",
        "    # optimizer: try AdamW if available, otherwise Adam with weight decay via L2 above\n",
        "    if use_adamw and AdamW is not None:\n",
        "        opt = AdamW(learning_rate=1e-3, weight_decay=1e-5)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Build model (example)\n",
        "cnn_model = build_cnn_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25, weight_decay=1e-4)\n",
        "cnn_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "2mDqNrx0SddA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ef00f1a-953e-47fb-dc63-8d2be2f01191"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │        \u001b[38;5;34m104\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m5,056\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m82,048\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m8,224\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m8,448\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m676,427\u001b[0m (2.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">676,427</span> (2.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m673,687\u001b[0m (2.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">673,687</span> (2.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,740\u001b[0m (10.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,740</span> (10.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "-p_nIYgVcWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, Bidirectional, LSTM, GRU, Dense, Dropout,\n",
        "    LayerNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
        "    Concatenate, Attention\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_lstm_enhanced(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = LayerNormalization()(inp)\n",
        "\n",
        "    # First BiLSTM layer\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Second BiGRU layer (faster and adds diversity in sequence modeling)\n",
        "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Self-Attention layer\n",
        "    attn_data = Attention()([x, x])\n",
        "    x = Concatenate()([x, attn_data])  # fuse original and attention output\n",
        "\n",
        "    # Pooling\n",
        "    x_avg = GlobalAveragePooling1D()(x)\n",
        "    x_max = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([x_avg, x_max])\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate model\n",
        "lstm_model = build_lstm_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "id": "IYtsddwpfp1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "3b934f73-40e3-4f57-b06a-c87db6e64907"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │         \u001b[38;5;34m52\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m158,720\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m123,648\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,720</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "7FalnDi8fxYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---- Map labels safely to integers 0,1,2 ----\n",
        "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
        "# if y_train etc are pandas Series this is robust:\n",
        "y_train_tab = pd.Series(y_train).map(label_map).astype('int').to_numpy()\n",
        "y_val_tab   = pd.Series(y_val).map(label_map).astype('int').to_numpy()\n",
        "y_test_tab  = pd.Series(y_test).map(label_map).astype('int').to_numpy()\n",
        "\n",
        "# ---- Per-sample balanced weights (recommended for multiclass) ----\n",
        "sample_weight_train = compute_sample_weight('balanced', y_train_tab)\n",
        "# sample_weight_train is length n_train; pass it into .fit(..., sample_weight=...)\n",
        "\n",
        "# ---- Defensive: compute per-class counts (avoid division by zero) ----\n",
        "class_counts = np.bincount(y_train_tab, minlength=3)\n",
        "total = len(y_train_tab)\n",
        "n_classes = len(class_counts)\n",
        "per_class_scale = np.where(class_counts == 0, 0.0, total / (n_classes * class_counts))\n",
        "print(\"class_counts:\", class_counts, \"per_class_scale:\", per_class_scale)\n",
        "\n",
        "# If you prefer per-sample weights from per_class_scale:\n",
        "sample_weight_from_scale = np.array([per_class_scale[c] for c in y_train_tab])\n",
        "\n",
        "# ---- XGBoost classifier (multi-class) ----\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',    # multiclass probability output\n",
        "    num_class=3,                   # explicit number of classes (safe to include)\n",
        "    n_estimators=1000,             # set high + use early stopping\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    gamma=1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',            # 'gpu_hist' if you have GPU\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "EjSEPd16f61x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e2a19b-f635-4e67-a184-3a34520164b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_counts: [3912 9266 4453] per_class_scale: [1.50230061 0.63425426 1.31978442]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "TKR7NlqVaq34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cOvOaClz5nPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if supported\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile with lower LR initially for stability\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_cnn_full_model.keras',  # save full model, not just weights\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/cnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "29088d9a-caf3-4f5c-f2c8-7fb36c8ebd8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.39329, saving model to best_cnn_full_model.keras\n",
            "138/138 - 52s - 374ms/step - accuracy: 0.3498 - loss: 1.5008 - val_accuracy: 0.5008 - val_loss: 1.3933 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.39329 to 1.38862, saving model to best_cnn_full_model.keras\n",
            "138/138 - 39s - 280ms/step - accuracy: 0.3630 - loss: 1.4342 - val_accuracy: 0.5011 - val_loss: 1.3886 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.38862\n",
            "138/138 - 30s - 218ms/step - accuracy: 0.3866 - loss: 1.4167 - val_accuracy: 0.3639 - val_loss: 1.4123 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.38862\n",
            "138/138 - 29s - 211ms/step - accuracy: 0.4068 - loss: 1.4026 - val_accuracy: 0.3980 - val_loss: 1.4070 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 1.38862 to 1.35763, saving model to best_cnn_full_model.keras\n",
            "138/138 - 30s - 214ms/step - accuracy: 0.4355 - loss: 1.3892 - val_accuracy: 0.5016 - val_loss: 1.3576 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.35763\n",
            "138/138 - 42s - 303ms/step - accuracy: 0.4384 - loss: 1.3772 - val_accuracy: 0.3974 - val_loss: 1.3880 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.35763\n",
            "138/138 - 41s - 296ms/step - accuracy: 0.4427 - loss: 1.3619 - val_accuracy: 0.4283 - val_loss: 1.3696 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 1.35763 to 1.34118, saving model to best_cnn_full_model.keras\n",
            "138/138 - 39s - 284ms/step - accuracy: 0.4508 - loss: 1.3487 - val_accuracy: 0.4915 - val_loss: 1.3412 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.34118\n",
            "138/138 - 41s - 297ms/step - accuracy: 0.4570 - loss: 1.3336 - val_accuracy: 0.4060 - val_loss: 1.3628 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.34118\n",
            "138/138 - 42s - 306ms/step - accuracy: 0.4653 - loss: 1.3208 - val_accuracy: 0.3969 - val_loss: 1.3544 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.34118\n",
            "138/138 - 40s - 288ms/step - accuracy: 0.4645 - loss: 1.3038 - val_accuracy: 0.3133 - val_loss: 1.4657 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 1.34118 to 1.32523, saving model to best_cnn_full_model.keras\n",
            "138/138 - 41s - 298ms/step - accuracy: 0.4766 - loss: 1.2930 - val_accuracy: 0.4425 - val_loss: 1.3252 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.32523\n",
            "138/138 - 41s - 300ms/step - accuracy: 0.4795 - loss: 1.2782 - val_accuracy: 0.3399 - val_loss: 1.3842 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.32523\n",
            "138/138 - 41s - 297ms/step - accuracy: 0.4904 - loss: 1.2596 - val_accuracy: 0.4273 - val_loss: 1.3352 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss improved from 1.32523 to 1.27975, saving model to best_cnn_full_model.keras\n",
            "138/138 - 40s - 292ms/step - accuracy: 0.4853 - loss: 1.2474 - val_accuracy: 0.4790 - val_loss: 1.2798 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.27975\n",
            "138/138 - 41s - 295ms/step - accuracy: 0.4960 - loss: 1.2297 - val_accuracy: 0.4398 - val_loss: 1.2995 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.27975\n",
            "138/138 - 42s - 305ms/step - accuracy: 0.5106 - loss: 1.2100 - val_accuracy: 0.4017 - val_loss: 1.3310 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 1.27975 to 1.27593, saving model to best_cnn_full_model.keras\n",
            "138/138 - 40s - 288ms/step - accuracy: 0.5074 - loss: 1.1988 - val_accuracy: 0.4334 - val_loss: 1.2759 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.27593\n",
            "138/138 - 41s - 297ms/step - accuracy: 0.5226 - loss: 1.1782 - val_accuracy: 0.3982 - val_loss: 1.3323 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.27593\n",
            "138/138 - 43s - 310ms/step - accuracy: 0.5273 - loss: 1.1601 - val_accuracy: 0.4212 - val_loss: 1.3163 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss improved from 1.27593 to 1.24961, saving model to best_cnn_full_model.keras\n",
            "138/138 - 40s - 288ms/step - accuracy: 0.5385 - loss: 1.1358 - val_accuracy: 0.4718 - val_loss: 1.2496 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 1.24961\n",
            "138/138 - 41s - 295ms/step - accuracy: 0.5394 - loss: 1.1233 - val_accuracy: 0.4198 - val_loss: 1.3120 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.24961\n",
            "138/138 - 41s - 296ms/step - accuracy: 0.5597 - loss: 1.0982 - val_accuracy: 0.4017 - val_loss: 1.3181 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.24961\n",
            "138/138 - 29s - 209ms/step - accuracy: 0.5673 - loss: 1.0769 - val_accuracy: 0.3532 - val_loss: 1.3964 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 1.24961\n",
            "138/138 - 28s - 205ms/step - accuracy: 0.5760 - loss: 1.0594 - val_accuracy: 0.3617 - val_loss: 1.4178 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_loss did not improve from 1.24961\n",
            "138/138 - 29s - 211ms/step - accuracy: 0.5981 - loss: 1.0120 - val_accuracy: 0.3910 - val_loss: 1.3682 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_loss did not improve from 1.24961\n",
            "138/138 - 41s - 300ms/step - accuracy: 0.6086 - loss: 0.9830 - val_accuracy: 0.3929 - val_loss: 1.3907 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_loss did not improve from 1.24961\n",
            "138/138 - 28s - 203ms/step - accuracy: 0.6146 - loss: 0.9645 - val_accuracy: 0.3852 - val_loss: 1.4233 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 1.24961\n",
            "138/138 - 42s - 303ms/step - accuracy: 0.6259 - loss: 0.9462 - val_accuracy: 0.3503 - val_loss: 1.4826 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: val_loss did not improve from 1.24961\n",
            "138/138 - 29s - 207ms/step - accuracy: 0.6420 - loss: 0.9187 - val_accuracy: 0.3655 - val_loss: 1.4856 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: val_loss did not improve from 1.24961\n",
            "138/138 - 41s - 299ms/step - accuracy: 0.6455 - loss: 0.9017 - val_accuracy: 0.3697 - val_loss: 1.5003 - learning_rate: 1.2500e-04\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yxu1niZ7gq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if GPU supports it (LSTMs benefit less than CNNs, but still good for speed)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile LSTM with gradient clipping (helps with exploding gradients in RNNs)\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_lstm_full_model.keras',  # Save entire model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/lstm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=120,  # Give it more room to converge\n",
        "    batch_size=96,  # Smaller batch size often helps LSTM generalization\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "ca213eb8-1d96-406b-9dbf-6bf7bd4d2fa2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.08925, saving model to best_lstm_full_model.keras\n",
            "184/184 - 32s - 174ms/step - accuracy: 0.4026 - loss: 1.0910 - val_accuracy: 0.3934 - val_loss: 1.0893 - learning_rate: 3.0000e-04\n",
            "Epoch 2/120\n",
            "\n",
            "Epoch 2: val_loss improved from 1.08925 to 1.08672, saving model to best_lstm_full_model.keras\n",
            "184/184 - 41s - 221ms/step - accuracy: 0.4360 - loss: 1.0789 - val_accuracy: 0.3820 - val_loss: 1.0867 - learning_rate: 3.0000e-04\n",
            "Epoch 3/120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.08672\n",
            "184/184 - 41s - 225ms/step - accuracy: 0.4511 - loss: 1.0717 - val_accuracy: 0.4017 - val_loss: 1.0876 - learning_rate: 3.0000e-04\n",
            "Epoch 4/120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.08672\n",
            "184/184 - 41s - 222ms/step - accuracy: 0.4599 - loss: 1.0641 - val_accuracy: 0.4044 - val_loss: 1.0920 - learning_rate: 3.0000e-04\n",
            "Epoch 5/120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.08672\n",
            "184/184 - 39s - 215ms/step - accuracy: 0.4667 - loss: 1.0541 - val_accuracy: 0.3913 - val_loss: 1.1079 - learning_rate: 3.0000e-04\n",
            "Epoch 6/120\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.08672\n",
            "184/184 - 25s - 135ms/step - accuracy: 0.4676 - loss: 1.0467 - val_accuracy: 0.3913 - val_loss: 1.1169 - learning_rate: 3.0000e-04\n",
            "Epoch 7/120\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.08672\n",
            "184/184 - 41s - 221ms/step - accuracy: 0.4905 - loss: 1.0282 - val_accuracy: 0.4129 - val_loss: 1.0950 - learning_rate: 1.5000e-04\n",
            "Epoch 8/120\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.08672\n",
            "184/184 - 26s - 142ms/step - accuracy: 0.4968 - loss: 1.0182 - val_accuracy: 0.4148 - val_loss: 1.0965 - learning_rate: 1.5000e-04\n",
            "Epoch 9/120\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.08672\n",
            "184/184 - 41s - 224ms/step - accuracy: 0.5025 - loss: 1.0088 - val_accuracy: 0.3950 - val_loss: 1.1215 - learning_rate: 1.5000e-04\n",
            "Epoch 10/120\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.08672\n",
            "184/184 - 40s - 218ms/step - accuracy: 0.5085 - loss: 0.9986 - val_accuracy: 0.3993 - val_loss: 1.1214 - learning_rate: 1.5000e-04\n",
            "Epoch 11/120\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.08672\n",
            "184/184 - 42s - 228ms/step - accuracy: 0.5238 - loss: 0.9799 - val_accuracy: 0.3881 - val_loss: 1.1284 - learning_rate: 7.5000e-05\n",
            "Epoch 12/120\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.08672\n",
            "184/184 - 26s - 142ms/step - accuracy: 0.5233 - loss: 0.9741 - val_accuracy: 0.3921 - val_loss: 1.1274 - learning_rate: 7.5000e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "2RHWbvELgyIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- ensure label mapping (same as before) ---\n",
        "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
        "y_train_tab = pd.Series(y_train).map(label_map).astype(int).to_numpy()\n",
        "y_val_tab   = pd.Series(y_val).map(label_map).astype(int).to_numpy()\n",
        "y_test_tab  = pd.Series(y_test).map(label_map).astype(int).to_numpy()\n",
        "\n",
        "# --- sample weights (multiclass) ---\n",
        "sw_train = compute_sample_weight(class_weight='balanced', y=y_train_tab)\n",
        "sw_val   = compute_sample_weight(class_weight='balanced', y=y_val_tab)\n",
        "\n",
        "# helper: robust predict that works across xgboost versions\n",
        "def predict_with_best(booster: xgb.Booster, dmatrix: xgb.DMatrix):\n",
        "    \"\"\"\n",
        "    Try several predict call styles in order:\n",
        "      1) predict(..., iteration_range=(0, best_iteration+1)) if best_iteration exists\n",
        "      2) predict(..., ntree_limit=best_ntree_limit) if supported\n",
        "      3) fallback: predict(dmatrix)\n",
        "    \"\"\"\n",
        "    # 1) iteration_range (newer interface)\n",
        "    try:\n",
        "        if hasattr(booster, \"best_iteration\") and booster.best_iteration is not None:\n",
        "            return booster.predict(dmatrix, iteration_range=(0, int(booster.best_iteration) + 1))\n",
        "    except TypeError:\n",
        "        # some versions may not accept iteration_range\n",
        "        pass\n",
        "    # 2) ntree_limit (older interface)\n",
        "    try:\n",
        "        if hasattr(booster, \"best_ntree_limit\") and booster.best_ntree_limit is not None:\n",
        "            return booster.predict(dmatrix, ntree_limit=int(booster.best_ntree_limit))\n",
        "    except TypeError:\n",
        "        pass\n",
        "    # 3) plain predict fallback\n",
        "    return booster.predict(dmatrix)\n",
        "\n",
        "# prepare DMatrix for validation & test once outside objective (weights included)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_tab, weight=sw_val)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "# Optuna objective (robust)\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 3,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'hist',\n",
        "        'seed': 42,\n",
        "        'verbosity': 0,\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),\n",
        "    }\n",
        "\n",
        "    # create DMatrix for the training fold (weights applied)\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train_tab, weight=sw_train)\n",
        "\n",
        "    try:\n",
        "        bst = xgb.train(\n",
        "            params,\n",
        "            dtrain,\n",
        "            num_boost_round=1500,\n",
        "            evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "            early_stopping_rounds=50,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "        # robust predict\n",
        "        preds = predict_with_best(bst, dval)\n",
        "        pred_labels = np.argmax(preds, axis=1)\n",
        "        acc = accuracy_score(y_val_tab, pred_labels)\n",
        "        # store best_iteration (useful later)\n",
        "        trial.set_user_attr(\"best_iteration\", getattr(bst, \"best_iteration\", None))\n",
        "        return acc\n",
        "\n",
        "    except Exception as e:\n",
        "        # Log a warning and return a very low score so Optuna can continue.\n",
        "        # Avoid letting the exception bubble and stop the entire study.\n",
        "        print(f\"[Optuna objective] caught exception during training/predict: {e!r}\")\n",
        "        return 0.0\n",
        "\n",
        "# run the study\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters:\", study.best_params)\n",
        "print(\"Best validation accuracy:\", study.best_value)\n",
        "print(\"Best trial attrs:\", study.best_trial.user_attrs)\n",
        "\n",
        "# Train final model on same train/val with best params\n",
        "best_params = study.best_params.copy()\n",
        "best_params.update({\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 3,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'hist',\n",
        "    'seed': 42,\n",
        "    'verbosity': 1\n",
        "})\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_tab, weight=sw_train)\n",
        "dval   = xgb.DMatrix(X_val, label=y_val_tab, weight=sw_val)\n",
        "final_model = xgb.train(\n",
        "    best_params,\n",
        "    dtrain,\n",
        "    num_boost_round=3000,\n",
        "    evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")\n",
        "# -------------------------\n",
        "# Save & evaluate (fixed, saving to xgb_model.pkl)\n",
        "# -------------------------\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Defensive check\n",
        "if 'final_model' not in globals():\n",
        "    raise RuntimeError(\"final_model not found. Make sure xgb.train(...) completed and produced final_model.\")\n",
        "\n",
        "# 1) Save the trained Booster\n",
        "# (a) JSON copy — reliable XGBoost-native format\n",
        "final_model.save_model(\"xgb_model.json\")\n",
        "\n",
        "# (b) Pickle via joblib so filename is xgb_model.pkl as requested\n",
        "# joblib will serialize the Booster object; this is convenient for later joblib.load()\n",
        "joblib.dump(final_model, \"xgb_model.pkl\")\n",
        "\n",
        "# 2) How to reload later (examples)\n",
        "# loaded_bst = joblib.load(\"xgb_model.pkl\")\n",
        "# OR\n",
        "# loaded_bst = xgb.Booster()\n",
        "# loaded_bst.load_model(\"xgb_model.json\")\n",
        "\n",
        "# 3) Evaluate on test set using the robust predict helper\n",
        "y_prob = predict_with_best(final_model, dtest)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"Final Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fdacfa2626844294988d1860db050873",
            "2c8d4175e3694962a39517f4869d97d1",
            "295920c9f59b43a3a1559dc73e3cd707",
            "b19f49429b1245a98b67cf3ae5c18512",
            "3723ece3ffd14598bbaf870e10727d3a",
            "15b280a973944326b8c50d4243b6cc63",
            "3fbd7a18f95d4370b1473d4a612677ec",
            "bd50e02661dd4a9b813160d44d244f0f",
            "0890d1c153c04dc79d5ca01aec0e3169",
            "212ae1f159564079a3f039fe2710c9d2",
            "bfcc77a3988744a592347e03c2b08673"
          ]
        },
        "id": "lOUy9Yd0g-6E",
        "outputId": "4d5265ad-e761-4d02-d914-871976f7886d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/395.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-16 14:27:58,351] A new study created in memory with name: no-name-a7092cd6-16d0-492a-85fe-18019a052dd3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdacfa2626844294988d1860db050873"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-08-16 14:27:59,155] Trial 0 finished with value: 0.4727368978295394 and parameters: {'max_depth': 5, 'learning_rate': 0.2536999076681772, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'gamma': 0.7800932022121826, 'min_child_weight': 2, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 2.665440364437338}. Best is trial 0 with value: 0.4727368978295394.\n",
            "[I 2025-08-16 14:28:00,133] Trial 1 finished with value: 0.47750132345156165 and parameters: {'max_depth': 7, 'learning_rate': 0.11114989443094977, 'subsample': 0.608233797718321, 'colsample_bytree': 0.9879639408647978, 'gamma': 4.162213204002109, 'min_child_weight': 3, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 0.9585112746335845}. Best is trial 1 with value: 0.47750132345156165.\n",
            "[I 2025-08-16 14:28:01,154] Trial 2 finished with value: 0.47432503970354684 and parameters: {'max_depth': 5, 'learning_rate': 0.05958389350068958, 'subsample': 0.7727780074568463, 'colsample_bytree': 0.7164916560792167, 'gamma': 3.0592644736118975, 'min_child_weight': 2, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 1.4159046082342293}. Best is trial 1 with value: 0.47750132345156165.\n",
            "[I 2025-08-16 14:28:02,067] Trial 3 finished with value: 0.47856008470089995 and parameters: {'max_depth': 6, 'learning_rate': 0.14447746112718687, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'gamma': 2.9620728443102124, 'min_child_weight': 1, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 0.9263103092182288}. Best is trial 3 with value: 0.47856008470089995.\n",
            "[I 2025-08-16 14:28:02,591] Trial 4 finished with value: 0.471148755955532 and parameters: {'max_depth': 3, 'learning_rate': 0.2521267904777921, 'subsample': 0.9862528132298237, 'colsample_bytree': 0.9233589392465844, 'gamma': 1.5230688458668533, 'min_child_weight': 1, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 1.6003812343490034}. Best is trial 3 with value: 0.47856008470089995.\n",
            "[I 2025-08-16 14:28:03,850] Trial 5 finished with value: 0.4809422975119111 and parameters: {'max_depth': 3, 'learning_rate': 0.05388108577817234, 'subsample': 0.6137554084460873, 'colsample_bytree': 0.9637281608315128, 'gamma': 1.2938999080000846, 'min_child_weight': 7, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 1.800170052944527}. Best is trial 5 with value: 0.4809422975119111.\n",
            "[I 2025-08-16 14:28:08,664] Trial 6 finished with value: 0.47961884595023824 and parameters: {'max_depth': 7, 'learning_rate': 0.01875220945578641, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'gamma': 4.697494707820946, 'min_child_weight': 9, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 2.804685587557792}. Best is trial 5 with value: 0.4809422975119111.\n",
            "[I 2025-08-16 14:28:11,280] Trial 7 finished with value: 0.474854420328216 and parameters: {'max_depth': 3, 'learning_rate': 0.01947558230629543, 'subsample': 0.6180909155642152, 'colsample_bytree': 0.7301321323053057, 'gamma': 1.9433864484474102, 'min_child_weight': 3, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 1.3918833167339733}. Best is trial 5 with value: 0.4809422975119111.\n",
            "[I 2025-08-16 14:28:12,622] Trial 8 finished with value: 0.4833245103229222 and parameters: {'max_depth': 5, 'learning_rate': 0.06333268775321842, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'gamma': 0.3727532183988541, 'min_child_weight': 10, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 0.996789203835431}. Best is trial 8 with value: 0.4833245103229222.\n",
            "[I 2025-08-16 14:28:13,265] Trial 9 finished with value: 0.4814716781365802 and parameters: {'max_depth': 3, 'learning_rate': 0.1601531217136121, 'subsample': 0.8827429375390468, 'colsample_bytree': 0.8916028672163949, 'gamma': 3.8563517334297286, 'min_child_weight': 1, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 0.7896726488128243}. Best is trial 8 with value: 0.4833245103229222.\n",
            "[I 2025-08-16 14:28:24,261] Trial 10 finished with value: 0.4896770778189518 and parameters: {'max_depth': 10, 'learning_rate': 0.010206070557576998, 'subsample': 0.7230776845801049, 'colsample_bytree': 0.6071847502459278, 'gamma': 0.0728350391697653, 'min_child_weight': 10, 'reg_alpha': 0.9657999152312998, 'reg_lambda': 2.191044618921876}. Best is trial 10 with value: 0.4896770778189518.\n",
            "[I 2025-08-16 14:28:35,656] Trial 11 finished with value: 0.49311805187930124 and parameters: {'max_depth': 10, 'learning_rate': 0.010233524192808546, 'subsample': 0.7294480126518945, 'colsample_bytree': 0.6068744601075835, 'gamma': 0.11757387798799368, 'min_child_weight': 10, 'reg_alpha': 0.9923480895289144, 'reg_lambda': 2.164233542244918}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:28:48,730] Trial 12 finished with value: 0.48835362625727896 and parameters: {'max_depth': 10, 'learning_rate': 0.010269786859910212, 'subsample': 0.75545277470995, 'colsample_bytree': 0.6014562981232444, 'gamma': 0.22470209877269948, 'min_child_weight': 8, 'reg_alpha': 0.9971646149932867, 'reg_lambda': 2.2275245985995733}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:28:58,697] Trial 13 finished with value: 0.48623610375860243 and parameters: {'max_depth': 10, 'learning_rate': 0.011210124205357169, 'subsample': 0.7180231755394999, 'colsample_bytree': 0.6040569883749647, 'gamma': 0.9376631571668359, 'min_child_weight': 6, 'reg_alpha': 0.999362438641551, 'reg_lambda': 2.2531467450263287}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:05,153] Trial 14 finished with value: 0.4880889359449444 and parameters: {'max_depth': 9, 'learning_rate': 0.022740809791548022, 'subsample': 0.8111404038292744, 'colsample_bytree': 0.6638123593227387, 'gamma': 0.06570157858904091, 'min_child_weight': 10, 'reg_alpha': 0.8660413852999438, 'reg_lambda': 2.173250119110337}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:08,091] Trial 15 finished with value: 0.4753838009528851 and parameters: {'max_depth': 9, 'learning_rate': 0.026952113250703014, 'subsample': 0.8235194332173258, 'colsample_bytree': 0.6754908909746108, 'gamma': 2.2616315643880416, 'min_child_weight': 8, 'reg_alpha': 0.898036979691809, 'reg_lambda': 2.486613410280222}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:10,873] Trial 16 finished with value: 0.4841185812599259 and parameters: {'max_depth': 8, 'learning_rate': 0.035217322325656414, 'subsample': 0.7154311686654149, 'colsample_bytree': 0.6526519622190808, 'gamma': 0.7079212082617552, 'min_child_weight': 6, 'reg_alpha': 0.7206045334702624, 'reg_lambda': 1.9186154702770941}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:19,205] Trial 17 finished with value: 0.4838538909475913 and parameters: {'max_depth': 9, 'learning_rate': 0.014032863794076924, 'subsample': 0.8517314664119261, 'colsample_bytree': 0.7542495483658851, 'gamma': 1.553447098489982, 'min_child_weight': 9, 'reg_alpha': 0.5117948900087056, 'reg_lambda': 2.901528301243676}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:23,872] Trial 18 finished with value: 0.474854420328216 and parameters: {'max_depth': 10, 'learning_rate': 0.015124502999761995, 'subsample': 0.7377183690511787, 'colsample_bytree': 0.6411743739750013, 'gamma': 2.7304392599531058, 'min_child_weight': 10, 'reg_alpha': 0.918099519741837, 'reg_lambda': 2.489609148782407}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:28,039] Trial 19 finished with value: 0.48438327157226047 and parameters: {'max_depth': 8, 'learning_rate': 0.03602599624361157, 'subsample': 0.6733221423256304, 'colsample_bytree': 0.7730982444721965, 'gamma': 0.04938939107388564, 'min_child_weight': 5, 'reg_alpha': 0.7916912711390918, 'reg_lambda': 1.94870471033696}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:37,095] Trial 20 finished with value: 0.4804129168872419 and parameters: {'max_depth': 8, 'learning_rate': 0.010130534397396584, 'subsample': 0.7871583631253997, 'colsample_bytree': 0.700955391485638, 'gamma': 1.0913301914870148, 'min_child_weight': 8, 'reg_alpha': 0.4463220084500361, 'reg_lambda': 2.0815759819057953}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:45,324] Trial 21 finished with value: 0.48173636844891476 and parameters: {'max_depth': 10, 'learning_rate': 0.01446869783318069, 'subsample': 0.749498503430448, 'colsample_bytree': 0.6010004902112124, 'gamma': 0.46519643078748574, 'min_child_weight': 9, 'reg_alpha': 0.9992266250832247, 'reg_lambda': 2.3653819681213237}. Best is trial 11 with value: 0.49311805187930124.\n",
            "[I 2025-08-16 14:29:57,334] Trial 22 finished with value: 0.49550026469031233 and parameters: {'max_depth': 10, 'learning_rate': 0.010403166981612921, 'subsample': 0.7088441385447185, 'colsample_bytree': 0.6320408163578337, 'gamma': 0.057218067212422036, 'min_child_weight': 8, 'reg_alpha': 0.9518393344365162, 'reg_lambda': 1.662765895200044}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:04,218] Trial 23 finished with value: 0.48517734250926414 and parameters: {'max_depth': 9, 'learning_rate': 0.015519728644547775, 'subsample': 0.7045554147159333, 'colsample_bytree': 0.635164938672421, 'gamma': 0.6571647289156075, 'min_child_weight': 10, 'reg_alpha': 0.8883529425450482, 'reg_lambda': 1.647135231592086}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:09,563] Trial 24 finished with value: 0.4915299100052938 and parameters: {'max_depth': 10, 'learning_rate': 0.0274397586568777, 'subsample': 0.6501296164690729, 'colsample_bytree': 0.6883392920303911, 'gamma': 0.05283733884229453, 'min_child_weight': 7, 'reg_alpha': 0.9089511547723872, 'reg_lambda': 1.4234786209296457}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:13,965] Trial 25 finished with value: 0.4849126521969296 and parameters: {'max_depth': 9, 'learning_rate': 0.03206764185241379, 'subsample': 0.6429204888264599, 'colsample_bytree': 0.6829479191676197, 'gamma': 1.73228842017611, 'min_child_weight': 7, 'reg_alpha': 0.7401265631416255, 'reg_lambda': 1.2672524061813295}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:17,723] Trial 26 finished with value: 0.4814716781365802 and parameters: {'max_depth': 8, 'learning_rate': 0.02419308666629775, 'subsample': 0.6872654215622431, 'colsample_bytree': 0.6362613095099616, 'gamma': 0.9892521611815441, 'min_child_weight': 5, 'reg_alpha': 0.6521937986217918, 'reg_lambda': 1.29757802193157}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:22,228] Trial 27 finished with value: 0.49047114875595554 and parameters: {'max_depth': 10, 'learning_rate': 0.04430852986128907, 'subsample': 0.6431611995707527, 'colsample_bytree': 0.6914554123067637, 'gamma': 0.47790789073726375, 'min_child_weight': 7, 'reg_alpha': 0.8003210768111753, 'reg_lambda': 0.5588464975806604}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:24,652] Trial 28 finished with value: 0.4756484912652197 and parameters: {'max_depth': 9, 'learning_rate': 0.07832195498953343, 'subsample': 0.6832162841819422, 'colsample_bytree': 0.7366195675267277, 'gamma': 1.2408648067882893, 'min_child_weight': 8, 'reg_alpha': 0.9219272684932173, 'reg_lambda': 1.5739621576542584}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:29,049] Trial 29 finished with value: 0.47776601376389627 and parameters: {'max_depth': 10, 'learning_rate': 0.018608582219302363, 'subsample': 0.7675808861554817, 'colsample_bytree': 0.8290628171100286, 'gamma': 3.472147933184168, 'min_child_weight': 9, 'reg_alpha': 0.8521159331760219, 'reg_lambda': 1.8038663817231444}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:34,823] Trial 30 finished with value: 0.4825304393859185 and parameters: {'max_depth': 7, 'learning_rate': 0.012620313065294654, 'subsample': 0.6519635138316393, 'colsample_bytree': 0.6321048503627266, 'gamma': 2.0721559622698362, 'min_child_weight': 6, 'reg_alpha': 0.042745180079641565, 'reg_lambda': 1.1493389685358668}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:38,848] Trial 31 finished with value: 0.48623610375860243 and parameters: {'max_depth': 10, 'learning_rate': 0.039013463930270595, 'subsample': 0.6353991890363785, 'colsample_bytree': 0.6991678061782007, 'gamma': 0.5618426872272979, 'min_child_weight': 7, 'reg_alpha': 0.7889666528302294, 'reg_lambda': 0.5670654566613733}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:42,019] Trial 32 finished with value: 0.48994176813128637 and parameters: {'max_depth': 9, 'learning_rate': 0.04582730879370216, 'subsample': 0.6041393755876385, 'colsample_bytree': 0.6730194309834429, 'gamma': 0.37776520278246833, 'min_child_weight': 7, 'reg_alpha': 0.9342673916756882, 'reg_lambda': 0.6190550418844742}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:46,197] Trial 33 finished with value: 0.4891476971942827 and parameters: {'max_depth': 10, 'learning_rate': 0.07465920681983092, 'subsample': 0.7019544304039234, 'colsample_bytree': 0.7746268210831186, 'gamma': 0.6899509921230371, 'min_child_weight': 5, 'reg_alpha': 0.8400122231808055, 'reg_lambda': 1.9795988399912978}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:49,077] Trial 34 finished with value: 0.48014822657490736 and parameters: {'max_depth': 10, 'learning_rate': 0.10111392333480379, 'subsample': 0.644513864237922, 'colsample_bytree': 0.7036597859358703, 'gamma': 0.0009958723307368286, 'min_child_weight': 4, 'reg_alpha': 0.15301797696764652, 'reg_lambda': 1.502164361292407}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:51,970] Trial 35 finished with value: 0.48517734250926414 and parameters: {'max_depth': 6, 'learning_rate': 0.02807259028271756, 'subsample': 0.6612983486394911, 'colsample_bytree': 0.7225205494690331, 'gamma': 0.39689251423501654, 'min_child_weight': 8, 'reg_alpha': 0.8154010853883216, 'reg_lambda': 1.0448537511677523}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:53,527] Trial 36 finished with value: 0.47511911064055057 and parameters: {'max_depth': 4, 'learning_rate': 0.0461490380227162, 'subsample': 0.6233102957658649, 'colsample_bytree': 0.6289242647310681, 'gamma': 0.9066784876156666, 'min_child_weight': 7, 'reg_alpha': 0.9416021186801016, 'reg_lambda': 0.786711824928275}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:30:58,487] Trial 37 finished with value: 0.48358920063525673 and parameters: {'max_depth': 8, 'learning_rate': 0.02145381227505709, 'subsample': 0.6850576361250271, 'colsample_bytree': 0.6571432410174884, 'gamma': 1.3888174900405768, 'min_child_weight': 9, 'reg_alpha': 0.6707675260757393, 'reg_lambda': 1.737395239825403}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:02,098] Trial 38 finished with value: 0.4857067231339333 and parameters: {'max_depth': 9, 'learning_rate': 0.04485553836318623, 'subsample': 0.7457751097632451, 'colsample_bytree': 0.686735172473941, 'gamma': 0.27414426216831245, 'min_child_weight': 6, 'reg_alpha': 0.5783053986059628, 'reg_lambda': 2.7162630907704806}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:05,861] Trial 39 finished with value: 0.47803070407623083 and parameters: {'max_depth': 10, 'learning_rate': 0.01725454757347009, 'subsample': 0.9554477427050652, 'colsample_bytree': 0.798165343426112, 'gamma': 4.899226356996808, 'min_child_weight': 7, 'reg_alpha': 0.7364027479706177, 'reg_lambda': 0.8115027143579794}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:11,762] Trial 40 finished with value: 0.4806776071995765 and parameters: {'max_depth': 6, 'learning_rate': 0.012875250569497749, 'subsample': 0.7942718495892576, 'colsample_bytree': 0.7519849993125655, 'gamma': 0.7943242989039732, 'min_child_weight': 4, 'reg_alpha': 0.8828229583944358, 'reg_lambda': 1.4412264744652534}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:14,663] Trial 41 finished with value: 0.48544203282159876 and parameters: {'max_depth': 9, 'learning_rate': 0.04610786196691056, 'subsample': 0.6130418572490925, 'colsample_bytree': 0.6577077003272642, 'gamma': 0.33962559169034245, 'min_child_weight': 7, 'reg_alpha': 0.9503956258431311, 'reg_lambda': 0.6060075987216451}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:17,741] Trial 42 finished with value: 0.48358920063525673 and parameters: {'max_depth': 10, 'learning_rate': 0.05408144013731696, 'subsample': 0.610835391874343, 'colsample_bytree': 0.6167512940632958, 'gamma': 0.48933666430484146, 'min_child_weight': 8, 'reg_alpha': 0.9543265241010196, 'reg_lambda': 0.5040216729228715}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:21,243] Trial 43 finished with value: 0.490206458443621 and parameters: {'max_depth': 9, 'learning_rate': 0.06263608381056847, 'subsample': 0.6019469610807042, 'colsample_bytree': 0.6701114322369409, 'gamma': 0.010419065313288838, 'min_child_weight': 6, 'reg_alpha': 0.837777148676382, 'reg_lambda': 0.7213404552325284}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:24,723] Trial 44 finished with value: 0.48994176813128637 and parameters: {'max_depth': 10, 'learning_rate': 0.0702145999706102, 'subsample': 0.666417495865706, 'colsample_bytree': 0.8672113500722916, 'gamma': 0.2106952961725532, 'min_child_weight': 6, 'reg_alpha': 0.8545481088792964, 'reg_lambda': 1.1565452256099382}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:26,990] Trial 45 finished with value: 0.47511911064055057 and parameters: {'max_depth': 9, 'learning_rate': 0.10516194009207713, 'subsample': 0.6270000896594058, 'colsample_bytree': 0.7125702978676984, 'gamma': 0.14943464577494536, 'min_child_weight': 4, 'reg_alpha': 0.758093175759082, 'reg_lambda': 0.6948809861669456}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:31,429] Trial 46 finished with value: 0.48676548438327155 and parameters: {'max_depth': 10, 'learning_rate': 0.08824555227333729, 'subsample': 0.6988270094321616, 'colsample_bytree': 0.9643309908483702, 'gamma': 0.01833056925089078, 'min_child_weight': 6, 'reg_alpha': 0.8161146750190433, 'reg_lambda': 1.702908089896852}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:33,140] Trial 47 finished with value: 0.46929592376919005 and parameters: {'max_depth': 10, 'learning_rate': 0.13270073638832952, 'subsample': 0.6354973540382214, 'colsample_bytree': 0.6241796380269936, 'gamma': 1.1611377225132413, 'min_child_weight': 8, 'reg_alpha': 0.6978270210477411, 'reg_lambda': 1.0358996058504446}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:34,875] Trial 48 finished with value: 0.46982530439385917 and parameters: {'max_depth': 9, 'learning_rate': 0.1898950890810116, 'subsample': 0.7227864660292536, 'colsample_bytree': 0.649078269045934, 'gamma': 0.6115750308118894, 'min_child_weight': 5, 'reg_alpha': 0.6267250129668871, 'reg_lambda': 0.9128548472081928}. Best is trial 22 with value: 0.49550026469031233.\n",
            "[I 2025-08-16 14:31:36,768] Trial 49 finished with value: 0.48438327157226047 and parameters: {'max_depth': 8, 'learning_rate': 0.06406929515273868, 'subsample': 0.6014297976178283, 'colsample_bytree': 0.6771338497454742, 'gamma': 0.842116751234283, 'min_child_weight': 9, 'reg_alpha': 0.9696418826007774, 'reg_lambda': 1.3136916643219712}. Best is trial 22 with value: 0.49550026469031233.\n",
            "\n",
            "Best parameters: {'max_depth': 10, 'learning_rate': 0.010403166981612921, 'subsample': 0.7088441385447185, 'colsample_bytree': 0.6320408163578337, 'gamma': 0.057218067212422036, 'min_child_weight': 8, 'reg_alpha': 0.9518393344365162, 'reg_lambda': 1.662765895200044}\n",
            "Best validation accuracy: 0.49550026469031233\n",
            "Best trial attrs: {'best_iteration': 234}\n",
            "[0]\ttrain-mlogloss:1.09706\teval-mlogloss:1.09808\n",
            "[50]\ttrain-mlogloss:1.02219\teval-mlogloss:1.08055\n",
            "[100]\ttrain-mlogloss:0.96309\teval-mlogloss:1.07311\n",
            "[150]\ttrain-mlogloss:0.91453\teval-mlogloss:1.06947\n",
            "[200]\ttrain-mlogloss:0.87340\teval-mlogloss:1.06814\n",
            "[250]\ttrain-mlogloss:0.83670\teval-mlogloss:1.06794\n",
            "[283]\ttrain-mlogloss:0.81557\teval-mlogloss:1.06844\n",
            "Final Test Accuracy: 0.1929081767663403\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.00      0.00      0.00       753\n",
            "         0.0       0.42      0.12      0.18      2137\n",
            "         1.0       0.19      0.54      0.28       889\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.19      3779\n",
            "   macro avg       0.15      0.16      0.12      3779\n",
            "weighted avg       0.28      0.19      0.17      3779\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0  160  411  182]\n",
            " [   0  248 1627  262]\n",
            " [   0  180  481  228]\n",
            " [   0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-O-F Predictions"
      ],
      "metadata": {
        "id": "Di2jwJEwhUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use correct aligned length (should match X_train_seq or X_tab_aligned)\n",
        "n_samples = X_train_seq.shape[0]  # or X_tab_aligned.shape[0], should be 17607\n",
        "oof_cnn = np.zeros((n_samples, 3))\n",
        "oof_lstm = np.zeros((n_samples, 3))\n",
        "oof_xgb = np.zeros((n_samples, 3))"
      ],
      "metadata": {
        "id": "P1VNAxG9xLC2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ==== Combine your split data back into one dataset ====\n",
        "X_tab = np.vstack([X_train, X_val, X_test])\n",
        "y_tab = np.concatenate([y_train, y_val, y_test])\n",
        "y_tab = pd.Series(y_tab)  # needed for .map()\n",
        "\n",
        "# ==== Time series split config ====\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# ==== Label remap (-1, 0, 1) -> (0, 1, 2) ====\n",
        "label_map = {-1: 0, 0: 1, 1: 2}\n",
        "\n",
        "# ==== One-hot encoder for DL models ====\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "y_all_mapped = y_tab.map(label_map)\n",
        "y_all_oh = enc.fit_transform(y_all_mapped.values.reshape(-1, 1))\n",
        "\n",
        "# ==== Align all arrays to the same length ====\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_all_mapped))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_all_mapped_aligned = y_all_mapped.iloc[:min_len]\n",
        "y_all_oh_aligned = y_all_oh[:min_len]\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_all_mapped_aligned.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BstRtL0ehVta",
        "outputId": "df3fb9e6-28ca-460c-d553-0b3787a64f22"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(17607, 26), seq=(17607, 24, 26), y=(17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq_aligned[train_idx], X_train_seq_aligned[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh_aligned[train_idx], y_all_oh_aligned[val_idx]\n",
        "    # Build + compile\n",
        "    cnn_model = build_cnn_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3NN2CkhDvJ",
        "outputId": "42947d1b-ce67-4148-bb1c-8fc01ede4053"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating CNN OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq_aligned[train_idx], X_train_seq_aligned[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh_aligned[train_idx], y_all_oh_aligned[val_idx]\n",
        "    # Build + compile\n",
        "    lstm_model = build_lstm_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUIXAYdhGJ4",
        "outputId": "7b9a385c-c3f5-43ed-a4c2-6ca801e541cd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating LSTM OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "    # Tabular split\n",
        "    X_tr_tab, X_va_tab = X_tab_aligned[train_idx], X_tab_aligned[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_all_mapped_aligned.iloc[train_idx], y_all_mapped_aligned.iloc[val_idx]\n",
        "    # Build with best parameters\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        num_class=3,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.0182014870849285,\n",
        "        subsample=0.8218430665716767,\n",
        "        colsample_bytree=0.7628150155615464,\n",
        "        gamma=0.7186090872199041,\n",
        "        min_child_weight=8,\n",
        "        reg_alpha=0.5856294446650139,\n",
        "        reg_lambda=2.9006322365170183,\n",
        "        n_estimators=300,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "    # Train\n",
        "    xgb_clf.fit(X_tr_tab, y_tr_tab)\n",
        "    # Predict\n",
        "    oof_xgb[val_idx] = xgb_clf.predict_proba(X_va_tab)\n",
        "\n",
        "# After all OOF prediction cells (CNN, LSTM, XGB)\n",
        "oof_idx_xgb = np.concatenate([val_idx for _, val_idx in tscv.split(X_tab_aligned)])\n",
        "print(\"oof_idx_xgb shape:\", oof_idx_xgb.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlbAkv81hL4f",
        "outputId": "84829850-70d0-4b40-e14c-f4255d85dd72"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating XGB OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n",
            "oof_idx_xgb shape: (13203,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_all_mapped_aligned.values\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")"
      ],
      "metadata": {
        "id": "6tHDwGqD9_vv",
        "outputId": "b41765f1-86a3-4716-91ff-c0112e1f7e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 OOF predictions saved to oof_preds.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.asarray(oof_idx_xgb)  # shape (17607,)\n",
        "oof_cnn_aligned = np.asarray(oof_cnn)[idx]\n",
        "oof_lstm_aligned = np.asarray(oof_lstm)[idx]\n",
        "oof_xgb_aligned = np.asarray(oof_xgb)[idx]\n",
        "print(\"Aligned shapes:\", oof_cnn_aligned.shape, oof_lstm_aligned.shape, oof_xgb_aligned.shape)"
      ],
      "metadata": {
        "id": "jhJxvxu9C6I8",
        "outputId": "c2fb2686-e0e2-41f5-d05a-ef1a23edf416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned shapes: (13203, 3) (13203, 3) (13203, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# META LEARNER"
      ],
      "metadata": {
        "id": "IhKOAKMNxrMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Ensure the XGB index mapping exists\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found. Re-run XGB OOF generation to set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "\n",
        "# 2) Select aligned rows from CNN/LSTM using that mapping\n",
        "aligned_cnn = np.asarray(oof_cnn)[idx]\n",
        "aligned_lstm = np.asarray(oof_lstm)[idx]\n",
        "aligned_xgb = np.asarray(oof_xgb)[idx]  # <-- FIX: select only aligned rows!\n",
        "\n",
        "# 3) Sanity checks\n",
        "assert aligned_cnn.shape[0] == aligned_lstm.shape[0] == aligned_xgb.shape[0], \\\n",
        "       f\"Aligned shapes mismatch: cnn {aligned_cnn.shape} lstm {aligned_lstm.shape} xgb {aligned_xgb.shape}\"\n",
        "\n",
        "# 4) Build meta matrices (stacked probabilities)\n",
        "meta_X_train = np.hstack([aligned_cnn, aligned_lstm, aligned_xgb])  # shape: (N_aligned, 9)\n",
        "\n",
        "# Use the y that matches the aligned samples\n",
        "if 'y_all_mapped_aligned' in globals():\n",
        "    meta_y_train = np.asarray(y_all_mapped_aligned)[idx]\n",
        "else:\n",
        "    # If not available, fallback to y_all_mapped (full length)\n",
        "    meta_y_train = np.asarray(y_all_mapped)[idx]\n",
        "\n",
        "print(\"meta_X_train shape:\", meta_X_train.shape)\n",
        "print(\"meta_y_train shape:\", meta_y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UY6W_zKg-fS",
        "outputId": "8d6d3783-a484-420d-f70c-42112fedc6c2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta_X_train shape: (13203, 9)\n",
            "meta_y_train shape: (13203,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — meta-features construction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model probabilities as features\n",
        "meta_probs = np.hstack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 9)\n",
        "\n",
        "# Add engineered meta-features derived from base model outputs:\n",
        "# - per-sample mean/std/max/min across base model probs\n",
        "# - disagreements (max prob - 2nd max prob) for confidence\n",
        "def meta_stats_from_probs(probs_block):\n",
        "    # probs_block shape (n, n_models * n_classes)\n",
        "    n_classes = 3\n",
        "    n_models = probs_block.shape[1] // n_classes\n",
        "    block = probs_block.reshape(len(probs_block), n_models, n_classes)\n",
        "    # per model best class prob and best class\n",
        "    best_probs = block.max(axis=2)                 # (n, n_models)\n",
        "    best_classes = block.argmax(axis=2)             # (n, n_models)\n",
        "    # statistics across models on best_probs\n",
        "    mean_best = best_probs.mean(axis=1)\n",
        "    std_best = best_probs.std(axis=1)\n",
        "    max_best = best_probs.max(axis=1)\n",
        "    min_best = best_probs.min(axis=1)\n",
        "    # disagreement: how many models agree with majority class\n",
        "    from scipy.stats import mode\n",
        "    mode_vals, mode_counts = mode(best_classes, axis=1)\n",
        "    agree_fraction = (mode_counts.ravel() / n_models)\n",
        "    # confidence gap: top prob - second top prob per model averaged\n",
        "    def gap_per_row(row_block):\n",
        "        # row_block shape (n_models, n_classes)\n",
        "        gaps = []\n",
        "        for m in range(row_block.shape[0]):\n",
        "            arr = np.sort(row_block[m])[::-1]\n",
        "            gaps.append(arr[0] - (arr[1] if arr.shape[0] > 1 else 0.0))\n",
        "        return np.mean(gaps)\n",
        "    gap = np.array([gap_per_row(row) for row in block])\n",
        "\n",
        "    stats = np.vstack([mean_best, std_best, max_best, min_best, agree_fraction, gap]).T\n",
        "    stats_cols = [\"mean_best_prob\", \"std_best_prob\", \"max_best_prob\", \"min_best_prob\", \"agree_frac\", \"avg_top_gap\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_probs(meta_probs)\n",
        "\n",
        "# Optionally add a few simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# For now, we'll build final meta_X from probs + stats\n",
        "meta_X = np.hstack([meta_probs, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_p{c}\" for c in range(3)] +\n",
        "    [f\"lstm_p{c}\" for c in range(3)] +\n",
        "    [f\"xgb_p{c}\" for c in range(3)] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F859Av3p0qf",
        "outputId": "1e93ed74-18c9-465f-d0b0-8060d808dc0c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta X shape: (17607, 15)\n",
            "Feature names: ['cnn_p0', 'cnn_p1', 'cnn_p2', 'lstm_p0', 'lstm_p1', 'lstm_p2', 'xgb_p0', 'xgb_p1', 'xgb_p2', 'mean_best_prob', 'std_best_prob', 'max_best_prob', 'min_best_prob', 'agree_frac', 'avg_top_gap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Train final meta-learner on aligned meta features (fix mismatch) ----------\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Use aligned meta arrays produced earlier\n",
        "if 'meta_X_train' in globals() and 'meta_y_train' in globals():\n",
        "    X_meta = np.asarray(meta_X_train)\n",
        "    y_meta = np.asarray(meta_y_train)\n",
        "else:\n",
        "    raise RuntimeError(\"Aligned meta arrays not found. Make sure meta_X_train and meta_y_train exist.\")\n",
        "\n",
        "print(\"Shapes before fit: X_meta:\", X_meta.shape, \"y_meta:\", y_meta.shape)\n",
        "\n",
        "# sanity\n",
        "if X_meta.shape[0] != y_meta.shape[0]:\n",
        "    raise ValueError(f\"Shape mismatch: X_meta rows {X_meta.shape[0]} != y_meta {y_meta.shape[0]}\")\n",
        "\n",
        "# compute balanced sample weights for the meta set\n",
        "sample_weight_meta = compute_sample_weight(class_weight=\"balanced\", y=y_meta)\n",
        "\n",
        "# build final model with the best hyperparameters found earlier (best_cfg)\n",
        "# make sure best_cfg exists; if not, you can hardcode the best config you printed\n",
        "try:\n",
        "    best_cfg  # noqa: F821\n",
        "except NameError:\n",
        "    # fallback: use the best config you printed: {'max_iter':200,'learning_rate':0.1,'max_depth':4}\n",
        "    best_cfg = {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
        "\n",
        "final_model = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=42)\n",
        "final_model.fit(X_meta, y_meta, sample_weight=sample_weight_meta)\n",
        "\n",
        "# Save the trained meta model\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n",
        "print(\"Final meta_learner model trained and saved to meta_laerner.pkl\")\n",
        "\n",
        "# Quick train-set diagnostics\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
        "pred_train = final_model.predict(X_meta)\n",
        "print(\"Train balanced accuracy:\", balanced_accuracy_score(y_meta, pred_train))\n",
        "print(\"Train classification report:\\n\", classification_report(y_meta, pred_train, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJul1btp2JA",
        "outputId": "92ee9a4e-43be-4c85-efcd-889d87b85b60"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes before fit: X_meta: (13203, 9) y_meta: (13203,)\n",
            "Final meta_learner model trained and saved to meta_laerner.pkl\n",
            "Train balanced accuracy: 0.8087828713016334\n",
            "Train classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7208    0.8422    0.7767      2927\n",
            "           1     0.8562    0.7299    0.7880      6878\n",
            "           2     0.7406    0.8543    0.7934      3398\n",
            "\n",
            "    accuracy                         0.7868     13203\n",
            "   macro avg     0.7725    0.8088    0.7860     13203\n",
            "weighted avg     0.7964    0.7868    0.7869     13203\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from typing import Optional\n",
        "\n",
        "def load_and_predict(\n",
        "    model_path: str,\n",
        "    meta_X: np.ndarray,\n",
        "    y: Optional[np.ndarray] = None,\n",
        "    threshold: Optional[np.ndarray] = None,\n",
        "    label_map_back: Optional[dict] = None,  # e.g. {0:-1.0, 1:0.0, 2:1.0}\n",
        "    verbose: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a saved meta model (or a dict with 'meta_model' and optional 'calibrators'),\n",
        "    restricts meta_X to 9 features, predicts probabilities and classes, applies optional thresholding,\n",
        "    and returns (probs, preds, preds_mapped_if_label_map).\n",
        "    \"\"\"\n",
        "    assert isinstance(meta_X, np.ndarray), \"meta_X must be a numpy array\"\n",
        "\n",
        "    # --- force only 9 features ---\n",
        "    if meta_X.shape[1] > 9:\n",
        "        if verbose:\n",
        "            print(f\"[INFO] meta_X has {meta_X.shape[1]} features, truncating to first 9.\")\n",
        "        meta_X = meta_X[:, :9]\n",
        "    elif meta_X.shape[1] < 9:\n",
        "        raise ValueError(f\"meta_X has {meta_X.shape[1]} features, but at least 9 are required.\")\n",
        "\n",
        "    # --- FIX: accept both 'meta_learner.pkl' and 'meta_model.pkl' as input ---\n",
        "    try:\n",
        "        obj = joblib.load(model_path)\n",
        "    except FileNotFoundError as e:\n",
        "        if model_path == \"meta_model.pkl\":\n",
        "            print(\"[WARN] meta_model.pkl not found, trying meta_learner.pkl instead.\")\n",
        "            obj = joblib.load(\"meta_learner.pkl\")\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    # object can be:\n",
        "    # - a fitted estimator with predict_proba\n",
        "    # - a dict: {'meta_model': estimator, 'calibrators': [cal1, cal2, ...]} or similar\n",
        "    if isinstance(obj, dict):\n",
        "        if verbose:\n",
        "            print(\"Loaded dict artifact with keys:\", list(obj.keys()))\n",
        "        meta_model = obj.get(\"meta_model\") or obj.get(\"model\") or obj.get(\"estimator\")\n",
        "        calibrators = obj.get(\"calibrators\", None)\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"Loaded estimator directly from\", model_path)\n",
        "        meta_model = obj\n",
        "        calibrators = None\n",
        "\n",
        "    if meta_model is None:\n",
        "        raise RuntimeError(\"No 'meta_model' found in artifact and artifact is not a direct estimator.\")\n",
        "\n",
        "    # Get probabilities\n",
        "    if calibrators:\n",
        "        if verbose:\n",
        "            print(\"Using calibrators to produce averaged probabilities (len calibrators):\", len(calibrators))\n",
        "        probs_list = []\n",
        "        for cal in calibrators:\n",
        "            if hasattr(cal, \"predict_proba\"):\n",
        "                probs_list.append(cal.predict_proba(meta_X))\n",
        "            elif hasattr(cal, \"predict\"):\n",
        "                preds = cal.predict(meta_X)\n",
        "                onehot = np.zeros((len(preds), np.max(preds)+1))\n",
        "                onehot[np.arange(len(preds)), preds] = 1.0\n",
        "                probs_list.append(onehot)\n",
        "            else:\n",
        "                raise RuntimeError(\"Calibrator does not support predict_proba or predict.\")\n",
        "        probs = np.mean(probs_list, axis=0)\n",
        "    else:\n",
        "        if not hasattr(meta_model, \"predict_proba\"):\n",
        "            raise RuntimeError(\"Loaded meta_model has no predict_proba method.\")\n",
        "        probs = meta_model.predict_proba(meta_X)\n",
        "\n",
        "    # Optional thresholding\n",
        "    if threshold is not None:\n",
        "        threshold = np.asarray(threshold)\n",
        "        if threshold.shape[0] != probs.shape[1]:\n",
        "            raise ValueError(\"threshold must have length equal to number of classes\")\n",
        "        scores = probs - threshold.reshape((1, -1))\n",
        "        preds = np.argmax(scores, axis=1)\n",
        "    else:\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Map back to original labels\n",
        "    preds_mapped = None\n",
        "    if label_map_back is not None:\n",
        "        preds_mapped = np.array([label_map_back[int(p)] for p in preds])\n",
        "\n",
        "    # Diagnostics\n",
        "    if y is not None:\n",
        "        if len(y) != len(preds):\n",
        "            raise ValueError(f\"Length mismatch: y ({len(y)}) vs preds ({len(preds)})\")\n",
        "        acc = accuracy_score(y, preds)\n",
        "        f1m = f1_score(y, preds, average=\"macro\", zero_division=0)\n",
        "        if verbose:\n",
        "            print(f\"Accuracy: {acc:.4f}   F1_macro: {f1m:.4f}\")\n",
        "            print(classification_report(y, preds, digits=4))\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"No ground-truth y provided; returning predictions only.\")\n",
        "\n",
        "    return probs, preds, preds_mapped\n"
      ],
      "metadata": {
        "id": "LoSvckCSp8Mr"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "X1nvP47MjnKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "5nGTwsv4qpi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92db5e7e-5e21-40de-e660-abcb55104b7f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['meta_learner.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "TdtsuwkPaxcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4cabfaa4-3688-4b2c-c51c-576680089d76"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8fc99f76-f531-4eee-a332-63079963ade7\", \"meta_learner.pkl\", 309664)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save the three base models\n",
        "joblib.dump(cnn_model, \"cnn_model.pkl\")\n",
        "joblib.dump(lstm_model, \"lstm_model.pkl\")\n",
        "joblib.dump(xgb_clf, \"xgb_model.pkl\")  # change to your actual XGB var name\n",
        "\n",
        "# Download them\n",
        "files.download(\"cnn_model.pkl\")\n",
        "files.download(\"lstm_model.pkl\")\n",
        "files.download(\"xgb_model.pkl\")\n"
      ],
      "metadata": {
        "id": "SF20g9Ys68Nb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "77317917-0521-42aa-b889-343822fa4fc8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7fddd0cd-bd68-4207-b0c9-e29c59795e66\", \"cnn_model.pkl\", 8295953)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bf6bb737-9559-4a66-b72f-81eaafe1e4a6\", \"lstm_model.pkl\", 5459415)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ece4fe5-8859-45ae-b218-0f93b8766b14\", \"xgb_model.pkl\", 5196568)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "files.download(\"scaler.pkl\")"
      ],
      "metadata": {
        "id": "layD2Oi7Tymv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fdacfa2626844294988d1860db050873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c8d4175e3694962a39517f4869d97d1",
              "IPY_MODEL_295920c9f59b43a3a1559dc73e3cd707",
              "IPY_MODEL_b19f49429b1245a98b67cf3ae5c18512"
            ],
            "layout": "IPY_MODEL_3723ece3ffd14598bbaf870e10727d3a"
          }
        },
        "2c8d4175e3694962a39517f4869d97d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b280a973944326b8c50d4243b6cc63",
            "placeholder": "​",
            "style": "IPY_MODEL_3fbd7a18f95d4370b1473d4a612677ec",
            "value": "Best trial: 22. Best value: 0.4955: 100%"
          }
        },
        "295920c9f59b43a3a1559dc73e3cd707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd50e02661dd4a9b813160d44d244f0f",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0890d1c153c04dc79d5ca01aec0e3169",
            "value": 50
          }
        },
        "b19f49429b1245a98b67cf3ae5c18512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212ae1f159564079a3f039fe2710c9d2",
            "placeholder": "​",
            "style": "IPY_MODEL_bfcc77a3988744a592347e03c2b08673",
            "value": " 50/50 [03:38&lt;00:00,  2.40s/it]"
          }
        },
        "3723ece3ffd14598bbaf870e10727d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b280a973944326b8c50d4243b6cc63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbd7a18f95d4370b1473d4a612677ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd50e02661dd4a9b813160d44d244f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0890d1c153c04dc79d5ca01aec0e3169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "212ae1f159564079a3f039fe2710c9d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfcc77a3988744a592347e03c2b08673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}