{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris/blob/main/solaris_reborn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Libraries"
      ],
      "metadata": {
        "id": "XUR0zNCpOy7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "dab1c1e1-15e5-400d-b374-1b7339d19ba5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "3hev1JrVPjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\"AAPL\", \"SPY\", \"TSLA\", \"NVDA\", \"QQQ\"]  # note: ^VIX for Yahoo\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "07a56831-86a0-4968-ed31-72da2b7f6856"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "SPY: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "TSLA: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "NVDA: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "QQQ: 5075 rows from 2022-09-13 13:30:00 to 2025-08-08 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL         SPY        TSLA        NVDA  \\\n",
            "Datetime                                                              \n",
            "2025-08-08 15:30:00  228.199997  636.875000  330.319214  182.908096   \n",
            "2025-08-08 16:30:00  228.675003  636.395020  328.660004  181.884995   \n",
            "2025-08-08 17:30:00  229.289993  637.219971  329.510498  182.615005   \n",
            "2025-08-08 18:30:00  228.830002  637.260010  328.630005  182.695007   \n",
            "2025-08-08 19:30:00  229.369995  637.119995  329.679993  182.750000   \n",
            "\n",
            "                            QQQ  \n",
            "Datetime                         \n",
            "2025-08-08 15:30:00  574.000000  \n",
            "2025-08-08 16:30:00  573.280029  \n",
            "2025-08-08 17:30:00  574.375000  \n",
            "2025-08-08 18:30:00  574.375000  \n",
            "2025-08-08 19:30:00  574.549988  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Creation"
      ],
      "metadata": {
        "id": "jLnkdkzRRvVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Features"
      ],
      "metadata": {
        "id": "omLPzq5TDwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    macd = ta.trend.MACD(price_series)\n",
        "    feat_tmp[\"macd\"] = macd.macd()\n",
        "    feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"SPY\", \"QQQ\", \"NVDA\"]:\n",
        "        if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    if \"^VIX\" in aligned_ffill.columns:\n",
        "        feat_tmp[\"vix_ret_1h\"] = aligned_ffill[\"^VIX\"].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    feat_tmp = feat_tmp.dropna(subset=[col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]])\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = ticker\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())\n"
      ],
      "metadata": {
        "id": "MFIHXqY5R2fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92785a02-a10d-417b-bccb-b81ecb84ca0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created features for 5 tickers\n",
            "Shape: (25210, 26)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.007971  0.012013  0.024587  0.031305 -0.007604  0.003690  0.003882   \n",
            "1  0.002602  0.008187  0.021955  0.036208 -0.003386  0.003683  0.003588   \n",
            "2  0.001715  0.012327  0.018588  0.040581  0.003208  0.003681  0.003188   \n",
            "3  0.011595  0.015967  0.028172  0.049035  0.016817  0.004992  0.003984   \n",
            "4  0.004310  0.017698  0.026030  0.047453  0.012652  0.004917  0.003945   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...      ema_20  vol_change_1h  \\\n",
            "0  0.006928  57.174728 -0.489358  ...  152.371399       0.354865   \n",
            "1  0.006946  58.880818 -0.266801  ...  152.577932      -0.018507   \n",
            "2  0.006880  60.014242 -0.068253  ...  152.790033       1.223954   \n",
            "3  0.007246  66.708324  0.231274  ...  153.152888      -0.300933   \n",
            "4  0.007102  68.822038  0.517156  ...  153.545469       0.135969   \n",
            "\n",
            "     vol_ma_24h  SPY_ret_1h  QQQ_ret_1h  NVDA_ret_1h  hour  day_of_week  \\\n",
            "0  1.176824e+07    0.007243    0.007556     0.008757    18            0   \n",
            "1  1.186138e+07    0.001443    0.001342     0.001497    19            0   \n",
            "2  1.239661e+07   -0.011685   -0.007730    -0.004633    13            1   \n",
            "3  1.266864e+07    0.001588    0.003572     0.007054    14            1   \n",
            "4  1.299610e+07   -0.000104   -0.000854    -0.005476    15            1   \n",
            "\n",
            "             datetime  ticker  \n",
            "0 2022-09-19 18:30:00    AAPL  \n",
            "1 2022-09-19 19:30:00    AAPL  \n",
            "2 2022-09-20 13:30:00    AAPL  \n",
            "3 2022-09-20 14:30:00    AAPL  \n",
            "4 2022-09-20 15:30:00    AAPL  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation"
      ],
      "metadata": {
        "id": "TKZHysWZZsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "vol_lookback = 24         # hours to compute rolling volatility\n",
        "vol_multiplier = 0.5      # threshold scaling vs volatility\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Volatility-based threshold\n",
        "    rolling_vol = price_series.pct_change().rolling(vol_lookback).std()\n",
        "    threshold = rolling_vol * vol_multiplier\n",
        "\n",
        "    # Label creation\n",
        "    label = future_ret.copy()\n",
        "    label[future_ret > threshold] = 1    # Up\n",
        "    label[future_ret < -threshold] = -1  # Down\n",
        "    label[(future_ret <= threshold) & (future_ret >= -threshold)] = 0  # Neutral\n",
        "\n",
        "    # Drop NaNs\n",
        "    label = label.dropna()\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": label.index,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[label.index],\n",
        "        \"label\": label.values,\n",
        "        \"future_ret\": future_ret.loc[label.index],\n",
        "        \"volatility\": rolling_vol.loc[label.index]\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "print(labels_df[\"label\"].value_counts(normalize=True))\n",
        "labels_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "7dbf0323-8ab9-4701-8f5c-714f766a3d3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (25370, 6)\n",
            "label\n",
            " 0.000000    0.532322\n",
            " 1.000000    0.245211\n",
            "-1.000000    0.217737\n",
            "-0.009297    0.000039\n",
            "-0.006482    0.000039\n",
            "               ...   \n",
            " 0.004660    0.000039\n",
            "-0.013126    0.000039\n",
            "-0.002298    0.000039\n",
            "-0.002268    0.000039\n",
            " 0.002448    0.000039\n",
            "Name: proportion, Length: 123, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime ticker       price     label  future_ret  volatility\n",
              "0 2022-09-13 13:30:00   AAPL  157.820007 -0.008618   -0.008618         NaN\n",
              "1 2022-09-13 14:30:00   AAPL  156.459900 -0.001324   -0.001324         NaN\n",
              "2 2022-09-13 15:30:00   AAPL  156.252701  0.001647    0.001647         NaN\n",
              "3 2022-09-13 16:30:00   AAPL  156.509995 -0.009297   -0.009297         NaN\n",
              "4 2022-09-13 17:30:00   AAPL  155.054993 -0.006482   -0.006482         NaN\n",
              "5 2022-09-13 18:30:00   AAPL  154.050003 -0.001298   -0.001298         NaN\n",
              "6 2022-09-13 19:30:00   AAPL  153.850006  0.007410    0.007410         NaN\n",
              "7 2022-09-14 13:30:00   AAPL  154.990005  0.006065    0.006065         NaN\n",
              "8 2022-09-14 14:30:00   AAPL  155.929993 -0.003912   -0.003912         NaN\n",
              "9 2022-09-14 15:30:00   AAPL  155.320007 -0.001642   -0.001642         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-080a6b3d-6928-44c7-8382-82e4d2d03314\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>label</th>\n",
              "      <th>future_ret</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-13 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>157.820007</td>\n",
              "      <td>-0.008618</td>\n",
              "      <td>-0.008618</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-13 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.459900</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-13 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.252701</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-13 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>156.509995</td>\n",
              "      <td>-0.009297</td>\n",
              "      <td>-0.009297</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-13 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>155.054993</td>\n",
              "      <td>-0.006482</td>\n",
              "      <td>-0.006482</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-13 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.050003</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-13 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.850006</td>\n",
              "      <td>0.007410</td>\n",
              "      <td>0.007410</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-14 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>154.990005</td>\n",
              "      <td>0.006065</td>\n",
              "      <td>0.006065</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-09-14 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>155.929993</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-09-14 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>155.320007</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-080a6b3d-6928-44c7-8382-82e4d2d03314')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-080a6b3d-6928-44c7-8382-82e4d2d03314 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-080a6b3d-6928-44c7-8382-82e4d2d03314');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25b6f906-6c90-4eb3-bca5-b5285bfcc080\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25b6f906-6c90-4eb3-bca5-b5285bfcc080')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25b6f906-6c90-4eb3-bca5-b5285bfcc080 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 25370,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-13 13:30:00\",\n        \"max\": \"2025-08-08 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-09-08 14:30:00\",\n          \"2024-03-19 19:30:00\",\n          \"2022-09-19 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SPY\",\n          \"QQQ\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 164.9018868280772,\n        \"min\": 11.14999008178711,\n        \"max\": 638.8200073242188,\n        \"num_unique_values\": 23047,\n        \"samples\": [\n          256.17999267578125,\n          115.37909698486328,\n          190.27499389648438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6798621000448775,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          -0.010206823419083452,\n          -0.008030450047519849,\n          -0.01496935961038128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009396225312605574,\n        \"min\": -0.13022686951739132,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          0.002815443242036273,\n          0.029964044609556647,\n          0.0016589617246019581\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005531955109130905,\n        \"min\": 0.0008914795917642343,\n        \"max\": 0.05414076773543391,\n        \"num_unique_values\": 25250,\n        \"samples\": [\n          0.014011333107111322,\n          0.005262215907619315,\n          0.0021794746472931646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "rieWxNf5Mp44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1H-ATXHjSK6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Features"
      ],
      "metadata": {
        "id": "_PxZH38IebtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & labels\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y distribution:\\n\", y.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "OERLO3TNed16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ad5239-43e5-4c0e-c2b9-b1b67bb1aed0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25205, 26)\n",
            "y distribution:\n",
            " label\n",
            " 0.0    0.534854\n",
            " 1.0    0.246023\n",
            "-1.0    0.219123\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale"
      ],
      "metadata": {
        "id": "rpnDnFsiWa87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Label distribution in Train:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "4oxCtsXaSTrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b4edaf-3301-4f93-a25c-9b34d57174c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train: (17631, 26), Val: (3778, 26), Test: (3779, 26)\n",
            "Label distribution in Train: label\n",
            " 0.0    0.525268\n",
            " 1.0    0.252113\n",
            "-1.0    0.222619\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence making - For LSTM AND CNN"
      ],
      "metadata": {
        "id": "euQxLDkaWdBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 24  # last 24 hours to predict next hour\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "id": "mn5XIK9DWlAN",
        "outputId": "6af448c9-ff84-4273-e7f7-6328a26c821c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (17607, 24, 26), Val seq: (3754, 24, 26), Test seq: (3755, 24, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 — label encoding + class weights\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# mapping: -1 -> 0 (down), 0 -> 1 (neutral), 1 -> 2 (up)\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "\n",
        "# If your y_* are numpy arrays (seq labels), convert\n",
        "y_train_seq_mapped = np.vectorize(label_map.get)(y_train_seq)\n",
        "y_val_seq_mapped   = np.vectorize(label_map.get)(y_val_seq)\n",
        "y_test_seq_mapped  = np.vectorize(label_map.get)(y_test_seq)\n",
        "\n",
        "# one-hot for Keras\n",
        "y_train_cat = to_categorical(y_train_seq_mapped, num_classes=3)\n",
        "y_val_cat   = to_categorical(y_val_seq_mapped, num_classes=3)\n",
        "y_test_cat  = to_categorical(y_test_seq_mapped, num_classes=3)\n",
        "\n",
        "# compute class weights from training sequence labels\n",
        "classes = np.unique(y_train_seq_mapped)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_seq_mapped)\n",
        "class_weights_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "print(\"Train class distribution:\", np.bincount(y_train_seq_mapped) / len(y_train_seq_mapped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "f86e3193-5170-47a7-9d01-d375c85a31e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.4983405667602758), 1: np.float64(0.6344864864864865), 2: np.float64(1.321846846846847)}\n",
            "Train class distribution: [0.22246834 0.52535923 0.25217243]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1jUYMhA9cSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === CNN Architecture ===\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, GlobalAveragePooling1D, Dense\n",
        "\n",
        "def build_cnn_best(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = Conv1D(64, kernel_size=3, padding='same')(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(128, kernel_size=5, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv1D(256, kernel_size=3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    return model\n",
        "\n",
        "cnn_model = build_cnn_best(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n"
      ],
      "metadata": {
        "id": "2mDqNrx0SddA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "-p_nIYgVcWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LSTM Architecture (Fixed) ===\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, LayerNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate\n",
        "\n",
        "def build_lstm_best(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = LayerNormalization()(inp)\n",
        "\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Use Keras pooling layers instead of raw TF ops\n",
        "    x_avg = GlobalAveragePooling1D()(x)\n",
        "    x_max = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([x_avg, x_max])\n",
        "\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    return model\n",
        "\n",
        "# Instantiate\n",
        "lstm_model = build_lstm_best(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n"
      ],
      "metadata": {
        "id": "IYtsddwpfp1i"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "7FalnDi8fxYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === XGBoost Setup ===\n",
        "import xgboost as xgb\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import numpy as np\n",
        "\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "y_train_tab = np.vectorize(label_map.get)(y_train)\n",
        "y_val_tab   = np.vectorize(label_map.get)(y_val)\n",
        "y_test_tab  = np.vectorize(label_map.get)(y_test)\n",
        "\n",
        "sample_weight = compute_sample_weight('balanced', y_train_tab)\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=3,\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='auto'\n",
        ")\n"
      ],
      "metadata": {
        "id": "EjSEPd16f61x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "TKR7NlqVaq34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cOvOaClz5nPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === CNN Training ===\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=1e-6, verbose=1)\n",
        "chk = ModelCheckpoint('best_cnn.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=80,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "13827b68-d1f0-4b01-ee51-0b15267e95a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 30s - 215ms/step - accuracy: 0.4032 - loss: 1.0999 - val_accuracy: 0.4451 - val_loss: 1.0644 - learning_rate: 1.0000e-03\n",
            "Epoch 2/80\n",
            "138/138 - 20s - 144ms/step - accuracy: 0.4490 - loss: 1.0722 - val_accuracy: 0.4294 - val_loss: 1.0801 - learning_rate: 1.0000e-03\n",
            "Epoch 3/80\n",
            "138/138 - 13s - 91ms/step - accuracy: 0.4673 - loss: 1.0623 - val_accuracy: 0.4065 - val_loss: 1.0935 - learning_rate: 1.0000e-03\n",
            "Epoch 4/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 20s - 148ms/step - accuracy: 0.4786 - loss: 1.0524 - val_accuracy: 0.4704 - val_loss: 1.0453 - learning_rate: 1.0000e-03\n",
            "Epoch 5/80\n",
            "138/138 - 21s - 151ms/step - accuracy: 0.4840 - loss: 1.0421 - val_accuracy: 0.4100 - val_loss: 1.0997 - learning_rate: 1.0000e-03\n",
            "Epoch 6/80\n",
            "138/138 - 21s - 152ms/step - accuracy: 0.4943 - loss: 1.0324 - val_accuracy: 0.4529 - val_loss: 1.0653 - learning_rate: 1.0000e-03\n",
            "Epoch 7/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 21s - 149ms/step - accuracy: 0.5011 - loss: 1.0222 - val_accuracy: 0.4939 - val_loss: 1.0344 - learning_rate: 1.0000e-03\n",
            "Epoch 8/80\n",
            "138/138 - 20s - 142ms/step - accuracy: 0.5086 - loss: 1.0091 - val_accuracy: 0.4686 - val_loss: 1.0489 - learning_rate: 1.0000e-03\n",
            "Epoch 9/80\n",
            "138/138 - 14s - 101ms/step - accuracy: 0.5095 - loss: 0.9977 - val_accuracy: 0.4579 - val_loss: 1.0740 - learning_rate: 1.0000e-03\n",
            "Epoch 10/80\n",
            "138/138 - 13s - 94ms/step - accuracy: 0.5197 - loss: 0.9877 - val_accuracy: 0.4763 - val_loss: 1.0525 - learning_rate: 1.0000e-03\n",
            "Epoch 11/80\n",
            "138/138 - 13s - 91ms/step - accuracy: 0.5296 - loss: 0.9729 - val_accuracy: 0.4912 - val_loss: 1.0404 - learning_rate: 1.0000e-03\n",
            "Epoch 12/80\n",
            "138/138 - 20s - 148ms/step - accuracy: 0.5327 - loss: 0.9640 - val_accuracy: 0.4672 - val_loss: 1.0704 - learning_rate: 1.0000e-03\n",
            "Epoch 13/80\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "138/138 - 20s - 148ms/step - accuracy: 0.5380 - loss: 0.9501 - val_accuracy: 0.4547 - val_loss: 1.1094 - learning_rate: 1.0000e-03\n",
            "Epoch 14/80\n",
            "138/138 - 12s - 90ms/step - accuracy: 0.5551 - loss: 0.9148 - val_accuracy: 0.3687 - val_loss: 1.1852 - learning_rate: 5.0000e-04\n",
            "Epoch 15/80\n",
            "138/138 - 12s - 90ms/step - accuracy: 0.5631 - loss: 0.8967 - val_accuracy: 0.3761 - val_loss: 1.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 16/80\n",
            "138/138 - 22s - 158ms/step - accuracy: 0.5656 - loss: 0.8905 - val_accuracy: 0.3508 - val_loss: 1.2524 - learning_rate: 5.0000e-04\n",
            "Epoch 17/80\n",
            "138/138 - 12s - 90ms/step - accuracy: 0.5742 - loss: 0.8758 - val_accuracy: 0.3780 - val_loss: 1.2113 - learning_rate: 5.0000e-04\n",
            "Epoch 18/80\n",
            "138/138 - 20s - 148ms/step - accuracy: 0.5773 - loss: 0.8658 - val_accuracy: 0.3663 - val_loss: 1.2251 - learning_rate: 5.0000e-04\n",
            "Epoch 19/80\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "138/138 - 12s - 91ms/step - accuracy: 0.5822 - loss: 0.8535 - val_accuracy: 0.3780 - val_loss: 1.2376 - learning_rate: 5.0000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yxu1niZ7gq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LSTM Training ===\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=1e-6, verbose=1)\n",
        "chk = ModelCheckpoint('best_lstm.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "06f0f474-07b7-43e0-ae20-843bebeaf941"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 49s - 353ms/step - accuracy: 0.4139 - loss: 1.0866 - val_accuracy: 0.4036 - val_loss: 1.0861 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 78s - 565ms/step - accuracy: 0.4479 - loss: 1.0718 - val_accuracy: 0.4153 - val_loss: 1.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 41s - 296ms/step - accuracy: 0.4640 - loss: 1.0571 - val_accuracy: 0.4315 - val_loss: 1.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "138/138 - 42s - 303ms/step - accuracy: 0.4782 - loss: 1.0444 - val_accuracy: 0.4113 - val_loss: 1.0827 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "138/138 - 39s - 283ms/step - accuracy: 0.4900 - loss: 1.0244 - val_accuracy: 0.4046 - val_loss: 1.0754 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "138/138 - 42s - 303ms/step - accuracy: 0.5060 - loss: 1.0013 - val_accuracy: 0.4124 - val_loss: 1.0779 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 - 41s - 300ms/step - accuracy: 0.5206 - loss: 0.9738 - val_accuracy: 0.4257 - val_loss: 1.0674 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "138/138 - 43s - 314ms/step - accuracy: 0.5404 - loss: 0.9385 - val_accuracy: 0.4078 - val_loss: 1.0895 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "138/138 - 39s - 282ms/step - accuracy: 0.5584 - loss: 0.9136 - val_accuracy: 0.4366 - val_loss: 1.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "138/138 - 38s - 272ms/step - accuracy: 0.5739 - loss: 0.8760 - val_accuracy: 0.4321 - val_loss: 1.0784 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "138/138 - 37s - 270ms/step - accuracy: 0.5884 - loss: 0.8465 - val_accuracy: 0.4267 - val_loss: 1.1009 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "138/138 - 43s - 308ms/step - accuracy: 0.6058 - loss: 0.8149 - val_accuracy: 0.4329 - val_loss: 1.0858 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "138/138 - 39s - 284ms/step - accuracy: 0.6135 - loss: 0.7887 - val_accuracy: 0.4542 - val_loss: 1.0777 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "138/138 - 38s - 274ms/step - accuracy: 0.6419 - loss: 0.7348 - val_accuracy: 0.4132 - val_loss: 1.1381 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "138/138 - 40s - 292ms/step - accuracy: 0.6594 - loss: 0.7095 - val_accuracy: 0.4206 - val_loss: 1.1382 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "138/138 - 42s - 307ms/step - accuracy: 0.6658 - loss: 0.6841 - val_accuracy: 0.4286 - val_loss: 1.1387 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "138/138 - 39s - 284ms/step - accuracy: 0.6745 - loss: 0.6638 - val_accuracy: 0.4201 - val_loss: 1.1594 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "138/138 - 37s - 268ms/step - accuracy: 0.6847 - loss: 0.6487 - val_accuracy: 0.4305 - val_loss: 1.1650 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "138/138 - 40s - 292ms/step - accuracy: 0.6876 - loss: 0.6362 - val_accuracy: 0.4331 - val_loss: 1.1849 - learning_rate: 2.5000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "2RHWbvELgyIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create DMatrix objects\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_tab)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_tab)\n",
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': 3,\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'seed': 42,\n",
        "    'tree_method': 'hist'\n",
        "}\n",
        "\n",
        "# Train with early stopping\n",
        "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")\n",
        "\n",
        "# Predict\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "y_pred = model.predict(dtest)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test_tab, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOUy9Yd0g-6E",
        "outputId": "459ae0cf-bb98-4fae-b372-03d68986b56f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.08732\teval-mlogloss:1.08898\n",
            "[50]\ttrain-mlogloss:0.89629\teval-mlogloss:0.96849\n",
            "[100]\ttrain-mlogloss:0.83466\teval-mlogloss:0.96683\n",
            "[132]\ttrain-mlogloss:0.80427\teval-mlogloss:0.96905\n",
            "Test Accuracy: 0.5824292140777984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-O-F Predictions"
      ],
      "metadata": {
        "id": "Di2jwJEwhUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Time series split config\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Label remap (-1, 0, 1) -> (0, 1, 2)\n",
        "label_map = {-1: 0, 0: 1, 1: 2}\n",
        "\n",
        "# One-hot encoder for DL models\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "y_all_mapped = y_tab.map(label_map)\n",
        "y_all_oh = enc.fit_transform(y_all_mapped.values.reshape(-1, 1))\n",
        "\n",
        "# Storage for OOF predictions\n",
        "oof_cnn = np.zeros((len(X_tab), 3))\n",
        "oof_lstm = np.zeros((len(X_tab), 3))\n",
        "oof_xgb = np.zeros((len(X_tab), 3))\n",
        "\n",
        "# Ensure tabular and sequence data match in length\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_all_mapped))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_all_mapped_aligned = y_all_mapped.iloc[:min_len]\n",
        "y_all_oh_aligned = y_all_oh[:min_len]\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_all_mapped_aligned.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BstRtL0ehVta",
        "outputId": "c98625ad-bd38-4454-e19a-1dd9dc2c5597"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(17607, 26), seq=(17607, 24, 26), y=(17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    cnn_model = build_cnn_best(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3NN2CkhDvJ",
        "outputId": "90bb3509-69f5-432b-99f5-d0666f3a5a2f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating CNN OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    lstm_model = build_lstm_best(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUIXAYdhGJ4",
        "outputId": "80afb360-36aa-427f-b11f-a8cc7a51f336"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating LSTM OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Tabular\n",
        "    X_tr_tab, X_va_tab = X_tab[train_idx], X_tab[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_all_mapped.iloc[train_idx], y_all_mapped.iloc[val_idx]\n",
        "\n",
        "    # Build\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        num_class=3,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        n_estimators=300,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_clf.fit(X_tr_tab, y_tr_tab)\n",
        "\n",
        "    # Predict\n",
        "    oof_xgb[val_idx] = xgb_clf.predict_proba(X_va_tab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlbAkv81hL4f",
        "outputId": "4148d572-6fc3-472b-8e15-f2d431e09f72"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating XGB OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack all model predictions for meta-learner\n",
        "meta_X_train = np.hstack([oof_cnn, oof_lstm, oof_xgb])\n",
        "meta_y_train = y_all_mapped.values  # already mapped to (0,1,2)\n",
        "\n",
        "print(\"✅ OOF generation complete!\")\n",
        "print(\"Meta-train shape:\", meta_X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oypZH8ABhQFk",
        "outputId": "c334c67b-b12f-4c1e-f5bb-0de82c9b9315"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OOF generation complete!\n",
            "Meta-train shape: (17631, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# Save OOF predictions and labels\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_all_mapped.values\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5i8N1lJps85",
        "outputId": "cef6b3dc-1d29-4cb0-b38e-c446d89c6535"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 OOF predictions saved to oof_preds.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# META LEARNER"
      ],
      "metadata": {
        "id": "IhKOAKMNxrMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A — Load OOF predictions and align\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "# Try to load previously saved OOF predictions. If you already have them in memory,\n",
        "# replace this with the arrays directly (oof_cnn, oof_lstm, oof_xgb, y).\n",
        "oof_path = \"oof_preds.pkl\"\n",
        "obj = joblib.load(oof_path)  # expects dict with \"oof_cnn\",\"oof_lstm\",\"oof_xgb\",\"y\"\n",
        "\n",
        "oof_cnn = obj[\"oof_cnn\"]    # shape (n_samples, 3)\n",
        "oof_lstm = obj[\"oof_lstm\"]\n",
        "oof_xgb = obj[\"oof_xgb\"]\n",
        "y_raw   = obj[\"y\"]          # ground-truth labels used during OOF (mapped 0/1/2 or original)\n",
        "\n",
        "# Make numpy arrays and check sizes\n",
        "oof_cnn = np.asarray(oof_cnn)\n",
        "oof_lstm = np.asarray(oof_lstm)\n",
        "oof_xgb = np.asarray(oof_xgb)\n",
        "y_raw = np.asarray(y_raw).ravel()\n",
        "\n",
        "print(\"Shapes:\", oof_cnn.shape, oof_lstm.shape, oof_xgb.shape, y_raw.shape)\n",
        "\n",
        "# Basic sanity checks\n",
        "n = len(y_raw)\n",
        "assert oof_cnn.shape[0] == n and oof_lstm.shape[0] == n and oof_xgb.shape[0] == n, \"OOF arrays must align with labels\"\n",
        "\n",
        "# If your y is in -1/0/1 mapping, map to 0/1/2 (consistent)\n",
        "# Detect automatically if values are -1/0/1 and map to 0/1/2\n",
        "if set(np.unique(y_raw)).issuperset({-1,0,1}) and set(np.unique(y_raw)).difference({-1,0,1})==set():\n",
        "    print(\"Detected labels in {-1,0,1} — remapping to {0,1,2}\")\n",
        "    map_arr = np.array([0 if v==-1 else (1 if v==0 else 2) for v in y_raw])\n",
        "    y = map_arr\n",
        "else:\n",
        "    # assume already 0/1/2\n",
        "    y = y_raw.copy()\n",
        "\n",
        "# Confirm class distribution\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"Label distribution (mapped):\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UY6W_zKg-fS",
        "outputId": "fa46adf0-2f0d-4d4b-fb80-90ae5fc86f84"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (17631, 3) (17631, 3) (17631, 3) (17631,)\n",
            "Label distribution (mapped): {np.int64(0): np.int64(3925), np.int64(1): np.int64(9261), np.int64(2): np.int64(4445)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — meta-features construction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model probabilities as features\n",
        "meta_probs = np.hstack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 9)\n",
        "\n",
        "# Add engineered meta-features derived from base model outputs:\n",
        "# - per-sample mean/std/max/min across base model probs\n",
        "# - disagreements (max prob - 2nd max prob) for confidence\n",
        "def meta_stats_from_probs(probs_block):\n",
        "    # probs_block shape (n, n_models * n_classes)\n",
        "    n_classes = 3\n",
        "    n_models = probs_block.shape[1] // n_classes\n",
        "    block = probs_block.reshape(len(probs_block), n_models, n_classes)\n",
        "    # per model best class prob and best class\n",
        "    best_probs = block.max(axis=2)                 # (n, n_models)\n",
        "    best_classes = block.argmax(axis=2)             # (n, n_models)\n",
        "    # statistics across models on best_probs\n",
        "    mean_best = best_probs.mean(axis=1)\n",
        "    std_best = best_probs.std(axis=1)\n",
        "    max_best = best_probs.max(axis=1)\n",
        "    min_best = best_probs.min(axis=1)\n",
        "    # disagreement: how many models agree with majority class\n",
        "    from scipy.stats import mode\n",
        "    mode_vals, mode_counts = mode(best_classes, axis=1)\n",
        "    agree_fraction = (mode_counts.ravel() / n_models)\n",
        "    # confidence gap: top prob - second top prob per model averaged\n",
        "    def gap_per_row(row_block):\n",
        "        # row_block shape (n_models, n_classes)\n",
        "        gaps = []\n",
        "        for m in range(row_block.shape[0]):\n",
        "            arr = np.sort(row_block[m])[::-1]\n",
        "            gaps.append(arr[0] - (arr[1] if arr.shape[0] > 1 else 0.0))\n",
        "        return np.mean(gaps)\n",
        "    gap = np.array([gap_per_row(row) for row in block])\n",
        "\n",
        "    stats = np.vstack([mean_best, std_best, max_best, min_best, agree_fraction, gap]).T\n",
        "    stats_cols = [\"mean_best_prob\", \"std_best_prob\", \"max_best_prob\", \"min_best_prob\", \"agree_frac\", \"avg_top_gap\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_probs(meta_probs)\n",
        "\n",
        "# Optionally add a few simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# For now, we'll build final meta_X from probs + stats\n",
        "meta_X = np.hstack([meta_probs, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_p{c}\" for c in range(3)] +\n",
        "    [f\"lstm_p{c}\" for c in range(3)] +\n",
        "    [f\"xgb_p{c}\" for c in range(3)] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F859Av3p0qf",
        "outputId": "f00c9537-e2ab-44ef-93d5-75e5743b2b2b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta X shape: (17631, 15)\n",
            "Feature names: ['cnn_p0', 'cnn_p1', 'cnn_p2', 'lstm_p0', 'lstm_p1', 'lstm_p2', 'xgb_p0', 'xgb_p1', 'xgb_p2', 'mean_best_prob', 'std_best_prob', 'max_best_prob', 'min_best_prob', 'agree_frac', 'avg_top_gap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — Train meta-learner with TimeSeriesSplit CV and calibration\n",
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "n_splits = 5\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# We will collect fold validation predictions for diagnostics\n",
        "val_preds = np.zeros((len(meta_X), 3))   # prob preds\n",
        "val_mask = np.zeros(len(meta_X), dtype=bool)\n",
        "\n",
        "# Simple hyperparameter grid (small)\n",
        "param_grid = [\n",
        "    {\"max_iter\": 200, \"learning_rate\": 0.05, \"max_depth\": 6},\n",
        "    {\"max_iter\": 300, \"learning_rate\": 0.03, \"max_depth\": 8},\n",
        "    {\"max_iter\": 200, \"learning_rate\": 0.1,  \"max_depth\": 4},\n",
        "]\n",
        "\n",
        "best_cfg = None\n",
        "best_score = -1\n",
        "\n",
        "for cfg in param_grid:\n",
        "    print(\"Testing cfg:\", cfg)\n",
        "    cfg_val_probs = np.zeros((len(meta_X), 3))\n",
        "    cfg_mask = np.zeros(len(meta_X), dtype=bool)\n",
        "    fold_scores = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(meta_X), 1):\n",
        "        X_tr, X_va = meta_X[tr_idx], meta_X[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        # Light class imbalance: use class_weight via sample_weight\n",
        "        # compute sample_weight as inverse freq on train\n",
        "        unique, counts = np.unique(y_tr, return_counts=True)\n",
        "        inv_freq = {u: (1.0 / c) for u, c in zip(unique, counts)}\n",
        "        sample_weight = np.array([inv_freq[v] for v in y_tr])\n",
        "\n",
        "        model = HistGradientBoostingClassifier(**cfg, early_stopping=True, scoring=\"f1_macro\", random_state=42)\n",
        "        model.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
        "\n",
        "        probs = model.predict_proba(X_va)\n",
        "        cfg_val_probs[va_idx] = probs\n",
        "        cfg_mask[va_idx] = True\n",
        "\n",
        "        # compute fold metric: macro F1 on argmax preds\n",
        "        preds = probs.argmax(axis=1)\n",
        "        f1 = f1_score(y_va, preds, average=\"macro\", zero_division=0)\n",
        "        fold_scores.append(f1)\n",
        "        print(f\"  fold {fold} f1_macro: {f1:.4f}\")\n",
        "\n",
        "    mean_f1 = np.mean(fold_scores)\n",
        "    print(\"  mean f1_macro:\", mean_f1)\n",
        "    if mean_f1 > best_score:\n",
        "        best_score = mean_f1\n",
        "        best_cfg = cfg\n",
        "        best_oof_probs = cfg_val_probs.copy()\n",
        "    print(\"----\")\n",
        "\n",
        "print(\"Best cfg:\", best_cfg, \"best mean f1_macro:\", best_score)\n",
        "\n",
        "# Train final meta model on full training portion (we will use the same model type + calibration)\n",
        "final_model = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=42)\n",
        "# compute final sample weights on entire meta training set\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "inv_freq = {u: (1.0 / c) for u, c in zip(unique, counts)}\n",
        "sample_weight_full = np.array([inv_freq[v] for v in y])\n",
        "final_model.fit(meta_X, y, sample_weight=sample_weight_full)\n",
        "\n",
        "# Calibrate probabilities (Platt scaling) using cross-validation\n",
        "calibrator = CalibratedClassifierCV(final_model, method=\"sigmoid\", cv=3)  # cv on folds (not time-aware)\n",
        "calibrator.fit(meta_X, y)\n",
        "\n",
        "# Save\n",
        "import joblib\n",
        "joblib.dump({\"meta_model\": final_model, \"calibrator\": calibrator, \"best_cfg\": best_cfg, \"meta_feature_names\": meta_feature_names}, \"meta_model.pkl\")\n",
        "print(\"Saved meta_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJul1btp2JA",
        "outputId": "533b6942-9fab-4cb1-c508-c13cf8a63966"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing cfg: {'max_iter': 200, 'learning_rate': 0.05, 'max_depth': 6}\n",
            "  fold 1 f1_macro: 0.1220\n",
            "  fold 2 f1_macro: 0.6719\n",
            "  fold 3 f1_macro: 0.7021\n",
            "  fold 4 f1_macro: 0.7194\n",
            "  fold 5 f1_macro: 0.7198\n",
            "  mean f1_macro: 0.5870340309627685\n",
            "----\n",
            "Testing cfg: {'max_iter': 300, 'learning_rate': 0.03, 'max_depth': 8}\n",
            "  fold 1 f1_macro: 0.1220\n",
            "  fold 2 f1_macro: 0.6779\n",
            "  fold 3 f1_macro: 0.7032\n",
            "  fold 4 f1_macro: 0.7185\n",
            "  fold 5 f1_macro: 0.7198\n",
            "  mean f1_macro: 0.5882808873047827\n",
            "----\n",
            "Testing cfg: {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
            "  fold 1 f1_macro: 0.1220\n",
            "  fold 2 f1_macro: 0.6810\n",
            "  fold 3 f1_macro: 0.7035\n",
            "  fold 4 f1_macro: 0.7263\n",
            "  fold 5 f1_macro: 0.7294\n",
            "  mean f1_macro: 0.5924434043516823\n",
            "----\n",
            "Best cfg: {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4} best mean f1_macro: 0.5924434043516823\n",
            "Saved meta_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D — evaluate & threshold tuning\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
        "from itertools import product\n",
        "\n",
        "# load calibrator if needed\n",
        "obj = joblib.load(\"meta_model.pkl\")\n",
        "calibrator = obj[\"calibrator\"]\n",
        "\n",
        "probs = calibrator.predict_proba(meta_X)   # (n,3) calibrated\n",
        "y_true = y\n",
        "\n",
        "# baseline: argmax\n",
        "pred_argmax = probs.argmax(axis=1)\n",
        "print(\"Baseline (argmax) metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_true, pred_argmax))\n",
        "print(classification_report(y_true, pred_argmax, zero_division=0))\n",
        "\n",
        "# tune \"confidence cutoff\" — if top probability < cutoff => force neutral class (1)\n",
        "best_cutoff = 0.0\n",
        "best_f1 = -1\n",
        "best_preds = None\n",
        "for cutoff in np.linspace(0.0, 0.75, 16):\n",
        "    top_probs = probs.max(axis=1)\n",
        "    preds = probs.argmax(axis=1).copy()\n",
        "    # map anything with low confidence to neutral class index (1)\n",
        "    preds[top_probs < cutoff] = 1\n",
        "    f1 = f1_score(y_true, preds, average=\"macro\", zero_division=0)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_cutoff = cutoff\n",
        "        best_preds = preds.copy()\n",
        "\n",
        "print(\"Best confidence cutoff:\", best_cutoff, \"=> macro F1:\", best_f1)\n",
        "print(\"Metrics with best cutoff:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_true, best_preds))\n",
        "print(classification_report(y_true, best_preds, zero_division=0))\n",
        "print(\"Confusion matrix (rows=actual, cols=pred):\")\n",
        "print(confusion_matrix(y_true, best_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSvckCSp8Mr",
        "outputId": "1b77f41e-138f-4f8c-c458-fb1ac4e5259f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (argmax) metrics:\n",
            "Accuracy: 0.7045544779082298\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.52      0.62      3925\n",
            "           1       0.68      0.86      0.76      9261\n",
            "           2       0.75      0.54      0.62      4445\n",
            "\n",
            "    accuracy                           0.70     17631\n",
            "   macro avg       0.73      0.64      0.67     17631\n",
            "weighted avg       0.72      0.70      0.69     17631\n",
            "\n",
            "Best confidence cutoff: 0.35000000000000003 => macro F1: 0.6683918915681422\n",
            "Metrics with best cutoff:\n",
            "Accuracy: 0.7045544779082298\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.52      0.62      3925\n",
            "           1       0.68      0.86      0.76      9261\n",
            "           2       0.75      0.54      0.62      4445\n",
            "\n",
            "    accuracy                           0.70     17631\n",
            "   macro avg       0.73      0.64      0.67     17631\n",
            "weighted avg       0.72      0.70      0.69     17631\n",
            "\n",
            "Confusion matrix (rows=actual, cols=pred):\n",
            "[[2033 1808   84]\n",
            " [ 528 8008  725]\n",
            " [  50 2014 2381]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "X1nvP47MjnKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained meta-learner\n",
        "meta_model_path = \"meta_learner.pkl\"\n",
        "joblib.dump(meta_clf, meta_model_path)\n",
        "\n",
        "print(f\"✅ Meta-learner saved to {meta_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nGTwsv4qpi6",
        "outputId": "e1e52e03-eb68-4891-bf65-18579431f8a3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Meta-learner saved to meta_learner.pkl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}