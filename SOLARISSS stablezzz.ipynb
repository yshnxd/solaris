{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris/blob/main/SOLARISSS%20stablezzz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Libraries"
      ],
      "metadata": {
        "id": "XUR0zNCpOy7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "1563b680-172e-4803-86e1-6abf6cf9541c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "3hev1JrVPjXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\"AAPL\", \"SPY\", \"TSLA\", \"NVDA\", \"QQQ\"]  # note: ^VIX for Yahoo\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "cba782ca-31aa-4fb6-a29a-58f64fa26b78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "SPY: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "TSLA: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "NVDA: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "QQQ: 5075 rows from 2022-09-15 13:30:00 to 2025-08-12 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL         SPY        TSLA        NVDA  \\\n",
            "Datetime                                                              \n",
            "2025-08-12 15:30:00  229.779999  641.379272  338.031494  182.274994   \n",
            "2025-08-12 16:30:00  229.774994  641.539978  338.790009  182.240005   \n",
            "2025-08-12 17:30:00  229.570007  642.219971  339.413696  183.065002   \n",
            "2025-08-12 18:30:00  229.182999  642.320007  340.859985  182.784500   \n",
            "2025-08-12 19:30:00  229.649994  642.630005  340.755005  183.100006   \n",
            "\n",
            "                            QQQ  \n",
            "Datetime                         \n",
            "2025-08-12 15:30:00  578.659973  \n",
            "2025-08-12 16:30:00  578.887085  \n",
            "2025-08-12 17:30:00  579.619995  \n",
            "2025-08-12 18:30:00  579.744995  \n",
            "2025-08-12 19:30:00  580.020020  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Creation"
      ],
      "metadata": {
        "id": "jLnkdkzRRvVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Features"
      ],
      "metadata": {
        "id": "omLPzq5TDwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    macd = ta.trend.MACD(price_series)\n",
        "    feat_tmp[\"macd\"] = macd.macd()\n",
        "    feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"SPY\", \"QQQ\", \"NVDA\"]:\n",
        "        if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    if \"^VIX\" in aligned_ffill.columns:\n",
        "        feat_tmp[\"vix_ret_1h\"] = aligned_ffill[\"^VIX\"].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    feat_tmp = feat_tmp.dropna(subset=[col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]])\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = ticker\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())\n"
      ],
      "metadata": {
        "id": "MFIHXqY5R2fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04ad809-6165-46a6-b270-0dff544c0511"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created features for 5 tickers\n",
            "Shape: (25210, 26)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.003927 -0.009147 -0.007584  0.005846  0.046665  0.007817  0.007090   \n",
            "1 -0.012844 -0.022400 -0.023381 -0.018455  0.029676  0.008701  0.007126   \n",
            "2 -0.008392 -0.017286 -0.023793 -0.030869  0.015118  0.008742  0.007124   \n",
            "3 -0.007873 -0.028836 -0.037719 -0.030889  0.002985  0.007122  0.007125   \n",
            "4  0.005376 -0.010910 -0.033066 -0.026802  0.010589  0.008245  0.007425   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...      ema_20  vol_change_1h  \\\n",
            "0  0.005565  54.275636  0.990354  ...  155.298311       0.531565   \n",
            "1  0.006314  44.979346  0.740424  ...  155.147044      -0.481519   \n",
            "2  0.006528  40.196954  0.433265  ...  154.887325       0.716998   \n",
            "3  0.006707  36.327580  0.091949  ...  154.538056      -0.441574   \n",
            "4  0.006770  40.506051 -0.111656  ...  154.299480      -0.340051   \n",
            "\n",
            "     vol_ma_24h  SPY_ret_1h  QQQ_ret_1h  NVDA_ret_1h  hour  day_of_week  \\\n",
            "0  1.222141e+07   -0.000655    0.000349     0.006716    18            2   \n",
            "1  1.245613e+07   -0.010903   -0.012474    -0.017339    19            2   \n",
            "2  1.298858e+07   -0.004611   -0.008574    -0.036974    13            3   \n",
            "3  1.299329e+07   -0.003620   -0.005088    -0.014084    14            3   \n",
            "4  1.284415e+07    0.002056    0.002861     0.002052    15            3   \n",
            "\n",
            "             datetime  ticker  \n",
            "0 2022-09-21 18:30:00    AAPL  \n",
            "1 2022-09-21 19:30:00    AAPL  \n",
            "2 2022-09-22 13:30:00    AAPL  \n",
            "3 2022-09-22 14:30:00    AAPL  \n",
            "4 2022-09-22 15:30:00    AAPL  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation"
      ],
      "metadata": {
        "id": "TKZHysWZZsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "vol_lookback = 24         # hours to compute rolling volatility\n",
        "vol_multiplier = 0.5      # threshold scaling vs volatility\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Volatility-based threshold\n",
        "    rolling_vol = price_series.pct_change().rolling(vol_lookback).std()\n",
        "    threshold = rolling_vol * vol_multiplier\n",
        "\n",
        "    # Label creation\n",
        "    label = future_ret.copy()\n",
        "    label[future_ret > threshold] = 1    # Up\n",
        "    label[future_ret < -threshold] = -1  # Down\n",
        "    label[(future_ret <= threshold) & (future_ret >= -threshold)] = 0  # Neutral\n",
        "\n",
        "    # Drop NaNs\n",
        "    label = label.dropna()\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": label.index,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[label.index],\n",
        "        \"label\": label.values,\n",
        "        \"future_ret\": future_ret.loc[label.index],\n",
        "        \"volatility\": rolling_vol.loc[label.index]\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "print(labels_df[\"label\"].value_counts(normalize=True))\n",
        "labels_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "19e6572a-3700-4399-f712-01f0848e88d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (25370, 6)\n",
            "label\n",
            " 0.000000    0.532519\n",
            " 1.000000    0.244974\n",
            "-1.000000    0.217777\n",
            "-0.005652    0.000039\n",
            "-0.010207    0.000039\n",
            "               ...   \n",
            " 0.001342    0.000039\n",
            "-0.007730    0.000039\n",
            " 0.003572    0.000039\n",
            "-0.000854    0.000039\n",
            "-0.006713    0.000039\n",
            "Name: proportion, Length: 123, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime ticker       price     label  future_ret  volatility\n",
              "0 2022-09-15 13:30:00   AAPL  153.809998 -0.006306   -0.006306         NaN\n",
              "1 2022-09-15 14:30:00   AAPL  152.839996 -0.002486   -0.002486         NaN\n",
              "2 2022-09-15 15:30:00   AAPL  152.460007  0.009543    0.009543         NaN\n",
              "3 2022-09-15 16:30:00   AAPL  153.914993 -0.005652   -0.005652         NaN\n",
              "4 2022-09-15 17:30:00   AAPL  153.044998 -0.010207   -0.010207         NaN\n",
              "5 2022-09-15 18:30:00   AAPL  151.482895  0.005724    0.005724         NaN\n",
              "6 2022-09-15 19:30:00   AAPL  152.350006 -0.018969   -0.018969         NaN\n",
              "7 2022-09-16 13:30:00   AAPL  149.460007 -0.002141   -0.002141         NaN\n",
              "8 2022-09-16 14:30:00   AAPL  149.139999 -0.002496   -0.002496         NaN\n",
              "9 2022-09-16 15:30:00   AAPL  148.767807  0.003443    0.003443         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-427dce0d-266d-4478-907d-b3ca8f17f6ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>label</th>\n",
              "      <th>future_ret</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-15 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.809998</td>\n",
              "      <td>-0.006306</td>\n",
              "      <td>-0.006306</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-15 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.839996</td>\n",
              "      <td>-0.002486</td>\n",
              "      <td>-0.002486</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-15 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.460007</td>\n",
              "      <td>0.009543</td>\n",
              "      <td>0.009543</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-15 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.914993</td>\n",
              "      <td>-0.005652</td>\n",
              "      <td>-0.005652</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-15 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>153.044998</td>\n",
              "      <td>-0.010207</td>\n",
              "      <td>-0.010207</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-15 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>151.482895</td>\n",
              "      <td>0.005724</td>\n",
              "      <td>0.005724</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-15 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>152.350006</td>\n",
              "      <td>-0.018969</td>\n",
              "      <td>-0.018969</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-16 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>149.460007</td>\n",
              "      <td>-0.002141</td>\n",
              "      <td>-0.002141</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-09-16 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>149.139999</td>\n",
              "      <td>-0.002496</td>\n",
              "      <td>-0.002496</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-09-16 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>148.767807</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-427dce0d-266d-4478-907d-b3ca8f17f6ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-427dce0d-266d-4478-907d-b3ca8f17f6ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-427dce0d-266d-4478-907d-b3ca8f17f6ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1bf649b1-f489-4bbc-850f-928b010d6eac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bf649b1-f489-4bbc-850f-928b010d6eac')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1bf649b1-f489-4bbc-850f-928b010d6eac button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 25370,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-15 13:30:00\",\n        \"max\": \"2025-08-12 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-09-12 14:30:00\",\n          \"2024-03-21 19:30:00\",\n          \"2022-09-21 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SPY\",\n          \"QQQ\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 165.11083447929246,\n        \"min\": 11.14999008178711,\n        \"max\": 642.3200073242188,\n        \"num_unique_values\": 23045,\n        \"samples\": [\n          242.14999389648438,\n          191.10499572753906,\n          431.9898986816406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6797279165912652,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          0.007970851441836842,\n          0.0072432008287813265,\n          -0.01168479035640154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009395578829484894,\n        \"min\": -0.13022686951739132,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          -0.005606060362088802,\n          0.0012366833336945582,\n          0.0012739324415828206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005538061301030855,\n        \"min\": 0.0008907621389855575,\n        \"max\": 0.05414076773543391,\n        \"num_unique_values\": 25250,\n        \"samples\": [\n          0.018300016743778326,\n          0.005301061408171196,\n          0.001343384396674201\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "rieWxNf5Mp44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1H-ATXHjSK6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Features"
      ],
      "metadata": {
        "id": "_PxZH38IebtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & labels\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y distribution:\\n\", y.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "OERLO3TNed16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa60869b-b588-48ac-80aa-0947dd9aea03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25205, 26)\n",
            "y distribution:\n",
            " label\n",
            " 0.0    0.535013\n",
            " 1.0    0.246102\n",
            "-1.0    0.218885\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale"
      ],
      "metadata": {
        "id": "rpnDnFsiWa87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"label\", \"future_ret\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Label distribution in Train:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "4oxCtsXaSTrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6112046f-e2bb-460b-cfa0-533484bee7d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train: (17631, 26), Val: (3778, 26), Test: (3779, 26)\n",
            "Label distribution in Train: label\n",
            " 0.0    0.525665\n",
            " 1.0    0.251943\n",
            "-1.0    0.222392\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence making - For LSTM AND CNN"
      ],
      "metadata": {
        "id": "euQxLDkaWdBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 24  # last 24 hours to predict next hour\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "id": "mn5XIK9DWlAN",
        "outputId": "92510b42-674c-46de-d7df-436ac8e07683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (17607, 24, 26), Val seq: (3754, 24, 26), Test seq: (3755, 24, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 — label encoding + class weights\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# mapping: -1 -> 0 (down), 0 -> 1 (neutral), 1 -> 2 (up)\n",
        "label_map = { -1.0: 0, 0.0: 1, 1.0: 2 }\n",
        "\n",
        "# If your y_* are numpy arrays (seq labels), convert\n",
        "y_train_seq_mapped = np.vectorize(label_map.get)(y_train_seq)\n",
        "y_val_seq_mapped   = np.vectorize(label_map.get)(y_val_seq)\n",
        "y_test_seq_mapped  = np.vectorize(label_map.get)(y_test_seq)\n",
        "\n",
        "# one-hot for Keras\n",
        "y_train_cat = to_categorical(y_train_seq_mapped, num_classes=3)\n",
        "y_val_cat   = to_categorical(y_val_seq_mapped, num_classes=3)\n",
        "y_test_cat  = to_categorical(y_test_seq_mapped, num_classes=3)\n",
        "\n",
        "# compute class weights from training sequence labels\n",
        "classes = np.unique(y_train_seq_mapped)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_seq_mapped)\n",
        "class_weights_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "print(\"Train class distribution:\", np.bincount(y_train_seq_mapped) / len(y_train_seq_mapped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "918d5e84-dbec-4f09-c9b5-1fa5f01c357a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.5025601638504864), 1: np.float64(0.6336644353271431), 2: np.float64(1.322144627168281)}\n",
            "Train class distribution: [0.22184358 0.52604078 0.25211564]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1jUYMhA9cSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, BatchNormalization, Activation, Dropout, SpatialDropout1D,\n",
        "    GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Add, Multiply, Concatenate\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# try to use AdamW (TF nightly / TF >=2.11 has experimental AdamW); fallback to classic Adam\n",
        "try:\n",
        "    from tensorflow.keras.optimizers import experimental as exp_optimizers\n",
        "    AdamW = exp_optimizers.AdamW\n",
        "    use_adamw = True\n",
        "except Exception:\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    AdamW = None\n",
        "    use_adamw = False\n",
        "\n",
        "def se_block(x, reduction=8):\n",
        "    \"\"\"Squeeze-and-Excitation block.\"\"\"\n",
        "    channels = int(x.shape[-1])\n",
        "    se = GlobalAveragePooling1D()(x)\n",
        "    se = tf.keras.layers.Dense(channels // reduction, activation='relu', kernel_initializer='he_normal')(se)\n",
        "    se = tf.keras.layers.Dense(channels, activation='sigmoid', kernel_initializer='he_normal')(se)\n",
        "    se = tf.keras.layers.Reshape((1, channels))(se)\n",
        "    return Multiply()([x, se])\n",
        "\n",
        "def residual_block(x, filters, kernel_size, dropout_rate=0.2, weight_decay=1e-4):\n",
        "    shortcut = x\n",
        "    # projection if channels mismatch\n",
        "    if x.shape[-1] != filters:\n",
        "        shortcut = Conv1D(filters, kernel_size=1, padding='same',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          kernel_regularizer=l2(weight_decay))(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same',\n",
        "               kernel_initializer='he_normal',\n",
        "               kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # spatial dropout is preferable for time-series channels\n",
        "    x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "    x = Conv1D(filters, kernel_size=kernel_size, padding='same',\n",
        "               kernel_initializer='he_normal',\n",
        "               kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_cnn_enhanced(input_shape, n_classes=3, dropout_rate=0.25, weight_decay=1e-4):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # optionally normalize channels at input\n",
        "    x = BatchNormalization()(inp)\n",
        "\n",
        "    # initial conv\n",
        "    x = Conv1D(64, kernel_size=3, padding='same',\n",
        "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # residual blocks (reduce complexity growth if dataset small)\n",
        "    x = residual_block(x, 64, 3, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "    x = residual_block(x, 128, 5, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "    x = residual_block(x, 256, 3, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # attention\n",
        "    x = se_block(x, reduction=8)\n",
        "\n",
        "    # pooling combination\n",
        "    gap = GlobalAveragePooling1D()(x)\n",
        "    gmp = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([gap, gmp])  # combined representation\n",
        "\n",
        "    x = Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "\n",
        "    # optimizer: try AdamW if available, otherwise Adam with weight decay via L2 above\n",
        "    if use_adamw and AdamW is not None:\n",
        "        opt = AdamW(learning_rate=1e-3, weight_decay=1e-5)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Build model (example)\n",
        "cnn_model = build_cnn_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25, weight_decay=1e-4)\n",
        "cnn_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "2mDqNrx0SddA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fc07363-38f6-4c07-9605-391516eacaf9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │        \u001b[38;5;34m104\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_45 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m5,056\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_35       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ activation_35[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_36       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_36[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ activation_35[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_37       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ activation_37[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_38       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_4 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_38[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m82,048\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ activation_37[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_16 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_39       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_52 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ activation_39[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_40       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_5 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_40[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_53 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_51 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ activation_39[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_17 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_41       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_41[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m8,224\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m8,448\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_41[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_35       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_36       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_37       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ activation_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_38       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_4 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_39       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ activation_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_40       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d_5 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_41       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m676,427\u001b[0m (2.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">676,427</span> (2.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m673,687\u001b[0m (2.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">673,687</span> (2.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,740\u001b[0m (10.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,740</span> (10.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "-p_nIYgVcWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, Bidirectional, LSTM, GRU, Dense, Dropout,\n",
        "    LayerNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
        "    Concatenate, Attention\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_lstm_enhanced(input_shape, n_classes=3, dropout_rate=0.25):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = LayerNormalization()(inp)\n",
        "\n",
        "    # First BiLSTM layer\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Second BiGRU layer (faster and adds diversity in sequence modeling)\n",
        "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Self-Attention layer\n",
        "    attn_data = Attention()([x, x])\n",
        "    x = Concatenate()([x, attn_data])  # fuse original and attention output\n",
        "\n",
        "    # Pooling\n",
        "    x_avg = GlobalAveragePooling1D()(x)\n",
        "    x_max = GlobalMaxPooling1D()(x)\n",
        "    x = Concatenate()([x_avg, x_max])\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate model\n",
        "lstm_model = build_lstm_enhanced(input_shape=X_train_seq.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "id": "IYtsddwpfp1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "9a1eb00e-9ab4-4ae2-c9d7-2c68e150faa4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m26\u001b[0m)    │         \u001b[38;5;34m52\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m158,720\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_8[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m123,648\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_9[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_42          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_43          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,720</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m447,031\u001b[0m (1.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">447,031</span> (1.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "7FalnDi8fxYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---- Map labels safely to integers 0,1,2 ----\n",
        "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
        "# if y_train etc are pandas Series this is robust:\n",
        "y_train_tab = pd.Series(y_train).map(label_map).astype('int').to_numpy()\n",
        "y_val_tab   = pd.Series(y_val).map(label_map).astype('int').to_numpy()\n",
        "y_test_tab  = pd.Series(y_test).map(label_map).astype('int').to_numpy()\n",
        "\n",
        "# ---- Per-sample balanced weights (recommended for multiclass) ----\n",
        "sample_weight_train = compute_sample_weight('balanced', y_train_tab)\n",
        "# sample_weight_train is length n_train; pass it into .fit(..., sample_weight=...)\n",
        "\n",
        "# ---- Defensive: compute per-class counts (avoid division by zero) ----\n",
        "class_counts = np.bincount(y_train_tab, minlength=3)\n",
        "total = len(y_train_tab)\n",
        "n_classes = len(class_counts)\n",
        "per_class_scale = np.where(class_counts == 0, 0.0, total / (n_classes * class_counts))\n",
        "print(\"class_counts:\", class_counts, \"per_class_scale:\", per_class_scale)\n",
        "\n",
        "# If you prefer per-sample weights from per_class_scale:\n",
        "sample_weight_from_scale = np.array([per_class_scale[c] for c in y_train_tab])\n",
        "\n",
        "# ---- XGBoost classifier (multi-class) ----\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',    # multiclass probability output\n",
        "    num_class=3,                   # explicit number of classes (safe to include)\n",
        "    n_estimators=1000,             # set high + use early stopping\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    gamma=1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',            # 'gpu_hist' if you have GPU\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "EjSEPd16f61x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f060d84-ecc5-43f9-c40b-5dc08d1974f4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_counts: [3921 9268 4442] per_class_scale: [1.49885233 0.63411739 1.32305268]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "TKR7NlqVaq34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "cOvOaClz5nPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if supported\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile with lower LR initially for stability\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_cnn_full_model.keras',  # save full model, not just weights\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/cnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "9e51f149-8216-4167-93a3-a43ddfe2dd8c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.33763, saving model to best_cnn_full_model.keras\n",
            "138/138 - 57s - 411ms/step - accuracy: 0.5117 - loss: 1.5105 - val_accuracy: 0.5493 - val_loss: 1.3376 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.33763 to 1.32411, saving model to best_cnn_full_model.keras\n",
            "138/138 - 45s - 328ms/step - accuracy: 0.5260 - loss: 1.4473 - val_accuracy: 0.5493 - val_loss: 1.3241 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.32411 to 1.30621, saving model to best_cnn_full_model.keras\n",
            "138/138 - 83s - 598ms/step - accuracy: 0.5260 - loss: 1.4246 - val_accuracy: 0.5493 - val_loss: 1.3062 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 1.30621 to 1.30310, saving model to best_cnn_full_model.keras\n",
            "138/138 - 45s - 323ms/step - accuracy: 0.5269 - loss: 1.4097 - val_accuracy: 0.5493 - val_loss: 1.3031 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 1.30310 to 1.29405, saving model to best_cnn_full_model.keras\n",
            "138/138 - 83s - 605ms/step - accuracy: 0.5272 - loss: 1.3950 - val_accuracy: 0.5493 - val_loss: 1.2940 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 1.29405 to 1.28584, saving model to best_cnn_full_model.keras\n",
            "138/138 - 46s - 331ms/step - accuracy: 0.5266 - loss: 1.3797 - val_accuracy: 0.5506 - val_loss: 1.2858 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss improved from 1.28584 to 1.27368, saving model to best_cnn_full_model.keras\n",
            "138/138 - 82s - 591ms/step - accuracy: 0.5267 - loss: 1.3650 - val_accuracy: 0.5511 - val_loss: 1.2737 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 1.27368 to 1.25581, saving model to best_cnn_full_model.keras\n",
            "138/138 - 83s - 599ms/step - accuracy: 0.5307 - loss: 1.3479 - val_accuracy: 0.5514 - val_loss: 1.2558 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss improved from 1.25581 to 1.24719, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 590ms/step - accuracy: 0.5334 - loss: 1.3302 - val_accuracy: 0.5527 - val_loss: 1.2472 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss improved from 1.24719 to 1.23500, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 586ms/step - accuracy: 0.5330 - loss: 1.3169 - val_accuracy: 0.5578 - val_loss: 1.2350 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.23500\n",
            "138/138 - 48s - 346ms/step - accuracy: 0.5362 - loss: 1.3007 - val_accuracy: 0.5570 - val_loss: 1.2355 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 1.23500 to 1.23313, saving model to best_cnn_full_model.keras\n",
            "138/138 - 80s - 579ms/step - accuracy: 0.5427 - loss: 1.2811 - val_accuracy: 0.5541 - val_loss: 1.2331 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.23313\n",
            "138/138 - 46s - 336ms/step - accuracy: 0.5457 - loss: 1.2677 - val_accuracy: 0.5589 - val_loss: 1.2338 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss improved from 1.23313 to 1.22010, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 590ms/step - accuracy: 0.5471 - loss: 1.2546 - val_accuracy: 0.5471 - val_loss: 1.2201 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 1.22010\n",
            "138/138 - 81s - 590ms/step - accuracy: 0.5488 - loss: 1.2361 - val_accuracy: 0.5424 - val_loss: 1.2301 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.22010\n",
            "138/138 - 84s - 607ms/step - accuracy: 0.5613 - loss: 1.2145 - val_accuracy: 0.5586 - val_loss: 1.2206 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.22010\n",
            "138/138 - 80s - 577ms/step - accuracy: 0.5618 - loss: 1.1998 - val_accuracy: 0.5282 - val_loss: 1.2281 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss improved from 1.22010 to 1.21729, saving model to best_cnn_full_model.keras\n",
            "138/138 - 81s - 590ms/step - accuracy: 0.5686 - loss: 1.1840 - val_accuracy: 0.5178 - val_loss: 1.2173 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.21729\n",
            "138/138 - 83s - 603ms/step - accuracy: 0.5707 - loss: 1.1705 - val_accuracy: 0.5373 - val_loss: 1.2183 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.21729\n",
            "138/138 - 45s - 327ms/step - accuracy: 0.5791 - loss: 1.1514 - val_accuracy: 0.5519 - val_loss: 1.2380 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.21729\n",
            "138/138 - 84s - 606ms/step - accuracy: 0.5850 - loss: 1.1324 - val_accuracy: 0.5320 - val_loss: 1.2202 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 1.21729\n",
            "138/138 - 83s - 600ms/step - accuracy: 0.5895 - loss: 1.1139 - val_accuracy: 0.5352 - val_loss: 1.2312 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.21729\n",
            "138/138 - 81s - 583ms/step - accuracy: 0.6036 - loss: 1.0737 - val_accuracy: 0.5416 - val_loss: 1.2498 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.21729\n",
            "138/138 - 46s - 330ms/step - accuracy: 0.6134 - loss: 1.0540 - val_accuracy: 0.5298 - val_loss: 1.2604 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_loss did not improve from 1.21729\n",
            "138/138 - 81s - 585ms/step - accuracy: 0.6166 - loss: 1.0317 - val_accuracy: 0.5256 - val_loss: 1.2773 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 1.21729\n",
            "138/138 - 47s - 343ms/step - accuracy: 0.6265 - loss: 1.0188 - val_accuracy: 0.5192 - val_loss: 1.2729 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_loss did not improve from 1.21729\n",
            "138/138 - 79s - 572ms/step - accuracy: 0.6349 - loss: 0.9918 - val_accuracy: 0.5139 - val_loss: 1.2929 - learning_rate: 1.2500e-04\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_loss did not improve from 1.21729\n",
            "138/138 - 47s - 339ms/step - accuracy: 0.6444 - loss: 0.9736 - val_accuracy: 0.5096 - val_loss: 1.3156 - learning_rate: 1.2500e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 18.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yxu1niZ7gq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Enable mixed precision if GPU supports it (LSTMs benefit less than CNNs, but still good for speed)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Compile LSTM with gradient clipping (helps with exploding gradients in RNNs)\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rlr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "chk = ModelCheckpoint(\n",
        "    filepath='best_lstm_full_model.keras',  # Save entire model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# TensorBoard logging\n",
        "log_dir = \"logs/lstm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Training\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_seq, y_train_cat,\n",
        "    validation_data=(X_val_seq, y_val_cat),\n",
        "    epochs=120,  # Give it more room to converge\n",
        "    batch_size=96,  # Smaller batch size often helps LSTM generalization\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[es, rlr, chk, tb_callback],\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "566fba89-2295-4acd-dcab-6fe169f45dc1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.99749, saving model to best_lstm_full_model.keras\n",
            "184/184 - 52s - 280ms/step - accuracy: 0.5216 - loss: 1.1150 - val_accuracy: 0.5495 - val_loss: 0.9975 - learning_rate: 3.0000e-04\n",
            "Epoch 2/120\n",
            "\n",
            "Epoch 2: val_loss improved from 0.99749 to 0.99479, saving model to best_lstm_full_model.keras\n",
            "184/184 - 42s - 228ms/step - accuracy: 0.5262 - loss: 1.0887 - val_accuracy: 0.5479 - val_loss: 0.9948 - learning_rate: 3.0000e-04\n",
            "Epoch 3/120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.99479\n",
            "184/184 - 83s - 451ms/step - accuracy: 0.5266 - loss: 1.0800 - val_accuracy: 0.5509 - val_loss: 1.0005 - learning_rate: 3.0000e-04\n",
            "Epoch 4/120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.99479\n",
            "184/184 - 84s - 454ms/step - accuracy: 0.5280 - loss: 1.0736 - val_accuracy: 0.5490 - val_loss: 0.9997 - learning_rate: 3.0000e-04\n",
            "Epoch 5/120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.99479\n",
            "184/184 - 80s - 436ms/step - accuracy: 0.5294 - loss: 1.0666 - val_accuracy: 0.5503 - val_loss: 1.0105 - learning_rate: 3.0000e-04\n",
            "Epoch 6/120\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.99479\n",
            "184/184 - 45s - 242ms/step - accuracy: 0.5318 - loss: 1.0569 - val_accuracy: 0.5456 - val_loss: 1.0061 - learning_rate: 3.0000e-04\n",
            "Epoch 7/120\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.99479\n",
            "184/184 - 79s - 431ms/step - accuracy: 0.5388 - loss: 1.0398 - val_accuracy: 0.5501 - val_loss: 1.0032 - learning_rate: 1.5000e-04\n",
            "Epoch 8/120\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.99479\n",
            "184/184 - 46s - 248ms/step - accuracy: 0.5429 - loss: 1.0295 - val_accuracy: 0.5410 - val_loss: 1.0102 - learning_rate: 1.5000e-04\n",
            "Epoch 9/120\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.99479\n",
            "184/184 - 78s - 422ms/step - accuracy: 0.5481 - loss: 1.0217 - val_accuracy: 0.5397 - val_loss: 1.0076 - learning_rate: 1.5000e-04\n",
            "Epoch 10/120\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.99479\n",
            "184/184 - 42s - 226ms/step - accuracy: 0.5495 - loss: 1.0138 - val_accuracy: 0.5336 - val_loss: 1.0125 - learning_rate: 1.5000e-04\n",
            "Epoch 11/120\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.99479\n",
            "184/184 - 45s - 242ms/step - accuracy: 0.5528 - loss: 0.9982 - val_accuracy: 0.5269 - val_loss: 1.0155 - learning_rate: 7.5000e-05\n",
            "Epoch 12/120\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.99479\n",
            "184/184 - 79s - 428ms/step - accuracy: 0.5571 - loss: 0.9878 - val_accuracy: 0.5277 - val_loss: 1.0106 - learning_rate: 7.5000e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "2RHWbvELgyIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- ensure label mapping (same as before) ---\n",
        "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
        "y_train_tab = pd.Series(y_train).map(label_map).astype(int).to_numpy()\n",
        "y_val_tab   = pd.Series(y_val).map(label_map).astype(int).to_numpy()\n",
        "y_test_tab  = pd.Series(y_test).map(label_map).astype(int).to_numpy()\n",
        "\n",
        "# --- sample weights (multiclass) ---\n",
        "sw_train = compute_sample_weight(class_weight='balanced', y=y_train_tab)\n",
        "sw_val   = compute_sample_weight(class_weight='balanced', y=y_val_tab)\n",
        "\n",
        "# helper: robust predict that works across xgboost versions\n",
        "def predict_with_best(booster: xgb.Booster, dmatrix: xgb.DMatrix):\n",
        "    \"\"\"\n",
        "    Try several predict call styles in order:\n",
        "      1) predict(..., iteration_range=(0, best_iteration+1)) if best_iteration exists\n",
        "      2) predict(..., ntree_limit=best_ntree_limit) if supported\n",
        "      3) fallback: predict(dmatrix)\n",
        "    \"\"\"\n",
        "    # 1) iteration_range (newer interface)\n",
        "    try:\n",
        "        if hasattr(booster, \"best_iteration\") and booster.best_iteration is not None:\n",
        "            return booster.predict(dmatrix, iteration_range=(0, int(booster.best_iteration) + 1))\n",
        "    except TypeError:\n",
        "        # some versions may not accept iteration_range\n",
        "        pass\n",
        "    # 2) ntree_limit (older interface)\n",
        "    try:\n",
        "        if hasattr(booster, \"best_ntree_limit\") and booster.best_ntree_limit is not None:\n",
        "            return booster.predict(dmatrix, ntree_limit=int(booster.best_ntree_limit))\n",
        "    except TypeError:\n",
        "        pass\n",
        "    # 3) plain predict fallback\n",
        "    return booster.predict(dmatrix)\n",
        "\n",
        "# prepare DMatrix for validation & test once outside objective (weights included)\n",
        "dval = xgb.DMatrix(X_val, label=y_val_tab, weight=sw_val)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "# Optuna objective (robust)\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 3,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'hist',\n",
        "        'seed': 42,\n",
        "        'verbosity': 0,\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),\n",
        "    }\n",
        "\n",
        "    # create DMatrix for the training fold (weights applied)\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train_tab, weight=sw_train)\n",
        "\n",
        "    try:\n",
        "        bst = xgb.train(\n",
        "            params,\n",
        "            dtrain,\n",
        "            num_boost_round=1500,\n",
        "            evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "            early_stopping_rounds=50,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "        # robust predict\n",
        "        preds = predict_with_best(bst, dval)\n",
        "        pred_labels = np.argmax(preds, axis=1)\n",
        "        acc = accuracy_score(y_val_tab, pred_labels)\n",
        "        # store best_iteration (useful later)\n",
        "        trial.set_user_attr(\"best_iteration\", getattr(bst, \"best_iteration\", None))\n",
        "        return acc\n",
        "\n",
        "    except Exception as e:\n",
        "        # Log a warning and return a very low score so Optuna can continue.\n",
        "        # Avoid letting the exception bubble and stop the entire study.\n",
        "        print(f\"[Optuna objective] caught exception during training/predict: {e!r}\")\n",
        "        return 0.0\n",
        "\n",
        "# run the study\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters:\", study.best_params)\n",
        "print(\"Best validation accuracy:\", study.best_value)\n",
        "print(\"Best trial attrs:\", study.best_trial.user_attrs)\n",
        "\n",
        "# Train final model on same train/val with best params\n",
        "best_params = study.best_params.copy()\n",
        "best_params.update({\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 3,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'hist',\n",
        "    'seed': 42,\n",
        "    'verbosity': 1\n",
        "})\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_tab, weight=sw_train)\n",
        "dval   = xgb.DMatrix(X_val, label=y_val_tab, weight=sw_val)\n",
        "final_model = xgb.train(\n",
        "    best_params,\n",
        "    dtrain,\n",
        "    num_boost_round=3000,\n",
        "    evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")\n",
        "# -------------------------\n",
        "# Save & evaluate (fixed, saving to xgb_model.pkl)\n",
        "# -------------------------\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Defensive check\n",
        "if 'final_model' not in globals():\n",
        "    raise RuntimeError(\"final_model not found. Make sure xgb.train(...) completed and produced final_model.\")\n",
        "\n",
        "# 1) Save the trained Booster\n",
        "# (a) JSON copy — reliable XGBoost-native format\n",
        "final_model.save_model(\"xgb_model.json\")\n",
        "\n",
        "# (b) Pickle via joblib so filename is xgb_model.pkl as requested\n",
        "# joblib will serialize the Booster object; this is convenient for later joblib.load()\n",
        "joblib.dump(final_model, \"xgb_model.pkl\")\n",
        "\n",
        "# 2) How to reload later (examples)\n",
        "# loaded_bst = joblib.load(\"xgb_model.pkl\")\n",
        "# OR\n",
        "# loaded_bst = xgb.Booster()\n",
        "# loaded_bst.load_model(\"xgb_model.json\")\n",
        "\n",
        "# 3) Evaluate on test set using the robust predict helper\n",
        "y_prob = predict_with_best(final_model, dtest)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"Final Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c5c651d81ed841839ccbb42bc69c920c",
            "d5652d98c51343b3a5e8b50007394056",
            "d43b59df62fa470fa75b6eea7545d158",
            "0a821285a2bb4576ac75c27df427b56d",
            "0440fe06a82c4f46a9420268830b6491",
            "73db2e57dc864a4dbf1b1d9ec8da4c10",
            "5817d06dad5f41dc838eda0d02db087f",
            "c72d8109287b45c5b3db343a7ee29ed8",
            "d9cae7d27fe84fb2aad5e87396dd8643",
            "4e2a8b28d9904794ba7b91838c0d86e1",
            "4c64358960114bd78d576daf3a464f84"
          ]
        },
        "id": "lOUy9Yd0g-6E",
        "outputId": "b47ad8c2-7f4d-44d5-923c-1322cc3e3b46"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 01:06:55,894] A new study created in memory with name: no-name-4eb7b8e5-8ba7-4275-a767-c3a48dee0304\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c651d81ed841839ccbb42bc69c920c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-08-13 01:06:57,192] Trial 0 finished with value: 0.47697194282689254 and parameters: {'max_depth': 5, 'learning_rate': 0.2536999076681772, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'gamma': 0.7800932022121826, 'min_child_weight': 2, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 2.665440364437338}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:00,138] Trial 1 finished with value: 0.46823716251985176 and parameters: {'max_depth': 7, 'learning_rate': 0.11114989443094977, 'subsample': 0.608233797718321, 'colsample_bytree': 0.9879639408647978, 'gamma': 4.162213204002109, 'min_child_weight': 3, 'reg_alpha': 0.18182496720710062, 'reg_lambda': 0.9585112746335845}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:02,045] Trial 2 finished with value: 0.4745897300158814 and parameters: {'max_depth': 5, 'learning_rate': 0.05958389350068958, 'subsample': 0.7727780074568463, 'colsample_bytree': 0.7164916560792167, 'gamma': 3.0592644736118975, 'min_child_weight': 2, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 1.4159046082342293}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:03,260] Trial 3 finished with value: 0.4722075172048703 and parameters: {'max_depth': 6, 'learning_rate': 0.14447746112718687, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'gamma': 2.9620728443102124, 'min_child_weight': 1, 'reg_alpha': 0.6075448519014384, 'reg_lambda': 0.9263103092182288}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:04,034] Trial 4 finished with value: 0.4737956590788777 and parameters: {'max_depth': 3, 'learning_rate': 0.2521267904777921, 'subsample': 0.9862528132298237, 'colsample_bytree': 0.9233589392465844, 'gamma': 1.5230688458668533, 'min_child_weight': 1, 'reg_alpha': 0.6842330265121569, 'reg_lambda': 1.6003812343490034}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:05,980] Trial 5 finished with value: 0.47511911064055057 and parameters: {'max_depth': 3, 'learning_rate': 0.05388108577817234, 'subsample': 0.6137554084460873, 'colsample_bytree': 0.9637281608315128, 'gamma': 1.2938999080000846, 'min_child_weight': 7, 'reg_alpha': 0.31171107608941095, 'reg_lambda': 1.800170052944527}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:12,995] Trial 6 finished with value: 0.4756484912652197 and parameters: {'max_depth': 7, 'learning_rate': 0.01875220945578641, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'gamma': 4.697494707820946, 'min_child_weight': 9, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 2.804685587557792}. Best is trial 0 with value: 0.47697194282689254.\n",
            "[I 2025-08-13 01:07:17,636] Trial 7 finished with value: 0.4782953943885654 and parameters: {'max_depth': 3, 'learning_rate': 0.01947558230629543, 'subsample': 0.6180909155642152, 'colsample_bytree': 0.7301321323053057, 'gamma': 1.9433864484474102, 'min_child_weight': 3, 'reg_alpha': 0.8287375091519293, 'reg_lambda': 1.3918833167339733}. Best is trial 7 with value: 0.4782953943885654.\n",
            "[I 2025-08-13 01:07:19,503] Trial 8 finished with value: 0.47750132345156165 and parameters: {'max_depth': 5, 'learning_rate': 0.06333268775321842, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'gamma': 0.3727532183988541, 'min_child_weight': 10, 'reg_alpha': 0.7722447692966574, 'reg_lambda': 0.996789203835431}. Best is trial 7 with value: 0.4782953943885654.\n",
            "[I 2025-08-13 01:07:21,445] Trial 9 finished with value: 0.47750132345156165 and parameters: {'max_depth': 3, 'learning_rate': 0.1601531217136121, 'subsample': 0.8827429375390468, 'colsample_bytree': 0.8916028672163949, 'gamma': 3.8563517334297286, 'min_child_weight': 1, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 0.7896726488128243}. Best is trial 7 with value: 0.4782953943885654.\n",
            "[I 2025-08-13 01:07:38,723] Trial 10 finished with value: 0.4814716781365802 and parameters: {'max_depth': 10, 'learning_rate': 0.010206070557576998, 'subsample': 0.747491509088439, 'colsample_bytree': 0.6071847502459278, 'gamma': 2.102020040921987, 'min_child_weight': 5, 'reg_alpha': 0.9709367151705007, 'reg_lambda': 2.191430949356949}. Best is trial 10 with value: 0.4814716781365802.\n",
            "[I 2025-08-13 01:07:54,672] Trial 11 finished with value: 0.48279512969825306 and parameters: {'max_depth': 10, 'learning_rate': 0.010124083959432524, 'subsample': 0.7553822144513154, 'colsample_bytree': 0.6046395533640769, 'gamma': 2.168721058294291, 'min_child_weight': 5, 'reg_alpha': 0.9934674559812277, 'reg_lambda': 2.2027505240094962}. Best is trial 11 with value: 0.48279512969825306.\n",
            "[I 2025-08-13 01:08:10,342] Trial 12 finished with value: 0.4838538909475913 and parameters: {'max_depth': 10, 'learning_rate': 0.010142157257086108, 'subsample': 0.7604603292118235, 'colsample_bytree': 0.6014301271458979, 'gamma': 2.2830838274909495, 'min_child_weight': 5, 'reg_alpha': 0.9971747820340642, 'reg_lambda': 2.255858711359755}. Best is trial 12 with value: 0.4838538909475913.\n",
            "[I 2025-08-13 01:08:26,971] Trial 13 finished with value: 0.4737956590788777 and parameters: {'max_depth': 10, 'learning_rate': 0.011210124205357169, 'subsample': 0.7207614418914601, 'colsample_bytree': 0.6038855939114581, 'gamma': 2.5711146158659437, 'min_child_weight': 6, 'reg_alpha': 0.999362438641551, 'reg_lambda': 2.3185553872001456}. Best is trial 12 with value: 0.4838538909475913.\n",
            "[I 2025-08-13 01:08:33,550] Trial 14 finished with value: 0.4788247750132345 and parameters: {'max_depth': 9, 'learning_rate': 0.02270740862049956, 'subsample': 0.8384595656112799, 'colsample_bytree': 0.6638123593227387, 'gamma': 3.416273349823686, 'min_child_weight': 4, 'reg_alpha': 0.8649362061194023, 'reg_lambda': 2.0525731400418845}. Best is trial 12 with value: 0.4838538909475913.\n",
            "[I 2025-08-13 01:08:42,139] Trial 15 finished with value: 0.47961884595023824 and parameters: {'max_depth': 9, 'learning_rate': 0.026839081288625163, 'subsample': 0.8137520243406074, 'colsample_bytree': 0.6732985810657727, 'gamma': 2.361609808336007, 'min_child_weight': 7, 'reg_alpha': 0.4554270882387035, 'reg_lambda': 2.486613410280222}. Best is trial 12 with value: 0.4838538909475913.\n",
            "[I 2025-08-13 01:08:46,645] Trial 16 finished with value: 0.4764425622022234 and parameters: {'max_depth': 8, 'learning_rate': 0.03505111636819011, 'subsample': 0.706761500830221, 'colsample_bytree': 0.6509463935629054, 'gamma': 1.377220617160712, 'min_child_weight': 5, 'reg_alpha': 0.9055199851982583, 'reg_lambda': 1.9273071675785682}. Best is trial 12 with value: 0.4838538909475913.\n",
            "[I 2025-08-13 01:09:00,248] Trial 17 finished with value: 0.4896770778189518 and parameters: {'max_depth': 9, 'learning_rate': 0.014036226945368472, 'subsample': 0.7911302960155628, 'colsample_bytree': 0.7263229711478186, 'gamma': 0.02290192738033303, 'min_child_weight': 7, 'reg_alpha': 0.7327943400345108, 'reg_lambda': 2.9182639345790107}. Best is trial 17 with value: 0.4896770778189518.\n",
            "[I 2025-08-13 01:09:14,262] Trial 18 finished with value: 0.4886183165696136 and parameters: {'max_depth': 9, 'learning_rate': 0.015096379125206144, 'subsample': 0.8598045624984104, 'colsample_bytree': 0.7277742014225941, 'gamma': 0.18614582398396953, 'min_child_weight': 8, 'reg_alpha': 0.7374412369696406, 'reg_lambda': 2.988317611911389}. Best is trial 17 with value: 0.4896770778189518.\n",
            "[I 2025-08-13 01:09:26,581] Trial 19 finished with value: 0.490206458443621 and parameters: {'max_depth': 8, 'learning_rate': 0.01538828552359355, 'subsample': 0.9128814994878451, 'colsample_bytree': 0.7426815878832285, 'gamma': 0.047851119246915215, 'min_child_weight': 8, 'reg_alpha': 0.7255429663622144, 'reg_lambda': 2.9012482795864276}. Best is trial 19 with value: 0.490206458443621.\n",
            "[I 2025-08-13 01:09:33,230] Trial 20 finished with value: 0.4841185812599259 and parameters: {'max_depth': 8, 'learning_rate': 0.03700131623976115, 'subsample': 0.9298528902087924, 'colsample_bytree': 0.7721247604455055, 'gamma': 0.7661030847241814, 'min_child_weight': 8, 'reg_alpha': 0.5138811575365112, 'reg_lambda': 2.9682404862859495}. Best is trial 19 with value: 0.490206458443621.\n",
            "[I 2025-08-13 01:09:43,962] Trial 21 finished with value: 0.49047114875595554 and parameters: {'max_depth': 8, 'learning_rate': 0.016944349093945633, 'subsample': 0.853633472512693, 'colsample_bytree': 0.7443536424882302, 'gamma': 0.07759348851321876, 'min_child_weight': 8, 'reg_alpha': 0.7395117640990748, 'reg_lambda': 2.978064271165839}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:09:54,984] Trial 22 finished with value: 0.4825304393859185 and parameters: {'max_depth': 8, 'learning_rate': 0.01566550123851403, 'subsample': 0.9415170569816177, 'colsample_bytree': 0.7571471235932935, 'gamma': 0.05501244939351768, 'min_child_weight': 9, 'reg_alpha': 0.6599318836634941, 'reg_lambda': 2.6342811460951503}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:08,055] Trial 23 finished with value: 0.48438327157226047 and parameters: {'max_depth': 8, 'learning_rate': 0.013883253845636089, 'subsample': 0.8178990139662861, 'colsample_bytree': 0.8251323334561256, 'gamma': 0.6428426576570361, 'min_child_weight': 7, 'reg_alpha': 0.7626270254020855, 'reg_lambda': 2.781999041317182}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:12,618] Trial 24 finished with value: 0.4822657490735839 and parameters: {'max_depth': 7, 'learning_rate': 0.029440816394297086, 'subsample': 0.9218257869943705, 'colsample_bytree': 0.6986076867522688, 'gamma': 0.9984643416692361, 'min_child_weight': 8, 'reg_alpha': 0.5166527572516011, 'reg_lambda': 2.482099846520332}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:19,737] Trial 25 finished with value: 0.4833245103229222 and parameters: {'max_depth': 9, 'learning_rate': 0.040383700461943804, 'subsample': 0.8586530215063506, 'colsample_bytree': 0.7678881540338195, 'gamma': 0.02209472339181573, 'min_child_weight': 10, 'reg_alpha': 0.8180714818214876, 'reg_lambda': 2.998533735219213}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:24,647] Trial 26 finished with value: 0.4833245103229222 and parameters: {'max_depth': 6, 'learning_rate': 0.021539178568864264, 'subsample': 0.7916977101076282, 'colsample_bytree': 0.8569070493304348, 'gamma': 0.6139560150289818, 'min_child_weight': 6, 'reg_alpha': 0.6713773387310168, 'reg_lambda': 2.5216373773163494}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:36,153] Trial 27 finished with value: 0.4857067231339333 and parameters: {'max_depth': 8, 'learning_rate': 0.013572474253263982, 'subsample': 0.8996117736107982, 'colsample_bytree': 0.7906874156973069, 'gamma': 0.37997723137572714, 'min_child_weight': 9, 'reg_alpha': 0.5689091703506945, 'reg_lambda': 0.5459503480307788}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:45,191] Trial 28 finished with value: 0.4822657490735839 and parameters: {'max_depth': 9, 'learning_rate': 0.02581741992296186, 'subsample': 0.956757593754592, 'colsample_bytree': 0.6937782739376043, 'gamma': 1.091706621396947, 'min_child_weight': 7, 'reg_alpha': 0.8974034132400962, 'reg_lambda': 2.802031163715731}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:53,023] Trial 29 finished with value: 0.4841185812599259 and parameters: {'max_depth': 7, 'learning_rate': 0.017514166459101324, 'subsample': 0.8733872027780099, 'colsample_bytree': 0.7458057682144082, 'gamma': 0.4876108554234181, 'min_child_weight': 8, 'reg_alpha': 0.4404864654592384, 'reg_lambda': 2.6763940599526843}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:10:57,076] Trial 30 finished with value: 0.47511911064055057 and parameters: {'max_depth': 6, 'learning_rate': 0.07948693654773382, 'subsample': 0.8369531764323951, 'colsample_bytree': 0.8489817519564029, 'gamma': 1.571282550820353, 'min_child_weight': 6, 'reg_alpha': 0.042745180079641565, 'reg_lambda': 2.672806104063914}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:12,185] Trial 31 finished with value: 0.4886183165696136 and parameters: {'max_depth': 9, 'learning_rate': 0.013939136609583196, 'subsample': 0.8609385551159641, 'colsample_bytree': 0.7310053826390877, 'gamma': 0.0191697917271874, 'min_child_weight': 8, 'reg_alpha': 0.731288758879108, 'reg_lambda': 2.978893493218181}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:28,167] Trial 32 finished with value: 0.48544203282159876 and parameters: {'max_depth': 9, 'learning_rate': 0.013263777824900184, 'subsample': 0.9019936367500315, 'colsample_bytree': 0.706765041956895, 'gamma': 0.27842639505702543, 'min_child_weight': 9, 'reg_alpha': 0.7305714180343958, 'reg_lambda': 2.8232536198651035}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:38,774] Trial 33 finished with value: 0.48544203282159876 and parameters: {'max_depth': 8, 'learning_rate': 0.0161251931900977, 'subsample': 0.8370935625192157, 'colsample_bytree': 0.7850146875683001, 'gamma': 0.987119404368065, 'min_child_weight': 8, 'reg_alpha': 0.7906699199730428, 'reg_lambda': 2.8860146307282286}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:46,038] Trial 34 finished with value: 0.4891476971942827 and parameters: {'max_depth': 7, 'learning_rate': 0.022873267897724727, 'subsample': 0.7874524022980323, 'colsample_bytree': 0.7357557606750271, 'gamma': 0.2617807609710083, 'min_child_weight': 7, 'reg_alpha': 0.15301797696764652, 'reg_lambda': 2.592204862473187}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:51,385] Trial 35 finished with value: 0.4809422975119111 and parameters: {'max_depth': 7, 'learning_rate': 0.02271744686280414, 'subsample': 0.7873225848132586, 'colsample_bytree': 0.8162677862607134, 'gamma': 0.8511717345445047, 'min_child_weight': 7, 'reg_alpha': 0.1293608843184022, 'reg_lambda': 2.4143685429890147}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:53,644] Trial 36 finished with value: 0.47908946532556906 and parameters: {'max_depth': 5, 'learning_rate': 0.046160407568812546, 'subsample': 0.7283734051483381, 'colsample_bytree': 0.6387722871777997, 'gamma': 1.7899652040845706, 'min_child_weight': 6, 'reg_alpha': 0.19872722167220724, 'reg_lambda': 2.6245572870846448}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:11:59,658] Trial 37 finished with value: 0.48279512969825306 and parameters: {'max_depth': 7, 'learning_rate': 0.03287843462938853, 'subsample': 0.8072016538304894, 'colsample_bytree': 0.7478121388868729, 'gamma': 0.48411554685583, 'min_child_weight': 7, 'reg_alpha': 0.6364629264101, 'reg_lambda': 2.734039754941839}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:12:07,150] Trial 38 finished with value: 0.4788247750132345 and parameters: {'max_depth': 6, 'learning_rate': 0.012222805287636015, 'subsample': 0.779202810607227, 'colsample_bytree': 0.6824184471396766, 'gamma': 0.27207126716220187, 'min_child_weight': 9, 'reg_alpha': 0.24118252946788354, 'reg_lambda': 2.5464382801407455}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:12:13,340] Trial 39 finished with value: 0.47776601376389627 and parameters: {'max_depth': 8, 'learning_rate': 0.020612252827462218, 'subsample': 0.9554897164546702, 'colsample_bytree': 0.7948682658621955, 'gamma': 4.899226356996808, 'min_child_weight': 10, 'reg_alpha': 0.378346174802619, 'reg_lambda': 1.5239455645878874}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:12:20,505] Trial 40 finished with value: 0.4788247750132345 and parameters: {'max_depth': 7, 'learning_rate': 0.017417396290151453, 'subsample': 0.9994563730237144, 'colsample_bytree': 0.7180955889038535, 'gamma': 1.2136099739924562, 'min_child_weight': 4, 'reg_alpha': 0.10617411293848456, 'reg_lambda': 1.2618953812120433}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:12:36,228] Trial 41 finished with value: 0.48941238750661725 and parameters: {'max_depth': 9, 'learning_rate': 0.015513672919380295, 'subsample': 0.8458112456406391, 'colsample_bytree': 0.743200568196944, 'gamma': 0.26174683284229167, 'min_child_weight': 8, 'reg_alpha': 0.7240668864185215, 'reg_lambda': 2.881249962612403}. Best is trial 21 with value: 0.49047114875595554.\n",
            "[I 2025-08-13 01:12:44,998] Trial 42 finished with value: 0.4915299100052938 and parameters: {'max_depth': 8, 'learning_rate': 0.018759847536533078, 'subsample': 0.8280998427268167, 'colsample_bytree': 0.7423941190097567, 'gamma': 0.7120052581121009, 'min_child_weight': 7, 'reg_alpha': 0.572055083791061, 'reg_lambda': 2.859458166901022}. Best is trial 42 with value: 0.4915299100052938.\n",
            "[I 2025-08-13 01:12:54,432] Trial 43 finished with value: 0.49444150344097404 and parameters: {'max_depth': 8, 'learning_rate': 0.0182014870849285, 'subsample': 0.8218430665716767, 'colsample_bytree': 0.7628150155615464, 'gamma': 0.7186090872199041, 'min_child_weight': 8, 'reg_alpha': 0.5786050151231169, 'reg_lambda': 2.9006322365170183}. Best is trial 43 with value: 0.49444150344097404.\n",
            "[I 2025-08-13 01:13:03,311] Trial 44 finished with value: 0.4875595553202753 and parameters: {'max_depth': 8, 'learning_rate': 0.01910579071946243, 'subsample': 0.8868429246151318, 'colsample_bytree': 0.7740072974660847, 'gamma': 0.7500224036897607, 'min_child_weight': 9, 'reg_alpha': 0.6081164923668135, 'reg_lambda': 2.864966214165739}. Best is trial 43 with value: 0.49444150344097404.\n",
            "[I 2025-08-13 01:13:16,201] Trial 45 finished with value: 0.4830598200105876 and parameters: {'max_depth': 8, 'learning_rate': 0.011846171693001608, 'subsample': 0.9153748135339936, 'colsample_bytree': 0.713141042066672, 'gamma': 0.569660698476246, 'min_child_weight': 7, 'reg_alpha': 0.5655166465587148, 'reg_lambda': 2.3872630497571325}. Best is trial 43 with value: 0.49444150344097404.\n",
            "[I 2025-08-13 01:13:19,457] Trial 46 finished with value: 0.4859714134462679 and parameters: {'max_depth': 10, 'learning_rate': 0.10074805617320592, 'subsample': 0.8265687778860804, 'colsample_bytree': 0.8051585200717429, 'gamma': 1.5674622972646617, 'min_child_weight': 6, 'reg_alpha': 0.6796134552611981, 'reg_lambda': 2.711867033191864}. Best is trial 43 with value: 0.49444150344097404.\n",
            "[I 2025-08-13 01:13:22,984] Trial 47 finished with value: 0.4793541556379037 and parameters: {'max_depth': 4, 'learning_rate': 0.027492522369625294, 'subsample': 0.765171661161022, 'colsample_bytree': 0.9724631470429347, 'gamma': 0.8982823644800946, 'min_child_weight': 8, 'reg_alpha': 0.5675084812189415, 'reg_lambda': 2.8917780193542266}. Best is trial 43 with value: 0.49444150344097404.\n",
            "[I 2025-08-13 01:13:25,308] Trial 48 finished with value: 0.4764425622022234 and parameters: {'max_depth': 8, 'learning_rate': 0.1898950890810116, 'subsample': 0.8076242389161387, 'colsample_bytree': 0.7570625813011633, 'gamma': 4.148033335239529, 'min_child_weight': 9, 'reg_alpha': 0.4739955104122035, 'reg_lambda': 2.761140268239364}. Best is trial 43 with value: 0.49444150344097404.\n",
            "[I 2025-08-13 01:13:32,969] Trial 49 finished with value: 0.4830598200105876 and parameters: {'max_depth': 9, 'learning_rate': 0.01819077695359325, 'subsample': 0.7402696433570358, 'colsample_bytree': 0.8696729696537576, 'gamma': 2.758455194199963, 'min_child_weight': 7, 'reg_alpha': 0.6294539620382192, 'reg_lambda': 2.097151663989036}. Best is trial 43 with value: 0.49444150344097404.\n",
            "\n",
            "Best parameters: {'max_depth': 8, 'learning_rate': 0.0182014870849285, 'subsample': 0.8218430665716767, 'colsample_bytree': 0.7628150155615464, 'gamma': 0.7186090872199041, 'min_child_weight': 8, 'reg_alpha': 0.5786050151231169, 'reg_lambda': 2.9006322365170183}\n",
            "Best validation accuracy: 0.49444150344097404\n",
            "Best trial attrs: {'best_iteration': 121}\n",
            "[0]\ttrain-mlogloss:1.09624\teval-mlogloss:1.09770\n",
            "[50]\ttrain-mlogloss:1.00551\teval-mlogloss:1.07346\n",
            "[100]\ttrain-mlogloss:0.94412\teval-mlogloss:1.06819\n",
            "[150]\ttrain-mlogloss:0.89651\teval-mlogloss:1.06839\n",
            "[171]\ttrain-mlogloss:0.88049\teval-mlogloss:1.06901\n",
            "Final Test Accuracy: 0.5363852871129928\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.24      0.25       756\n",
            "           1       0.66      0.75      0.70      2133\n",
            "           2       0.35      0.27      0.31       890\n",
            "\n",
            "    accuracy                           0.54      3779\n",
            "   macro avg       0.43      0.42      0.42      3779\n",
            "weighted avg       0.51      0.54      0.52      3779\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 179  385  192]\n",
            " [ 274 1604  255]\n",
            " [ 198  448  244]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O-O-F Predictions"
      ],
      "metadata": {
        "id": "Di2jwJEwhUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ==== Combine your split data back into one dataset ====\n",
        "X_tab = np.vstack([X_train, X_val, X_test])\n",
        "y_tab = np.concatenate([y_train, y_val, y_test])\n",
        "y_tab = pd.Series(y_tab)  # needed for .map()\n",
        "\n",
        "# ==== Time series split config ====\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# ==== Label remap (-1, 0, 1) -> (0, 1, 2) ====\n",
        "label_map = {-1: 0, 0: 1, 1: 2}\n",
        "\n",
        "# ==== One-hot encoder for DL models ====\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "y_all_mapped = y_tab.map(label_map)\n",
        "y_all_oh = enc.fit_transform(y_all_mapped.values.reshape(-1, 1))\n",
        "\n",
        "# ==== Storage for OOF predictions ====\n",
        "oof_cnn = np.zeros((len(X_tab), 3))\n",
        "oof_lstm = np.zeros((len(X_tab), 3))\n",
        "oof_xgb = np.zeros((len(X_tab), 3))\n",
        "\n",
        "# ==== Ensure tabular and sequence data match in length ====\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_all_mapped))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_all_mapped_aligned = y_all_mapped.iloc[:min_len]\n",
        "y_all_oh_aligned = y_all_oh[:min_len]\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_all_mapped_aligned.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BstRtL0ehVta",
        "outputId": "caa43c50-e66d-4f51-e93e-63a1f69407cc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(17607, 26), seq=(17607, 24, 26), y=(17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: create aligned copies (recommended, non-destructive)\n",
        "import numpy as np\n",
        "\n",
        "# require oof_idx_xgb exists\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found; re-run XGB OOF generation which should set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "# create aligned versions of CNN/LSTM that match oof_xgb's rows\n",
        "oof_cnn_aligned = np.asarray(oof_cnn)[idx]\n",
        "oof_lstm_aligned = np.asarray(oof_lstm)[idx]\n",
        "oof_xgb_aligned = np.asarray(oof_xgb)  # already aligned to idx\n",
        "\n",
        "print(\"Aligned shapes:\")\n",
        "print(\" oof_cnn_aligned:\", oof_cnn_aligned.shape)\n",
        "print(\" oof_lstm_aligned:\", oof_lstm_aligned.shape)\n",
        "print(\" oof_xgb_aligned:\", oof_xgb_aligned.shape)\n",
        "\n",
        "# Keep originals for debugging; set globals for convenience\n",
        "globals()['oof_cnn_aligned'] = oof_cnn_aligned\n",
        "globals()['oof_lstm_aligned'] = oof_lstm_aligned\n",
        "globals()['oof_xgb_aligned'] = oof_xgb_aligned\n",
        "\n",
        "# If later code expects oof_cnn/oof_lstm to be same length as oof_xgb, use these aligned ones.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdfTKCaeTHcX",
        "outputId": "0293dc4a-91d1-4520-b6ec-999151977e47"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned shapes:\n",
            " oof_cnn_aligned: (17607, 3)\n",
            " oof_lstm_aligned: (17607, 3)\n",
            " oof_xgb_aligned: (17607, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    cnn_model = build_cnn_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3NN2CkhDvJ",
        "outputId": "cb027835-0a5d-4151-f91b-8a9cbe7b1113"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating CNN OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq[train_idx], X_train_seq[val_idx]\n",
        "    y_seq_tr_oh, y_seq_va_oh = y_all_oh[train_idx], y_all_oh[val_idx]\n",
        "\n",
        "    # Build + compile\n",
        "    lstm_model = build_lstm_enhanced(input_shape=X_seq_tr.shape[1:], n_classes=3, dropout_rate=0.25)\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr_oh, validation_data=(X_seq_va, y_seq_va_oh),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUIXAYdhGJ4",
        "outputId": "35e6ba8c-177e-40d3-e27c-c8ddf1ea0d70"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating LSTM OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "\n",
        "    # Tabular split\n",
        "    X_tr_tab, X_va_tab = X_tab_aligned[train_idx], X_tab_aligned[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_all_mapped_aligned.iloc[train_idx], y_all_mapped_aligned.iloc[val_idx]\n",
        "\n",
        "    # Build with best parameters\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        num_class=3,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.0182014870849285,\n",
        "        subsample=0.8218430665716767,\n",
        "        colsample_bytree=0.7628150155615464,\n",
        "        gamma=0.7186090872199041,\n",
        "        min_child_weight=8,\n",
        "        reg_alpha=0.5856294446650139,\n",
        "        reg_lambda=2.9006322365170183,\n",
        "        n_estimators=300,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_clf.fit(X_tr_tab, y_tr_tab)\n",
        "\n",
        "    # Predict\n",
        "    oof_xgb[val_idx] = xgb_clf.predict_proba(X_va_tab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlbAkv81hL4f",
        "outputId": "8d4f1091-369f-4a8c-a385-2efa2e2dac41"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating XGB OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: create aligned copies (non-destructive)\n",
        "import numpy as np\n",
        "\n",
        "# require index mapping produced when generating XGB OOF\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found. Re-run the XGB OOF cell which should set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "n_full = oof_cnn.shape[0]\n",
        "if idx.min() < 0 or idx.max() >= n_full:\n",
        "    raise RuntimeError(f\"oof_idx_xgb values out of range for full length {n_full}\")\n",
        "\n",
        "# create aligned versions\n",
        "oof_cnn_aligned = np.asarray(oof_cnn)[idx]\n",
        "oof_lstm_aligned = np.asarray(oof_lstm)[idx]\n",
        "oof_xgb_aligned = np.asarray(oof_xgb)   # already the right smaller length\n",
        "\n",
        "print(\"Aligned shapes:\")\n",
        "print(\" oof_cnn_aligned:\", oof_cnn_aligned.shape)\n",
        "print(\" oof_lstm_aligned:\", oof_lstm_aligned.shape)\n",
        "print(\" oof_xgb_aligned:\", oof_xgb_aligned.shape)\n",
        "\n",
        "# set globals (convenience)\n",
        "globals()['oof_cnn_aligned'] = oof_cnn_aligned\n",
        "globals()['oof_lstm_aligned'] = oof_lstm_aligned\n",
        "globals()['oof_xgb_aligned'] = oof_xgb_aligned\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oypZH8ABhQFk",
        "outputId": "2f5cc189-0100-491e-ed90-b6af9bcf503b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned shapes:\n",
            " oof_cnn_aligned: (17607, 3)\n",
            " oof_lstm_aligned: (17607, 3)\n",
            " oof_xgb_aligned: (17607, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# Save OOF predictions and labels\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_all_mapped.values\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5i8N1lJps85",
        "outputId": "0bf9e552-48b9-48be-bc73-2c56ddd99213"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 OOF predictions saved to oof_preds.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# META LEARNER"
      ],
      "metadata": {
        "id": "IhKOAKMNxrMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Replace np.hstack([oof_cnn, oof_lstm, oof_xgb]) with this ---\n",
        "import numpy as np\n",
        "\n",
        "# 1) Ensure the XGB index mapping exists\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found. Re-run XGB OOF generation to set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "\n",
        "# 2) Select aligned rows from CNN/LSTM using that mapping\n",
        "aligned_cnn = np.asarray(oof_cnn)[idx]\n",
        "aligned_lstm = np.asarray(oof_lstm)[idx]\n",
        "aligned_xgb = np.asarray(oof_xgb)  # already matches idx\n",
        "\n",
        "# 3) Sanity checks\n",
        "assert aligned_cnn.shape[0] == aligned_lstm.shape[0] == aligned_xgb.shape[0], \\\n",
        "       f\"Aligned shapes mismatch: cnn {aligned_cnn.shape} lstm {aligned_lstm.shape} xgb {aligned_xgb.shape}\"\n",
        "\n",
        "# 4) Build meta matrices (stacked probabilities)\n",
        "meta_X_train = np.hstack([aligned_cnn, aligned_lstm, aligned_xgb])  # shape: (N_aligned, 9)\n",
        "# Use the y that already matches XGB (you indicated y_all_mapped_aligned is length 17607)\n",
        "meta_y_train = np.asarray(y_all_mapped_aligned)\n",
        "\n",
        "print(\"meta_X_train shape:\", meta_X_train.shape)\n",
        "print(\"meta_y_train shape:\", meta_y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UY6W_zKg-fS",
        "outputId": "11e27db1-c394-4987-f2ea-b9457a670e1d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta_X_train shape: (17607, 9)\n",
            "meta_y_train shape: (17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: overwrite original oof_* so downstream code that expects the smaller length works\n",
        "oof_cnn = aligned_cnn\n",
        "oof_lstm = aligned_lstm\n",
        "oof_xgb = aligned_xgb\n",
        "globals().update({'oof_cnn': oof_cnn, 'oof_lstm': oof_lstm, 'oof_xgb': oof_xgb})\n"
      ],
      "metadata": {
        "id": "qdu9LhULVsE_"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — meta-features construction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model probabilities as features\n",
        "meta_probs = np.hstack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 9)\n",
        "\n",
        "# Add engineered meta-features derived from base model outputs:\n",
        "# - per-sample mean/std/max/min across base model probs\n",
        "# - disagreements (max prob - 2nd max prob) for confidence\n",
        "def meta_stats_from_probs(probs_block):\n",
        "    # probs_block shape (n, n_models * n_classes)\n",
        "    n_classes = 3\n",
        "    n_models = probs_block.shape[1] // n_classes\n",
        "    block = probs_block.reshape(len(probs_block), n_models, n_classes)\n",
        "    # per model best class prob and best class\n",
        "    best_probs = block.max(axis=2)                 # (n, n_models)\n",
        "    best_classes = block.argmax(axis=2)             # (n, n_models)\n",
        "    # statistics across models on best_probs\n",
        "    mean_best = best_probs.mean(axis=1)\n",
        "    std_best = best_probs.std(axis=1)\n",
        "    max_best = best_probs.max(axis=1)\n",
        "    min_best = best_probs.min(axis=1)\n",
        "    # disagreement: how many models agree with majority class\n",
        "    from scipy.stats import mode\n",
        "    mode_vals, mode_counts = mode(best_classes, axis=1)\n",
        "    agree_fraction = (mode_counts.ravel() / n_models)\n",
        "    # confidence gap: top prob - second top prob per model averaged\n",
        "    def gap_per_row(row_block):\n",
        "        # row_block shape (n_models, n_classes)\n",
        "        gaps = []\n",
        "        for m in range(row_block.shape[0]):\n",
        "            arr = np.sort(row_block[m])[::-1]\n",
        "            gaps.append(arr[0] - (arr[1] if arr.shape[0] > 1 else 0.0))\n",
        "        return np.mean(gaps)\n",
        "    gap = np.array([gap_per_row(row) for row in block])\n",
        "\n",
        "    stats = np.vstack([mean_best, std_best, max_best, min_best, agree_fraction, gap]).T\n",
        "    stats_cols = [\"mean_best_prob\", \"std_best_prob\", \"max_best_prob\", \"min_best_prob\", \"agree_frac\", \"avg_top_gap\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_probs(meta_probs)\n",
        "\n",
        "# Optionally add a few simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# For now, we'll build final meta_X from probs + stats\n",
        "meta_X = np.hstack([meta_probs, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_p{c}\" for c in range(3)] +\n",
        "    [f\"lstm_p{c}\" for c in range(3)] +\n",
        "    [f\"xgb_p{c}\" for c in range(3)] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F859Av3p0qf",
        "outputId": "d17e2294-58cb-4668-959d-51252a5e41d7"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta X shape: (17607, 15)\n",
            "Feature names: ['cnn_p0', 'cnn_p1', 'cnn_p2', 'lstm_p0', 'lstm_p1', 'lstm_p2', 'xgb_p0', 'xgb_p1', 'xgb_p2', 'mean_best_prob', 'std_best_prob', 'max_best_prob', 'min_best_prob', 'agree_frac', 'avg_top_gap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Train final meta-learner on aligned meta features (fix mismatch) ----------\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Use aligned meta arrays produced earlier\n",
        "if 'meta_X_train' in globals() and 'meta_y_train' in globals():\n",
        "    X_meta = np.asarray(meta_X_train)\n",
        "    y_meta = np.asarray(meta_y_train)\n",
        "else:\n",
        "    raise RuntimeError(\"Aligned meta arrays not found. Make sure meta_X_train and meta_y_train exist.\")\n",
        "\n",
        "print(\"Shapes before fit: X_meta:\", X_meta.shape, \"y_meta:\", y_meta.shape)\n",
        "\n",
        "# sanity\n",
        "if X_meta.shape[0] != y_meta.shape[0]:\n",
        "    raise ValueError(f\"Shape mismatch: X_meta rows {X_meta.shape[0]} != y_meta {y_meta.shape[0]}\")\n",
        "\n",
        "# compute balanced sample weights for the meta set\n",
        "sample_weight_meta = compute_sample_weight(class_weight=\"balanced\", y=y_meta)\n",
        "\n",
        "# build final model with the best hyperparameters found earlier (best_cfg)\n",
        "# make sure best_cfg exists; if not, you can hardcode the best config you printed\n",
        "try:\n",
        "    best_cfg  # noqa: F821\n",
        "except NameError:\n",
        "    # fallback: use the best config you printed: {'max_iter':200,'learning_rate':0.1,'max_depth':4}\n",
        "    best_cfg = {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
        "\n",
        "final_model = HistGradientBoostingClassifier(**best_cfg, early_stopping=True, random_state=42)\n",
        "final_model.fit(X_meta, y_meta, sample_weight=sample_weight_meta)\n",
        "\n",
        "# Save the trained meta model\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n",
        "print(\"Final meta_learner model trained and saved to meta_laerner.pkl\")\n",
        "\n",
        "# Quick train-set diagnostics\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
        "pred_train = final_model.predict(X_meta)\n",
        "print(\"Train balanced accuracy:\", balanced_accuracy_score(y_meta, pred_train))\n",
        "print(\"Train classification report:\\n\", classification_report(y_meta, pred_train, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJul1btp2JA",
        "outputId": "1468954a-8c2f-4f7f-e806-423d54fa07db"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes before fit: X_meta: (17607, 9) y_meta: (17607,)\n",
            "Final meta model trained and saved to meta_final_model.pkl\n",
            "Train balanced accuracy: 0.714867776296772\n",
            "Train classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4572    0.9190    0.6106      3915\n",
            "           1     0.8858    0.5571    0.6840      9255\n",
            "           2     0.7574    0.6685    0.7102      4437\n",
            "\n",
            "    accuracy                         0.6656     17607\n",
            "   macro avg     0.7001    0.7149    0.6683     17607\n",
            "weighted avg     0.7581    0.6656    0.6743     17607\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust: Load meta model (or ensemble object) and predict probabilities / classes\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from typing import Optional\n",
        "\n",
        "def load_and_predict(\n",
        "    model_path: str,\n",
        "    meta_X: np.ndarray,\n",
        "    y: Optional[np.ndarray] = None,\n",
        "    threshold: Optional[np.ndarray] = None,\n",
        "    label_map_back: Optional[dict] = None,  # e.g. {0:-1.0, 1:0.0, 2:1.0}\n",
        "    verbose: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a saved meta model (or a dict with 'meta_model' and optional 'calibrators'),\n",
        "    predicts probabilities and classes on meta_X, applies optional thresholding,\n",
        "    and returns (probs, preds, preds_mapped_if_label_map).\n",
        "    \"\"\"\n",
        "    assert isinstance(meta_X, np.ndarray), \"meta_X must be a numpy array\"\n",
        "    # load artifact\n",
        "    obj = joblib.load(model_path)\n",
        "    # object can be:\n",
        "    # - a fitted estimator with predict_proba\n",
        "    # - a dict: {'meta_model': estimator, 'calibrators': [cal1, cal2, ...]} or similar\n",
        "    if isinstance(obj, dict):\n",
        "        if verbose:\n",
        "            print(\"Loaded dict artifact with keys:\", list(obj.keys()))\n",
        "        meta_model = obj.get(\"meta_model\") or obj.get(\"model\") or obj.get(\"estimator\")\n",
        "        calibrators = obj.get(\"calibrators\", None)\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"Loaded estimator directly from\", model_path)\n",
        "        meta_model = obj\n",
        "        calibrators = None\n",
        "\n",
        "    if meta_model is None:\n",
        "        raise RuntimeError(\"No 'meta_model' found in artifact and artifact is not a direct estimator.\")\n",
        "\n",
        "    # Get probabilities\n",
        "    if calibrators:\n",
        "        if verbose:\n",
        "            print(\"Using calibrators to produce averaged probabilities (len calibrators):\", len(calibrators))\n",
        "        probs_list = []\n",
        "        for cal in calibrators:\n",
        "            # prefer calibrator.predict_proba if it's a calibrator, otherwise fall back\n",
        "            if hasattr(cal, \"predict_proba\"):\n",
        "                probs_list.append(cal.predict_proba(meta_X))\n",
        "            elif hasattr(cal, \"predict\"):\n",
        "                # if calibrator returns labels, convert to one-hot-ish fallback (not ideal)\n",
        "                preds = cal.predict(meta_X)\n",
        "                onehot = np.zeros((len(preds), np.max(preds)+1))\n",
        "                onehot[np.arange(len(preds)), preds] = 1.0\n",
        "                probs_list.append(onehot)\n",
        "            else:\n",
        "                raise RuntimeError(\"Calibrator does not support predict_proba or predict.\")\n",
        "        probs = np.mean(probs_list, axis=0)\n",
        "    else:\n",
        "        if not hasattr(meta_model, \"predict_proba\"):\n",
        "            raise RuntimeError(\"Loaded meta_model has no predict_proba method.\")\n",
        "        probs = meta_model.predict_proba(meta_X)\n",
        "\n",
        "    # Optional thresholding (vector of length n_classes or None)\n",
        "    if threshold is not None:\n",
        "        threshold = np.asarray(threshold)\n",
        "        if threshold.shape[0] != probs.shape[1]:\n",
        "            raise ValueError(\"threshold must have length equal to number of classes\")\n",
        "        # Score = prob - threshold, then pick argmax (falls back to argmax of prob if all below)\n",
        "        scores = probs - threshold.reshape((1, -1))\n",
        "        preds = np.argmax(scores, axis=1)\n",
        "    else:\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Map back to original labels if requested\n",
        "    preds_mapped = None\n",
        "    if label_map_back is not None:\n",
        "        # label_map_back maps internal ints -> original labels\n",
        "        preds_mapped = np.array([label_map_back[int(p)] for p in preds])\n",
        "\n",
        "    # Diagnostics if ground-truth y provided\n",
        "    if y is not None:\n",
        "        if len(y) != len(preds):\n",
        "            raise ValueError(f\"Length mismatch: y ({len(y)}) vs preds ({len(preds)})\")\n",
        "        acc = accuracy_score(y, preds)\n",
        "        f1m = f1_score(y, preds, average=\"macro\", zero_division=0)\n",
        "        if verbose:\n",
        "            print(f\"Accuracy: {acc:.4f}   F1_macro: {f1m:.4f}\")\n",
        "            print(classification_report(y, preds, digits=4))\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"No ground-truth y provided; returning predictions only.\")\n",
        "\n",
        "    return probs, preds, preds_mapped\n",
        "\n",
        "# -------------------------\n",
        "# Example usage (replace meta_X and y with your data)\n",
        "# -------------------------\n",
        "# meta_X must be numpy array shaped like training-time meta features (e.g. meta_X_train shape)\n",
        "# y is optional\n",
        "# label_map_back = {0:-1.0, 1:0.0, 2:1.0}  # if you want original labels back\n",
        "probs, preds, preds_mapped = load_and_predict(\"meta_model.pkl\", meta_X=meta_X, y=None, threshold=None, label_map_back=None, verbose=True)\n",
        "\n",
        "# Inspect outputs\n",
        "print(\"probs.shape:\", probs.shape)\n",
        "print(\"preds.shape:\", preds.shape)\n",
        "if preds_mapped is not None:\n",
        "    print(\"preds_mapped[:10]:\", preds_mapped[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSvckCSp8Mr",
        "outputId": "f2802344-b3b7-4ecb-8ea7-bd69fe1a81fc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dict artifact with keys: ['meta_model', 'calibrators', 'best_cfg', 'meta_feature_names']\n",
            "Using calibrators to produce averaged probabilities (len calibrators): 5\n",
            "No ground-truth y provided; returning predictions only.\n",
            "probs.shape: (17607, 3)\n",
            "preds.shape: (17607,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "X1nvP47MjnKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "5nGTwsv4qpi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f2d9fa-0438-4806-895f-b4d91e9d5366"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['meta_learner.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"meta_learner.pkl\")\n"
      ],
      "metadata": {
        "id": "TdtsuwkPaxcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7f5e02aa-54d1-45a5-b5f2-9ac50fbe244c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9b1c44f6-b5a4-48c9-907b-d3b73737dc40\", \"meta_learner.pkl\", 425648)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save the three base models\n",
        "joblib.dump(cnn_model, \"cnn_model.pkl\")\n",
        "joblib.dump(lstm_model, \"lstm_model.pkl\")\n",
        "joblib.dump(xgb_clf, \"xgb_model.pkl\")  # change to your actual XGB var name\n",
        "\n",
        "# Download them\n",
        "files.download(\"cnn_model.pkl\")\n",
        "files.download(\"lstm_model.pkl\")\n",
        "files.download(\"xgb_model.pkl\")\n"
      ],
      "metadata": {
        "id": "SF20g9Ys68Nb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6d73df35-1ded-4bfa-f9a1-ba790344a806"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_44d869da-a780-4bca-a4d5-5c3802ecddcd\", \"cnn_model.pkl\", 8295853)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_079fac41-ee43-470c-952a-59e6fb6032a8\", \"lstm_model.pkl\", 5459396)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a631e53-d5d6-4bfc-8f6c-4fdd03efa465\", \"xgb_model.pkl\", 5149851)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "files.download(\"scaler.pkl\")"
      ],
      "metadata": {
        "id": "layD2Oi7Tymv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a66e6935-291f-4c6e-cfec-86c9b0ba9426"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_baf96aa3-ef7f-4741-83ef-49acf72c8ec9\", \"scaler.pkl\", 1751)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5c651d81ed841839ccbb42bc69c920c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5652d98c51343b3a5e8b50007394056",
              "IPY_MODEL_d43b59df62fa470fa75b6eea7545d158",
              "IPY_MODEL_0a821285a2bb4576ac75c27df427b56d"
            ],
            "layout": "IPY_MODEL_0440fe06a82c4f46a9420268830b6491"
          }
        },
        "d5652d98c51343b3a5e8b50007394056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73db2e57dc864a4dbf1b1d9ec8da4c10",
            "placeholder": "​",
            "style": "IPY_MODEL_5817d06dad5f41dc838eda0d02db087f",
            "value": "Best trial: 43. Best value: 0.494442: 100%"
          }
        },
        "d43b59df62fa470fa75b6eea7545d158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c72d8109287b45c5b3db343a7ee29ed8",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9cae7d27fe84fb2aad5e87396dd8643",
            "value": 50
          }
        },
        "0a821285a2bb4576ac75c27df427b56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e2a8b28d9904794ba7b91838c0d86e1",
            "placeholder": "​",
            "style": "IPY_MODEL_4c64358960114bd78d576daf3a464f84",
            "value": " 50/50 [06:37&lt;00:00,  6.11s/it]"
          }
        },
        "0440fe06a82c4f46a9420268830b6491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73db2e57dc864a4dbf1b1d9ec8da4c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5817d06dad5f41dc838eda0d02db087f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c72d8109287b45c5b3db343a7ee29ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9cae7d27fe84fb2aad5e87396dd8643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e2a8b28d9904794ba7b91838c0d86e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c64358960114bd78d576daf3a464f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}